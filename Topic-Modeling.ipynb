{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNk6PgUZErfF3LqY6vAp2Uz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oQZDmnIZSQXM","executionInfo":{"status":"ok","timestamp":1751185014962,"user_tz":-330,"elapsed":5100,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"4d986b5d-1d35-4370-dcd7-9267a3fcba89"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.6.15)\n","Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n","Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.5)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.4.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n"]}],"source":["!pip install opendatasets"]},{"cell_type":"code","source":["import opendatasets as od\n","od.download(\"https://www.kaggle.com/datasets/benhamner/nips-papers\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MS52IAoSf25","executionInfo":{"status":"ok","timestamp":1751185018778,"user_tz":-330,"elapsed":86,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"4544cd99-bbf5-47cb-e075-b19284307596"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping, found downloaded files in \"./nips-papers\" (use force=True to force download)\n"]}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"JHZKeSDsS6qQ","executionInfo":{"status":"ok","timestamp":1751185024777,"user_tz":-330,"elapsed":5,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["papers=pd.read_csv('/content/nips-papers/papers.csv')"],"metadata":{"id":"Q2T9w2AUerpI","executionInfo":{"status":"ok","timestamp":1751185033991,"user_tz":-330,"elapsed":6184,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["papers.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"id":"LdGVOR3Qe6F-","executionInfo":{"status":"ok","timestamp":1751185035993,"user_tz":-330,"elapsed":171,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"bfc8ddef-e4ef-4a28-b204-1a07a3ea3939"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        id  year                                              title  \\\n","4419    50  1987  An Adaptive and Heterodyne Filtering Procedure...   \n","51    1044  1995  Learning with ensembles: How overfitting can b...   \n","1229   212  1989            Time Dependent Adaptive Neural Networks   \n","5903  6340  2016               Doubly Convolutional Neural Networks   \n","3187  3888  2009                             Slow Learners are Fast   \n","5493  5972  2015  A fast, universal algorithm to learn parametri...   \n","7183   945  1994  The Electrotonic Transformation: a Tool for Re...   \n","6474  6856  2017  REBAR: Low-variance, unbiased gradient estimat...   \n","4914  5449  2014                                        A* Sampling   \n","5980   641  1992  Discriminability-Based Transfer between Neural...   \n","\n","     event_type                                           pdf_name  \\\n","4419        NaN  50-an-adaptive-and-heterodyne-filtering-proced...   \n","51          NaN  1044-learning-with-ensembles-how-overfitting-c...   \n","1229        NaN    212-time-dependent-adaptive-neural-networks.pdf   \n","5903     Poster      6340-doubly-convolutional-neural-networks.pdf   \n","3187        NaN                    3888-slow-learners-are-fast.pdf   \n","5493     Poster  5972-a-fast-universal-algorithm-to-learn-param...   \n","7183        NaN  945-the-electrotonic-transformation-a-tool-for...   \n","6474       Oral  6856-rebar-low-variance-unbiased-gradient-esti...   \n","4914       Oral                                5449-a-sampling.pdf   \n","5980        NaN  641-discriminability-based-transfer-between-ne...   \n","\n","                                               abstract  \\\n","4419                                   Abstract Missing   \n","51                                     Abstract Missing   \n","1229                                   Abstract Missing   \n","5903  Building large models with parameter sharing a...   \n","3187  Online learning algorithms have impressive con...   \n","5493  Nonlinear embedding algorithms such as stochas...   \n","7183                                   Abstract Missing   \n","6474  Learning in models with discrete latent variab...   \n","4914  The problem of drawing samples from a discrete...   \n","5980                                   Abstract Missing   \n","\n","                                             paper_text  \n","4419  662\\n\\nAN ADAPTIVE AND HETERODYNE FILTERING PR...  \n","51    Learning with ensembles: How\\nover-fitting can...  \n","1229  710\\n\\nPineda\\n\\nTime DependentAdaptive Neural...  \n","5903  Doubly Convolutional Neural Networks\\n\\nYu Che...  \n","3187  Slow Learners are Fast\\nJohn Langford, Alexand...  \n","5493  A Fast, Universal Algorithm\\nto Learn Parametr...  \n","7183  The Electrotonic Transformation:\\na Tool for R...  \n","6474  REBAR: Low-variance, unbiased gradient estimat...  \n","4914  A? Sampling\\nChris J. Maddison\\nDept. of Compu...  \n","5980  Discriminability-Based Transfer between\\nNeura...  "],"text/html":["\n","  <div id=\"df-62fe1e09-ded0-4a24-aa6e-455f5bf1b2cf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>year</th>\n","      <th>title</th>\n","      <th>event_type</th>\n","      <th>pdf_name</th>\n","      <th>abstract</th>\n","      <th>paper_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4419</th>\n","      <td>50</td>\n","      <td>1987</td>\n","      <td>An Adaptive and Heterodyne Filtering Procedure...</td>\n","      <td>NaN</td>\n","      <td>50-an-adaptive-and-heterodyne-filtering-proced...</td>\n","      <td>Abstract Missing</td>\n","      <td>662\\n\\nAN ADAPTIVE AND HETERODYNE FILTERING PR...</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>1044</td>\n","      <td>1995</td>\n","      <td>Learning with ensembles: How overfitting can b...</td>\n","      <td>NaN</td>\n","      <td>1044-learning-with-ensembles-how-overfitting-c...</td>\n","      <td>Abstract Missing</td>\n","      <td>Learning with ensembles: How\\nover-fitting can...</td>\n","    </tr>\n","    <tr>\n","      <th>1229</th>\n","      <td>212</td>\n","      <td>1989</td>\n","      <td>Time Dependent Adaptive Neural Networks</td>\n","      <td>NaN</td>\n","      <td>212-time-dependent-adaptive-neural-networks.pdf</td>\n","      <td>Abstract Missing</td>\n","      <td>710\\n\\nPineda\\n\\nTime DependentAdaptive Neural...</td>\n","    </tr>\n","    <tr>\n","      <th>5903</th>\n","      <td>6340</td>\n","      <td>2016</td>\n","      <td>Doubly Convolutional Neural Networks</td>\n","      <td>Poster</td>\n","      <td>6340-doubly-convolutional-neural-networks.pdf</td>\n","      <td>Building large models with parameter sharing a...</td>\n","      <td>Doubly Convolutional Neural Networks\\n\\nYu Che...</td>\n","    </tr>\n","    <tr>\n","      <th>3187</th>\n","      <td>3888</td>\n","      <td>2009</td>\n","      <td>Slow Learners are Fast</td>\n","      <td>NaN</td>\n","      <td>3888-slow-learners-are-fast.pdf</td>\n","      <td>Online learning algorithms have impressive con...</td>\n","      <td>Slow Learners are Fast\\nJohn Langford, Alexand...</td>\n","    </tr>\n","    <tr>\n","      <th>5493</th>\n","      <td>5972</td>\n","      <td>2015</td>\n","      <td>A fast, universal algorithm to learn parametri...</td>\n","      <td>Poster</td>\n","      <td>5972-a-fast-universal-algorithm-to-learn-param...</td>\n","      <td>Nonlinear embedding algorithms such as stochas...</td>\n","      <td>A Fast, Universal Algorithm\\nto Learn Parametr...</td>\n","    </tr>\n","    <tr>\n","      <th>7183</th>\n","      <td>945</td>\n","      <td>1994</td>\n","      <td>The Electrotonic Transformation: a Tool for Re...</td>\n","      <td>NaN</td>\n","      <td>945-the-electrotonic-transformation-a-tool-for...</td>\n","      <td>Abstract Missing</td>\n","      <td>The Electrotonic Transformation:\\na Tool for R...</td>\n","    </tr>\n","    <tr>\n","      <th>6474</th>\n","      <td>6856</td>\n","      <td>2017</td>\n","      <td>REBAR: Low-variance, unbiased gradient estimat...</td>\n","      <td>Oral</td>\n","      <td>6856-rebar-low-variance-unbiased-gradient-esti...</td>\n","      <td>Learning in models with discrete latent variab...</td>\n","      <td>REBAR: Low-variance, unbiased gradient estimat...</td>\n","    </tr>\n","    <tr>\n","      <th>4914</th>\n","      <td>5449</td>\n","      <td>2014</td>\n","      <td>A* Sampling</td>\n","      <td>Oral</td>\n","      <td>5449-a-sampling.pdf</td>\n","      <td>The problem of drawing samples from a discrete...</td>\n","      <td>A? Sampling\\nChris J. Maddison\\nDept. of Compu...</td>\n","    </tr>\n","    <tr>\n","      <th>5980</th>\n","      <td>641</td>\n","      <td>1992</td>\n","      <td>Discriminability-Based Transfer between Neural...</td>\n","      <td>NaN</td>\n","      <td>641-discriminability-based-transfer-between-ne...</td>\n","      <td>Abstract Missing</td>\n","      <td>Discriminability-Based Transfer between\\nNeura...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62fe1e09-ded0-4a24-aa6e-455f5bf1b2cf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-62fe1e09-ded0-4a24-aa6e-455f5bf1b2cf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-62fe1e09-ded0-4a24-aa6e-455f5bf1b2cf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-885bfb8b-1511-4e04-9aaa-11f651c86ba2\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-885bfb8b-1511-4e04-9aaa-11f651c86ba2')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-885bfb8b-1511-4e04-9aaa-11f651c86ba2 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"papers\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2819,\n        \"min\": 50,\n        \"max\": 6856,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          5449,\n          1044,\n          5972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 1987,\n        \"max\": 2017,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2014,\n          1995,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"A* Sampling\",\n          \"Learning with ensembles: How overfitting can be useful\",\n          \"A fast, universal algorithm to learn parametric nonlinear embeddings\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Oral\",\n          \"Poster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"5449-a-sampling.pdf\",\n          \"1044-learning-with-ensembles-how-overfitting-can-be-useful.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Abstract Missing\",\n          \"Building large models with parameter sharing accounts for most of the success of deep convolutional neural networks (CNNs). In this paper, we propose doubly convolutional neural networks (DCNNs), which significantly improve the performance of CNNs by further exploring this idea. In stead of allocating a set of convolutional filters that are independently learned, a DCNN maintains groups of filters where filters within each group are translated versions of each other. Practically, a DCNN can be easily implemented by a two-step convolution procedure, which is supported by most modern deep learning libraries. We perform extensive experiments on three image classification benchmarks: CIFAR-10, CIFAR-100 and ImageNet, and show that DCNNs consistently outperform other competing architectures. We have also verified that replacing a convolutional layer with a doubly convolutional layer at any depth of a CNN can improve its performance. Moreover, various design choices of DCNNs are demonstrated, which shows that DCNN can serve the dual purpose of building more accurate models and/or reducing the memory footprint without sacrificing the accuracy.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"A? Sampling\\nChris J. Maddison\\nDept. of Computer Science\\nUniversity of Toronto\\ncmaddis@cs.toronto.edu\\n\\nDaniel Tarlow, Tom Minka\\nMicrosoft Research\\n{dtarlow,minka}@microsoft.com\\n\\nAbstract\\nThe problem of drawing samples from a discrete distribution can be converted into\\na discrete optimization problem [1, 2, 3, 4]. In this work, we show how sampling\\nfrom a continuous distribution can be converted into an optimization problem over\\ncontinuous space. Central to the method is a stochastic process recently described\\nin mathematical statistics that we call the Gumbel process. We present a new\\nconstruction of the Gumbel process and A? Sampling, a practical generic sampling\\nalgorithm that searches for the maximum of a Gumbel process using A? search.\\nWe analyze the correctness and convergence time of A? Sampling and demonstrate\\nempirically that it makes more efficient use of bound and likelihood evaluations\\nthan the most closely related adaptive rejection sampling-based algorithms.\\n\\n1\\n\\nIntroduction\\n\\nDrawing samples from arbitrary probability distributions is a core problem in statistics and machine learning. Sampling methods are used widely when training, evaluating, and predicting with\\nprobabilistic models. In this work, we introduce a generic sampling algorithm that returns exact\\nindependent samples from a distribution of interest. This line of work is important as we seek to\\ninclude probabilistic models as subcomponents in larger systems, and as we seek to build probabilistic modelling tools that are usable by non-experts; in these cases, guaranteeing the quality of\\ninference is highly desirable. There are a range of existing approaches for exact sampling. Some\\nare specialized to specific distributions [5], but exact generic methods are based either on (adaptive)\\nrejection sampling [6, 7, 8] or Markov Chain Monte Carlo (MCMC) methods where convergence to\\nthe stationary distribution can be guaranteed [9, 10, 11].\\nThis work approaches the problem from a different perspective. Specifically, it is inspired by an\\nalgorithm for sampling from a discrete distribution that is known as the Gumbel-Max trick. The\\nalgorithm works by adding independent Gumbel perturbations to each configuration of a discrete\\nnegative energy function and returning the argmax configuration of the perturbed negative energy\\nfunction. The result is an exact sample from the corresponding Gibbs distribution. Previous work\\n[1, 3] has used this property to motivate samplers based on optimizing random energy functions but\\nhas been forced to resort to approximate sampling due to the fact that in structured output spaces,\\nexact sampling appears to require instantiating exponentially many Gumbel perturbations.\\nOur first key observation is that we can apply the Gumbel-Max trick without instantiating all of\\nthe (possibly exponentially many) Gumbel perturbations. The same basic idea then allows us to\\nextend the Gumbel-Max trick to continuous spaces where there will be infinitely many independent\\nperturbations. Intuitively, for any given random energy function, there are many perturbation values\\nthat are irrelevant to determining the argmax so long as we have an upper bound on their values. We\\nwill show how to instantiate the relevant ones and bound the irrelevant ones, allowing us to find the\\nargmax ? and thus an exact sample.\\nThere are a number of challenges that must be overcome along the way, which are addressed in this\\nwork. First, what does it mean to independently perturb space in a way analogous to perturbations\\nin the Gumbel-Max trick? We introduce the Gumbel process, a special case of a stochastic process recently defined in mathematical statistics [12], which generalizes the notion of perturbation\\n1\\n\\n\\fover space. Second, we need a method for working with a Gumbel process that does not require\\ninstantiating infinitely many random variables. This leads to our novel construction of the Gumbel\\nprocess, which draws perturbations according to a top-down ordering of their values. Just as the\\nstick breaking construction of the Dirichlet process gives insight into algorithms for the Dirichlet\\nprocess, our construction gives insight into algorithms for the Gumbel process. We demonstrate\\nthis by developing A? sampling, which leverages the construction to draw samples from arbitrary\\ncontinuous distributions. We study the relationship between A? sampling and adaptive rejection\\nsampling-based methods and identify a key difference that leads to more efficient use of bound and\\nlikelihood computations. We investigate the behaviour of A? sampling on a variety of illustrative\\nand challenging problems.\\n\\n2\\n\\nThe Gumbel Process\\n\\nThe Gumbel-Max trick is an algorithm for sampling from a categorical distribution over classes\\ni 2 {1, . . . , n} with probability proportional to exp( (i)). The algorithm proceeds by adding\\nindependent Gumbel-distributed noise to the log-unnormalized mass (i) and returns the optimal\\nclass of the perturbed distribution. In more detail, G ? Gumbel(m) is a Gumbel with location\\nm if P(G ? g) = exp( exp( g + m)). The Gumbel-Max trick follows from the structure of\\nGumbel distributions and basic properties\\nP of order statistics; if G(i) are i.i.d. Gumbel(0), then\\nargmaxi {G(i) + (i)} ? exp( (i))/ i exp( (i)). Further, for any B ? {1, . . . , n}\\n!\\nX\\nmax {G(i) + (i)} ? Gumbel log\\nexp( (i))\\n(1)\\ni2B\\n\\ni2B\\n\\nexp( (i))\\nargmax {G(i) + (i)} ? P\\n(2)\\ni2B\\ni2B exp( (i))\\nEq. 1 is known as max-stability?the highest order statistic of a sample of independent Gumbels\\nalso has a Gumbel distribution with a location that is the log partition function [13]. Eq. 2 is a\\nconsequence of the fact that Gumbels satisfy Luce?s choice axiom [14]. Moreover, the max and\\nargmax are independent random variables, see Appendix for proofs.\\nWe would like to generalize the interpretation to continuous distributions as maximizing over the\\nperturbation of a density p(x) / exp( (x)) on Rd . The perturbed density should have properties analogousR to the discrete case, namely that the max in B ? Rd should be distributed\\nas Gumbel(log x2B exp( (x))) and the distribution of the argmax in B should be distributed\\n/ 1(x 2 B) exp( (x)). The Gumbel process is a generalization satisfying these properties.\\nDefinition 1. Adapted from [12]. Let ?(B) be a sigma-finite measure on sample space ?, B ? ?\\nmeasurable, and G? (B) a random variable. G? = {G? (B) | B ? ?} is a Gumbel process, if\\n1. (marginal distributions) G? (B) ? Gumbel (log ?(B)) .\\n2. (independence of disjoint sets) G? (B) ? G? (B c ).\\n\\n3. (consistency constraints) for measurable A, B ? ?, then\\nG? (A [ B) = max(G? (A), G? (B)).\\nThe marginal distributions condition ensures that the Gumbel process satisfies the requirement on\\nthe max. The consistency requirement ensures that a realization of a Gumbel process is consistent\\nacross space. Together with the independence these ensure the argmax requirement. In particular, if\\nG? (B) is the optimal value of some perturbed density restricted to B, then the event that the optima\\nover ? is contained in B is equivalent to the event that G? (B) G? (B c ). The conditions ensure\\nthat P(G? (B)\\nG? (B c )) is a probability measure proportional\\nto ?(B) [12]. Thus, we can use\\nR\\nthe Gumbel process for a continuous measure ?(B) = x2B exp( (x)) on Rd to model a perturbed\\ndensity function where the optimum is distributed / exp( (x)). Notice that this definition is a\\ngeneralization of the finite case; if ? is finite, then the collection G? corresponds exactly to maxes\\nover subsets of independent Gumbels.\\n\\n3\\n\\nTop-Down Construction for the Gumbel Process\\n\\nWhile [12] defines and constructs a general class of stochastic processes that include the Gumbel\\nprocess, the construction that proves their existence gives little insight into how to execute a con2\\n\\n\\ftinuous version of the Gumbel-Max trick. Here we give an alternative algorithmic construction that\\nwill form the foundation of our practical sampling algorithm. In this section we assume log ?(?)\\ncan be computed tractably; this assumption will be lifted in Section 4. To explain the construction,\\nwe consider the discrete case as an introductory example.\\nSuppose G? (i) ? Gumbel( (i)) is a set\\nAlgorithm 1 Top-Down Construction\\nof independent Gumbel random variables\\nR\\nfor i 2 {1, . . . , n}. It would be straight- input sample space ?, measure ?(B) = B exp( )dm\\n(B1 , Q)\\n(?, Queue)\\nforward to sample the variables then build\\nG1 ? Gumbel(log ?(?))\\na heap of the G? (i) values and also have\\nX1 ? exp( (x))/?(?)\\nheap nodes store the index i associated\\nQ.push(1)\\nwith their value. Let Bi be the set of\\nk\\n1\\nindices that appear in the subtree rooted\\nwhile !Q.empty() do\\nat the node with index i. A property of\\np\\nQ.pop()\\nthe heap is that the root (G? (i), i) pair is\\nL, R\\npartition(Bp {Xp })\\nthe max and argmax of the set of Gumfor C 2 {L, R} do\\nbels with index in Bi . The key idea of\\nif C 6= ; then\\nk\\nk+1\\nour construction is to sample the indepenBk\\nC\\ndent set of random variables by instantiatGk ? TruncGumbel(log ?(Bk ), Gp )\\ning this heap from root to leaves. That is,\\nXk ? 1(x 2 Bk ) exp( (x))/?(Bk )\\nwe will first sample the root node, which is\\nQ.push(k)\\nthe global max and argmax, then we will\\nyield (Gk , Xk )\\nrecurse, sampling the root?s two children\\nconditional upon the root. At the end, we\\nwill have sampled a heap full of values and indices; reading off the value associated with each index\\nwill yield a draw of independent Gumbels from the target distribution.\\nWe sketch an inductive argument. For the base case, sample the max and its index i? using their\\ndistributions that we know from Eq. 1 and Eq. 2. Note the max and argmax are independent. Also\\nlet Bi? = {0, . . . , n 1} be the set of all indices. Now, inductively, suppose have sampled a partial\\nheap and would like to recurse downward starting at (G? (p), p). Partition the remaining indices to\\nbe sampled Bp {p} into two subsets L and R and let l 2 L be the left argmax and r 2 R be the\\nright argmax. Let [ p] be the indices that have been sampled already. Then\\np G? (l) = gl , G? (r) = gr , {G? (k) = gk }k2[ p] | [ p]\\n?\\n? ?\\n? Y\\n/p max G? (i) = gl p max G? (i) = gr\\npk (G? (k) = gk )1 gk\\ni2L\\n\\ni2R\\n\\nk2[ p]\\n\\n(3)\\ngL(k) ^ gk\\n\\ngR(k)\\n\\nwhere L(k) and R(k) denote the left and right children of k and the constraints should only be\\napplied amongst nodes [ p] [ {l, r}. This implies\\np G? (l) = gl , G? (r) = gr | {G? (k) = gk }k2[ p] , [ p]\\n?\\n? ?\\n?\\n/ p max G? (i) = gl p max G? (i) = gr 1(gp > gl ) 1(gp > gr ) .\\ni2L\\n\\ni2R\\n\\n(4)\\n\\nEq. 4 is the joint density of two independent Gumbels truncated at G? (p). We could sample the\\nchildren maxes and argmaxes by sampling the independent Gumbels in L and R respectively and\\ncomputing their maxes, rejecting those that exceed the known value of G? (p). Better, the truncated\\nGumbel distributions can be sampled efficiently via CDF inversion1 , and the independent argmaxes\\nwithin L and R can be sampled using Eq. 2. Note that any choice of partitioning strategy for L and\\nR leads to the same distribution over the set of Gumbel values.\\nThe basic structure of this top-down sampling procedure allows us to deal with infinite spaces; we\\ncan still generate an infinite descending heap of Gumbels and locations as if we had made a heap\\nfrom an infinite list. The algorithm (which appears as Algorithm 1) begins by sampling the optimal\\nvalue G1 ? Gumbel(log ?(?)) over sample space ? and its location X1 ? exp( (x))/?(?). X1\\nis removed from the sample space and the remaining sample space is partitioned into L and R. The\\noptimal Gumbel values for L and R are sampled from a Gumbel with location log measure of their\\n1\\nG ? TruncGumbel( , b) if G has CDF exp( exp( min(g, b)+ ))/ exp( exp( b+ )). To sample\\nefficiently, return G = log(exp( b\\n+ ) log(U ))\\n+ where U ? uniform[0, 1].\\n\\n3\\n\\n\\frespective sets, but truncated at G1 . The locations are sampled independently from their sets, and\\nthe procedure recurses. As in the discrete case, this yields a stream of (Gk , Xk ) pairs, which we can\\nthink of as being nodes in a heap of the Gk ?s.\\nIf G? (x) is the value of the perturbed negative energy at x, then Algorithm 1 instantiates this function\\nat countably many points by setting G? (Xk ) = Gk . In the discrete case we eventually sample\\nthe complete perturbed density, but in the continuous case we simply generate an infinite stream\\nof locations and values. The sense in which Algorithm 1 constructs a Gumbel process is that the\\ncollection {max{Gk | Xk 2 B} | B ? ?} satisfies Definition 1. The intuition should be provided by\\nthe introductory argument; a full proof appears in the Appendix. An important note is that because\\nGk ?s are sampled in descending order along a path in the tree, when the first Xk lands in set B, the\\nvalue of max{Gk | Xk 2 B} will not change as the algorithm continues.\\n\\n4\\n\\nexact\\nsample\\n\\nA? Sampling\\n\\nThe Top-Down construction is not executable\\nin general, because it assumes log ?(?) can be\\ncomputed efficiently. A? sampling is an algorithm that executes the Gumbel-Max trick without this assumption by exploiting properties\\nof the Gumbel process. Henceforth A? sampling refers exclusively to the continuous version.\\n\\nLB1\\n\\nLB2\\n\\no(x)+G\\nx1\\n\\nx2\\n\\no(x)\\nA sampling is possible because we can trans?\\nFigure 1: Illustration of A sampling.\\nform one Gumbel process into another by\\nadding the difference in their log densities.\\nAlgorithm 2 A? Sampling\\nSuppose we Rhave two continuous measures\\n?(B) =\\nexp( (x)) and ?(B) = input log density i(x), difference o(x), bounding\\nx2B\\nR\\nfunction M (B), and partition\\nexp(i(x)).\\nLet\\npairs (Gk , Xk ) be draws\\nx2B\\n(LB, X ? , k)\\n( 1, null, 1)\\nfrom the Top-Down construction for G? . If\\nQ\\nPriorityQueue\\no(x) = (x)\\ni(x) is bounded, then we\\nG1 ? Gumbel(log ?(Rd ))\\ncan recover G? by adding the difference o(Xk )\\nX1 ? exp(i(x))/?(Rd ))\\nto every Gk ; i.e., {max{Gk + o(Xk ) | Xk 2\\nM1\\nM (Rd )\\nB} | B ? Rd } is a Gumbel process with meaQ.pushW ithP riority(1, G1 + M1 )\\nsure ?. As an example, if ? were a prior and\\nwhile !Q.empty() and LB < Q.topP riority() do\\no(x) a bounded log-likelihood, then we could\\np\\nQ.popHighest()\\nLBp\\nGp + o(Xp )\\nsimulate the Gumbel process corresponding to\\nif LB < LBp then\\nthe posterior by adding o(Xk ) to every Gk from\\nLB\\nLBp\\na run of the construction for ?.\\n?\\n\\n?\\n\\nX\\n\\nXp\\n\\nThis ?linearity? allows us to decompose a tarL, R\\npartition(Bp , Xp )\\nfor C 2 {L, R} do\\nget log density function into a tractable i(x)\\nif C 6= ; then\\nand boundable o(x). The tractable compok\\nk+1\\nnent is analogous to the proposal distribution\\nBk\\nC\\nin a rejection sampler. A? sampling searches\\nGk ? TruncGumbel(log ?(Bk ), Gp )\\nfor argmax{Gk + o(Xk )} within the heap of\\nXk ? 1(x 2 Bk ) exp(i(x))/?(Bk )\\n(Gk , Xk ) pairs from the Top-Down construcif LB < Gk + Mp then\\n?\\ntion of G? . The search is an A procedure:\\nMk\\nM (Bk )\\nnodes in the search tree correspond to increasif LB < Gk + Mk then\\ningly refined regions in space, and the search\\nQ.pushW ithP riority(k, Gk + Mk )\\nis guided by upper and lower bounds that are output (LB, X ? )\\ncomputed for each region. Lower bounds for\\nregion B come from drawing the max Gk and argmax Xk of G? within B and evaluating Gk +o(Xk ).\\nUpper bounds come from the fact that\\nmax{Gk + o(Xk ) | Xk 2 B} ? max{Gk | Xk 2 B} + M (B),\\nwhere M (B) is a bounding function for a region, M (B) o(x) for all x 2 B. M (B) is not random\\nand can be implemented using methods from e.g., convex duality or interval analysis. The first term\\non the RHS is the Gk value used in the lower bound.\\n4\\n\\n\\fThe algorithm appears in Algorithm 2 and an execution is illustrated in Fig. 1. The algorithm begins\\nwith a global upper bound (dark blue dashed). G1 and X1 are sampled, and the first lower bound\\nLB1 = G1 + o(X1 ) is computed. Space is split, upper bounds are computed for the new children\\nregions (medium blue dashed), and the new nodes are put on the queue. The region with highest\\nupper bound is chosen, the maximum Gumbel in the region, (G2 , X2 ), is sampled, and LB2 is\\ncomputed. The current region is split at X2 (producing light blue dashed bounds), after which LB2\\nis greater than the upper bound for any region on the queue, so LB2 is guaranteed to be the max over\\nthe infinite tree of Gk + o(Xk ). Because max{Gk + o(Xk ) | Xk 2 B} is a Gumbel process with\\nmeasure ?, this means that X2 is an exact sample from p(x) / exp( (x))) and LB2 is an exact\\nsample from Gumbel(log ?(Rd )). Proofs of termination and correctness are in the Appendix.\\nA? Sampling Variants. There are several variants of A? sampling. When more than one sample\\nis desired, bound information can be reused across runs of the sampler. In particular, suppose we\\nhave a partition of Rd with bounds on o(x) for each region. A? sampling could use this by running a\\nsearch independently for each region and returning the max Gumbel. The maximization can be done\\nlazily by using A? search, only expanding nodes in regions that are needed to determine the global\\nmaximum. The second variant trades bound computations for likelhood computations by drawing\\nmore than one sample from the auxiliary Gumbel process at each node in the search tree. In this\\nway, more lower bounds are computed (costing more likelihood evaluations), but if this leads to\\nbetter lower bounds, then more regions of space can be pruned, leading to fewer bound evaluations.\\nFinally, an interesting special case of A? sampling can be implemented when o(x) is unimodal in\\n1D. In this case, at every split of a parent node, one child can immediately be pruned, so the ?search?\\ncan be executed without a queue. It simply maintains the currently active node and drills down until\\nit has provably found the optimum.\\n\\n5\\n\\nComparison to Rejection Samplers\\n\\nOur first result relating A? sampling to rejection sampling is that if the same global bound M =\\nM (Rd ) is used at all nodes within A? sampling, then the runtime of A? sampling is equivalent to that\\nof standard rejection sampling. That is, the distribution over the number of iterations is distributed\\nas a Geometric distribution with rate parameter ?(Rd )/(exp(M )?(Rd )). A proof is in the Appendix\\nas part of the proof of termination.\\nWhen bounds are refined, A? sampling bears similarity to adaptive rejection sampling-based algorithms. In particular, while it appears only to have been applied in discrete domains, OS? [7] is a\\ngeneral class of adaptive rejection sampling methods that maintain piecewise bounds on the target\\ndistribution. If piecewise constant bounds are used (henceforth we assume OS? uses only constant\\nbounds) the procedure can be described as follows: at each step, (1) a region B with bound U (B) is\\nsampled with probability proportional to ?(B) exp(M (B)), (2) a point is drawn from the proposal\\ndistribution restricted to the chosen region; (3) standard accept/rejection computations are performed\\nusing the regional bound, and (4) if the point is rejected, a region is chosen to be split into two, and\\nnew bounds are computed for the two regions that were created by the split. This process repeats\\nuntil a point is accepted.\\nSteps (2) and (4) are performed identically in A? when sampling argmax Gumbel locations and when\\nsplitting a parent node. A key difference is how regions are chosen in step (1). In OS? , a region\\nis drawn according to volume of the region under the proposal. Note that piece selection could be\\nimplemented using the Gumbel-Max trick, in which case we would choose the piece with maximum\\nGB + M (B) where GB ? Gumbel(log ?(B)). In A? sampling the region with highest upper bound\\nis chosen, where the upper bound is GB + M (B). The difference is that GB values are reset after\\neach rejection in OS? , while they persist in A? sampling until a sample is returned.\\nThe effect of the difference is that A? sampling more tightly couples together where the accepted\\nsample will be and which regions are refined. Unlike OS? , it can go so far as to prune a region\\nfrom the search, meaning there is zero probability that the returned sample will be from that region,\\nand that region will never be refined further. OS? , on the other hand, is blind towards where the\\nsample that will eventually be accepted comes from and will on average waste more computation\\nrefining regions that ultimately are not useful in drawing the sample. In experiments, we will see\\nthat A? consistently dominates OS? , refining the function less while also using fewer likelihood\\nevaluations. This is possible because the persistence inside A? sampling focuses the refinement on\\nthe regions that are important for accepting the current sample.\\n5\\n\\n\\f(a) vs. peakiness\\n\\n(b) vs. # pts\\n\\n(c) Problem-dependent scaling\\n\\nFigure 2: (a) Drill down algorithm performance on p(x) = exp( x)/(1 + x)a as function of a. (b) Effect of\\ndifferent bounding strategies as a function of number of data points; number of likelihood and bound evaluations\\nare reported. (c) Results of varying observation noise in several nonlinear regression problems.\\n\\n6\\n\\nExperiments\\n\\nThere are three main aims in this section. First, understand the empirical behavior of A? sampling as\\nparameters of the inference problem and o(x) bounds vary. Second, demonstrate generality by\\nshowing that A? sampling algorithms can be instantiated in just a few lines of model-specific code by\\nexpressing o(x) symbolically, and then using a branch and bound library to automatically compute\\nbounds. Finally, compare to OS? and an MCMC method (slice sampling). In all experiments,\\nregions in the search trees are hyper rectangles (possibly with infinite extent); to split a region A,\\nchoose the dimension with the largest side length and split the dimension at the sampled Xk point.\\n6.1 Scaling versus Peakiness and Dimension\\nIn the first experiment, we sample from p(x) = exp( x)/(1 + x)a for x > 0, a > 0 using exp( x)\\nas the proposal distribution. In this case, o(x) = a log(1 + x) which is unimodal, so the drill down\\nvariant of A? sampling can be used. As a grows, the function becomes peakier; while this presents\\nsignificant difficulty for vanilla rejection sampling, the cost to A? is just the cost of locating the peak,\\nwhich is essentially binary search. Results averaged over 1000 runs appear in Fig. 2 (a).\\nIn the second experiment, we run A? sampling on the clutter problem [15], which estimates the\\nmean of a fixed covariance isotropic Gaussian under the assumption that some points are outliers.\\nWe put a Gaussian prior on the inlier mean and set i(x) to be equal to the prior, so o(x) contains\\njust the likelihood terms. To compute bounds on the total log likelihood, we compute upper bounds\\non the log likelihood of each point independently then sum up these bounds. We will refer to these\\nas ?constant? bounds. In D dimensions, we generated 20 data points with half within [ 5, 3]D\\nand half within [2, 4]D , which ensures that the posterior is sharply bimodal, making vanilla MCMC\\nquickly inappropriate as D grows. The cost of drawing an exact sample as a function of D (averaged\\nover 100 runs) grows exponentially in D, but the problem remains reasonably tractable as D grows\\n(D = 3 requires 900 likelihood evaluations, D = 4 requires 4000). The analogous OS? algorithm\\nrun on the same set of problems requires 16% to 40% more computation on average over the runs.\\n6.2 Bounding Strategies\\nHere we investigate alternative strategies for bounding o(x) in the case where o(x) is a sum of\\nper-instance log likelihoods. To allow easy implementation of a variety of bounding strategies, we\\nchoose the simple problem of estimating the mean of a 1D Gaussian given N observations. We use\\nthree types of bounds: constant bounds as in the clutter problem; linear bounds, where we compute\\nlinear upper bounds on each term of the sum, then sum the linear functions and take the max over the\\nregion; and quadratic bounds, which are the same as linear except quadratic bounds are computed\\non each term. In this problem, quadratic bounds are tight. We evaluate A? sampling using each of\\nthe bounding strategies, varying N . See Fig. 2 (b) for results.\\nFor N = 1, all bound types are equivalent when each expands around the same point. For larger N ,\\nthe looseness of each per-point bound becomes important. The figure shows that, for large N , using\\nlinear bounds multiplies the number of evaluations p\\nby 3, compared to tight bounds. Using constant\\nbounds multiplies the number of evaluations by O( N ). The Appendix explains why this happens\\n6\\n\\n\\fand shows that this behavior is expected for any estimation problem where the width of the posterior\\nshrinks with N .\\n6.3 Using Generic Interval Bounds\\nHere we study the use of bounds that are derived automatically by means of interval methods [16].\\nThis suggests how A? sampling (or OS? ) could be used within a more general purpose probabilistic\\nprogramming setting. We chose a number of nonlinear regression models inspired by problems in\\nphysics, computational ecology, and biology. For each, we use FuncDesigner [17] to symbolically\\nconstruct o(x) and automatically compute the bounds needed by the samplers.\\nSeveral expressions for y = f (x) appear in the legend of Fig. 2 (c), where letters a through f denote\\nparameters that we wish to sample. The model in all cases is yn = f (xn ) + ?n where n is the\\ndata point index and ?n is Gaussian noise. We set uniform priors from a reasonable range for all\\nparameters (see Appendix) and generated a small (N=3) set of training data from the model so that\\nposteriors are multimodal. The peakiness of the posterior can be controlled by the magnitude of the\\nobservation noise; we varied this from large to small to produce problems over a range of difficulties.\\nWe use A? sampling to sample from the posterior five times for each model and noise setting and\\nreport the average number of likelihood evaluations needed in Fig. 2 (c) (y-axis). To establish the\\ndifficulty of the problems, we estimate the expected number of likelihood evaluations needed by a\\nrejection sampler to accept a sample. The savings over rejection sampling is often exponentially\\nlarge, but it varies per problem and is not necessarily tied to the dimension. In the example where\\nsavings are minimal, there are many symmetries in the model, which leads to uninformative bounds.\\nWe also compared to OS? on the same class of problems. Here we generated 20 random instances\\nwith a fixed intermediate observation noise value for each problem and drew 50 samples, resetting\\nthe bounds after each sample. The average cost (heuristically set to # likelihood evaluations plus 2\\n? # bound evaluations) of OS? for the five models in Fig. 2 (c) respectively was 21%, 30%, 11%,\\n21%, and 27% greater than for A? .\\n6.4 Robust Bayesian Regression\\nHere our aim is to do Bayesian inference in a robust linear regression model yn = wT xn + ?n where\\nnoise ?n is distributed as standard Cauchy and w has an isotropic Gaussian prior. Given a dataset\\nD = {xn , yn }N\\nn=1 our goal is to draw samples from the posterior P(w | D). This is a challenging\\nproblem because the heavy-tailed\\nP noise model can lead to multimodality in the posterior over w.\\nThe log likelihood is L(w) = n log(1 + (wT xn yn )2 ). We generated N data points with input\\ndimension D in such a way that the posterior is bimodal and symmetric by setting w? = [2, ..., 2]T ,\\ngenerating X 0 ? randn(N/2, D) and y 0 ? X 0 w? +.1?randn(N/2), then setting X = [X 0 ; X 0 ] and\\ny = [y 0 ; y 0 ]. There are then equally-sized modes near w? and w? . We decompose the posterior\\ninto a uniform i(?) within the interval [ 10, 10]D and put all of the prior and likelihood terms into\\no(?). Bounds are computed per point; in some regions the per point bounds are linear, and in others\\nthey are quadratic. Details appear in the Appendix.\\nWe compare to OS? , using two refinement strategies that are discussed in [7]. The first is directly\\nanalogous to A? sampling and is the method we have used in the earlier OS? comparisons. When a\\npoint is rejected, refine the piece that was proposed from at the sampled point, and split the dimension with largest side length. The second method splits the region with largest probability under the\\nproposal. We ran experiments on several random draws of the data and report performance along\\nthe two axes that are the dominant costs: how many bound computations were used, and how many\\nlikelihood evaluations were used. To weigh the tradeoff between the two, we did a rough asymptotic calculation of the costs of bounds versus likelihood computations and set the cost of a bound\\ncomputation to be D + 1 times the cost of a likelihood computation.\\nIn the first experiment, we ask each algorithm to draw a single exact sample from the posterior.\\nHere, we also report results for the variants of A? sampling and OS? that trade off likelihood computations for bound computations as discussed in Section 4. A representative result appears in Fig. 3\\n(left). Across operating points, A? consistently uses fewer bound evaluations and fewer likelihood\\nevaluations than both OS? refinement strategies.\\nIn the second experiment, we ask each algorithm to draw 200 samples from the posterior and experiment with the variants that reuse bound information across samples. A representative result appears\\nin Fig. 3 (right). Here we see that the extra refinement done by OS? early on allows it to use fewer\\nlikelihood evaluations at the expense of more bound computations, but A? sampling operates at a\\n7\\n\\n\\fpoint that is not achievable by OS? . For all of these problems, we ran a random direction slice\\nsampler [18] that was given 10 times the computational budget that A? sampling used to draw 200\\nsamples. The slice sampler had trouble mixing when D > 1. Across the five runs for D = 2, the\\nsampler switched modes once, and it did not ever switch modes when D > 2.\\n\\n7\\n\\nDiscussion\\n\\nThis work answers a natural question: is there\\na Gumbel-Max trick for continuous spaces, and\\ncan it be leveraged to develop tractable algorithms for sampling from continuous distributions?\\nIn the discrete case, recent work on ?Perturb\\nand MAP? (P&M) methods [1, 19, 2] that draw\\nsamples as the argmaxes of random energy\\nfunctions has shown value in developing approximate, correlated perturbations. It is natural to think about continuous analogs in which\\nexactness is abandoned in favor of more efficient computation. A question is if the approximations can be developed in a principled way,\\nlike how [3] showed a particular form of correlated discrete perturbation gives rise to bounds\\non the log partition function. Can analogous\\nrigorous approximations be established in the\\ncontinuous case? We hope this work is a starting point for exploring that question.\\n\\nFigure 3: A? (circles) versus OS? (squares and dia-\\n\\nmonds) computational costs on Cauchy regression experiments of varying dimension. Square is refinement\\nstrategy that splits node where rejected point was sampled; Diamond refines region with largest mass under\\nthe proposal distribution. Red lines denote lines of\\nequi-total computational cost and are spaced on a log\\nscale by 10% increase increments. Color of markers denotes the rate of refinement, ranging from (darkest) refining for every rejection (for OS? ) or one lower bound\\nevaluation per node expansion (for A? ) to (lightest) refining on 10% of rejections (for OS? ) or performing\\n1\\nPoisson( .1\\n1) + 1 lower bound evaluations per node\\nexpansion (for A? ). (left) Cost of drawing a single sample, averaged over 20 random data sets. (right) Drawing\\n200 samples averaged over 5 random data sets. Results\\nare similar over a range of N ?s and D = 1, . . . , 4.\\n\\nWe do not solve the problem of high dimensions. There are simple examples where\\nbounds become uninformative in high dimensions, such as when sampling a density that is\\nuniform over a hypersphere when using hyperrectangular search regions. In this case, little is gained\\nover vanilla rejection sampling. An open question is if the split between i(?) and o(?) can be adapted\\nto be node-specific during the search. An adaptive rejection sampler would be able to do this, which\\nwould allow leveraging parameter-varying bounds in the proposal distributions. This might be an\\nimportant degree of freedom to exercise, particularly when scaling up to higher dimensions.\\nThere are several possible follow-ons including the discrete version of A? sampling and evaluating\\nA? sampling as an estimator of the log partition function. In future work, we would like to explore\\ntaking advantage of conditional independence structure to perform more intelligent search, hopefully helping the method scale to larger dimensions. Example starting points might be ideas from\\nAND/OR search [20] or branch and bound algorithms that only branch on a subset of dimensions\\n[21].\\n\\nAcknowledgments\\nThis research was supported by NSERC. We thank James Martens and Radford Neal for helpful\\ndiscussions, Elad Mezuman for help developing early ideas related to this work, and Roger Grosse\\nfor suggestions that greatly improved this work.\\n\\nReferences\\n[1] G. Papandreou and A. Yuille. Perturb-and-MAP Random Fields: Using Discrete Optimization to Learn\\nand Sample from Energy Models. In ICCV, pages 193?200, November 2011.\\n[2] Daniel Tarlow, Ryan Prescott Adams, and Richard S Zemel. Randomized Optimum Models for Structured\\nPrediction. In AISTATS, pages 21?23, 2012.\\n[3] Tamir Hazan and Tommi S Jaakkola. On the Partition Function and Random Maximum A-Posteriori\\nPerturbations. In ICML, pages 991?998, 2012.\\n\\n8\\n\\n\\f[4] Stefano Ermon, Carla P Gomes, Ashish Sabharwal, and Bart Selman. Embed and Project: Discrete\\nSampling with Universal Hashing. In NIPS, pages 2085?2093, 2013.\\n[5] George Papandreou and Alan L Yuille. Gaussian Sampling by Local Perturbations. In NIPS, pages\\n1858?1866, 2010.\\n[6] W.R. Gilks and P. Wild. Adaptive Rejection Sampling for Gibbs Sampling. Applied Statistics, 41(2):337\\n? 348, 1992.\\n[7] Marc Dymetman, Guillaume Bouchard, and Simon Carter. The OS* Algorithm: a Joint Approach to\\nExact Optimization and Sampling. arXiv preprint arXiv:1207.0742, 2012.\\n[8] V Mansinghka, D Roy, E Jonas, and J Tenenbaum. Exact and Approximate Sampling by Systematic\\nStochastic Search. JMLR, 5:400?407, 2009.\\n[9] James Gary Propp and David Bruce Wilson. Exact Sampling with Coupled Markov Chains and Applications to Statistical Mechanics. Random Structures and Algorithms, 9(1-2):223?252, 1996.\\n[10] Antonietta Mira, Jesper Moller, and Gareth O Roberts. Perfect Slice Samplers. Journal of the Royal\\nStatistical Society: Series B (Statistical Methodology), 63(3):593?606, 2001.\\n[11] Faheem Mitha. Perfect Sampling on Continuous State Spaces. PhD thesis, University of North Carolina,\\nChapel Hill, 2003.\\n[12] Hannes Malmberg. Random Choice over a Continuous Set of Options. Master?s thesis, Department of\\nMathematics, Stockholm University, 2013.\\n[13] E. J. Gumbel and J. Lieblein. Statistical Theory of Extreme Values and Some Practical Applications: a\\nSeries of Lectures. US Govt. Print. Office, 1954.\\n[14] John I. Yellott Jr. The Relationship between Luce?s Choice Axiom, Thurstone?s Theory of Comparative\\nJudgment, and the Double Exponential Distribution. Journal of Mathematical Psychology, 15(2):109 ?\\n144, 1977.\\n[15] Thomas P Minka. Expectation Propagation for Approximate Bayesian Inference. In UAI, pages 362?369.\\nMorgan Kaufmann Publishers Inc., 2001.\\n[16] Eldon Hansen and G William Walster. Global Optimization Using Interval Analysis: Revised and Expanded, volume 264. CRC Press, 2003.\\n[17] Dmitrey Kroshko. FuncDesigner. http://openopt.org/FuncDesigner, June 2014.\\n[18] Radford M Neal. Slice Sampling. Annals of Statistics, pages 705?741, 2003.\\n[19] Tamir Hazan, Subhransu Maji, and Tommi Jaakkola. On Sampling from the Gibbs Distribution with\\nRandom Maximum A-Posteriori Perturbations. In NIPS, pages 1268?1276. 2013.\\n[20] Robert Eugeniu Mateescu. AND/OR Search Spaces for Graphical Models. PhD thesis, University of\\nCalifornia, 2007.\\n[21] Manmohan Chandraker and David Kriegman. Globally Optimal Bilinear Programming for Computer\\nVision Applications. In CVPR, pages 1?8, 2008.\\n\\n9\\n\\n\\f\",\n          \"Learning with ensembles: How\\nover-fitting can be useful\\n\\nPeter Sollich\\nDepartment of Physics\\nUniversity of Edinburgh, U.K.\\nP.SollichGed.ac.uk\\n\\nAnders Krogh'\\\"\\nNORDITA, Blegdamsvej 17\\n2100 Copenhagen, Denmark\\nkroghGsanger.ac.uk\\n\\nAbstract\\nWe study the characteristics of learning with ensembles. Solving\\nexactly the simple model of an ensemble of linear students, we\\nfind surprisingly rich behaviour. For learning in large ensembles,\\nit is advantageous to use under-regularized students, which actually over-fit the training data. Globally optimal performance can\\nbe obtained by choosing the training set sizes of the students appropriately. For smaller ensembles, optimization of the ensemble\\nweights can yield significant improvements in ensemble generalization performance, in particular if the individual students are subject to noise in the training process. Choosing students with a wide\\nrange of regularization parameters makes this improvement robust\\nagainst changes in the unknown level of noise in the training data.\\n\\n1\\n\\nINTRODUCTION\\n\\nAn ensemble is a collection of a (finite) number of neural networks or other types\\nof predictors that are trained for the same task. A combination of many different predictors can often improve predictions, and in statistics this idea has been\\ninvestigated extensively, see e.g. [1, 2, 3]. In the neural networks community, ensembles of neural networks have been investigated by several groups, see for instance\\n[4, 5, 6, 7]. Usually the networks in the ensemble are trained independently and\\nthen their predictions are combined.\\nIn this paper we study an ensemble of linear networks trained on different but\\noverlapping training sets. The limit in which all the networks are trained on the\\nfull data set and the one where all the data sets are different has been treated in\\n[8] . In this paper we treat the case of intermediate training set sizes and overlaps\\n?Present address: The Sanger Centre, Hinxton, Cambs CBIO IRQ, UK.\\n\\n\\fLearning with Ensembles: How Overfitting Can Be Useful\\n\\n191\\n\\nexactly, yielding novel insights into ensemble learning. Our analysis also allows us to\\nstudy the effect of regularization and of having different predictors in an ensemble.\\n\\n2\\n\\nGENERAL FEATURES OF ENSEMBLE LEARNING\\n\\nWe consider the task of approximating a target function fo from RN to R. It\\nwill be assumed that we can only obtain noisy samples of the function, and the\\n(now stochastic) target function will be denoted y(x) . The inputs x are taken\\nto be drawn from some distribution P(x). Assume now that an ensemble of K\\nindependent predictors fk(X) of y(x) is available. A weighted ensemble average is\\ndenoted by a bar, like\\n(1)\\nlex) = L,wkfk(X),\\nk\\n\\nwhich is the final output of the ensemble. One can think of the weight Wk as the\\nbelief in predictor k and we therefore constrain the weights to be positive and sum\\nto one. For an input x we define the error of the ensemble c(x), the error of the\\nkth predictor ck(X), and its ambiguity ak(x)\\nc(x)\\nck(X)\\n\\n(y(x) -lex)?\\n(y(x) - fk(X)?\\n(fk(X) -1(x?2.\\n\\n=\\n\\n(2)\\n(3)\\n(4)\\n\\n=\\n\\nThe ensemble error can be written as c(x)\\nlex) - a(x) [7], where lex)\\nL,k Wkck(X) is the average error over the individual predictors and a(x) =\\nL,k Wkak(X) is the average of their ambiguities, which is the variance of the output\\nover the ensemble. By averaging over the input distribution P(x) (and implicitly\\nover the target outputs y(x?, one obtains the ensemble generalization error\\n(5)\\nwhere c(x) averaged over P(x) is simply denoted c, and similarly for land a. The\\nfirst term on the right is the weighted average of the generalization errors of the individual predictors, and the second is the weighted average of the ambiguities, which\\nwe refer to as the ensemble ambiguity. An important feature of equation (5) is that\\nit separates the generalization error into a term that depends on the generalization\\nerrors of the individual students and another term that contains all correlations between the students. The latter can be estimated entirely from unlabeled data, i. e.,\\nwithout any knowledge of the target function to be approximated. The relation (5)\\nalso shows that the more the predictors differ, the lower the error will be, provided\\nthe individual errors remain constant.\\n\\nIn this paper we assume that the predictors are trained on a sample of p examples\\nof the target function, (xt',yt'), where yt' = fo(xt') + TJt' and TJt' is some additive\\nnoise (Jl. = 1, ... ,p). The predictors, to which we refer as students in this context\\nbecause they learn the target function from the training examples, need not be\\ntrained on all the available data. In fact, since training on different data sets will\\ngenerally increase the ambiguity, it is possible that training on subsets of the data\\nwill improve generalization. An additional advantage is that, by holding out for\\neach student a different part of the total data set for the purpose of testing, one\\ncan use the whole data set for training the ensemble while still getting an unbiased\\nestimate of the ensemble generalization error. Denoting this estimate by f, one has\\n(6)\\nwhere Ctest = L,k WkCtest,k is the average of the students' test errors. As already\\npointed out, the estimate ft of the ensemble ambiguity can be found from unlabeled\\ndata.\\n\\n\\fP. SOLLICH, A. KROGH\\n\\n192\\n\\nSo far, we have not mentioned how to find the weights Wk. Often uniform weights\\nare used, but optimization of the weights in some way is tempting. In [5, 6] the\\ntraining set was used to perform the optimization, i.e., the weights were chosen to\\nminimize the ensemble training error. This can easily lead to over-fitting, and in [7]\\nit was suggested to minimize the estimated generalization error (6) instead. If this\\nis done, the estimate (6) acquires a bias; intuitively, however, we expect this effect\\nto be small for large ensembles.\\n\\n3\\n\\nENSEMBLES OF LINEAR STUDENTS\\n\\nIn preparation for our analysis of learning with ensembles of linear students we now\\nbriefly review the case of a single linear student, sometimes referred to as 'linear\\nperceptron learning'. A linear student implements the input-output mapping\\n1 T\\nJ(x) = ..JNw x\\nparameterized in terms of an N-dimensional parameter vector w with real components; the scaling factor 1/..JN is introduced here for convenience, and . ..T denotes\\nthe transpose of a vector. The student parameter vector w should not be confused with the ensemble weights Wk. The most common method for training such\\na linear student (or parametric inference models in general) is minimization of the\\nsum-of-squares training error\\nE = L:(y/J - J(x/J))2 + Aw2\\n/J\\nwhere J.L = 1, ... ,p numbers the training examples. To prevent the student from\\nfitting noise in the training data, a weight decay term Aw2 has been added. The size\\nof the weight decay parameter A determines how strongly large parameter vectors\\nare penalized; large A corresponds to a stronger regularization of the student.\\nFor a linear student, the global minimum of E can easily be found. However,\\nin practical applications using non-linear networks, this is generally not true, and\\ntraining can be thought of as a stochastic process yielding a different solution each\\ntime. We crudely model this by considering white noise added to gradient descent\\nupdates of the parameter vector w. This yields a limiting distribution of parameter\\nvectors P(w) ex: exp(-E/2T), where the 'temperature' T measures the amount of\\nnoise in the training process.\\nWe focus our analysis on the 'thermodynamic limit' N - t 00 at constant normalized\\nnumber of training examples, ex = p/N. In this limit, quantities such as the training\\nor generalization error become self-averaging, i.e., their averages over all training\\nsets become identical to their typical values for a particular training set. Assume\\nnow that the training inputs x/J are chosen randomly and independently from a\\nGaussian distribution P(x) ex: exp( - ~x2), and that training outputs are generated\\nby a linear target function corrupted by additive noise, i.e., y/J = w'f x/J /..IN + 1]/J,\\nwhere the 1]/J are zero mean noise variables with variance u 2 ? Fixing the length of the\\nparameter vector of the target function to w~ = N for simplicity, the generalization\\nerror of a linear student with weight decay A and learning noise T becomes [9]\\n(; = (u 2 + T)G + A(U 2\\n\\n-\\n\\n8G\\n\\nA) 8A .\\n\\n(7)\\n\\nOn the r.h.s. of this equation we have dropped the term arising from the noise on\\nthe target function alone, which is simply u 2 , and we shall follow this convention\\nthroughout . The 'response function' Gis [10, 11]\\n\\nG = G(ex, A) = (1 - ex - A+ )(1 - ex - A)2 + 4A)/2A.\\n\\n(8)\\n\\n\\f193\\n\\nLearning with Ensembles: How Overfitting Can Be Useful\\n\\nFor zero training noise, T = 0, and for any a, the generalization error (7} is minimized when the weight decay is set to A = (T2j its value is then (T2G(a, (T2), which\\nis the minimum achievable generalization error [9].\\n\\n3.1\\n\\nENSEMBLE GENERALIZATION ERROR\\n\\nWe now consider an ensemble of K linear students with weight decays Ak and\\nlearning noises Tk (k = 1 . . . K). Each ,student has an ensemble weight Wk and\\nis trained on N ak training examples, with students k and I sharing N akl training\\nexamples (of course, akk = ak). As above, we consider noisy training data generated\\nby a linear target function. The resulting ensemble generalization error can be\\ncalculated by diagrammatic [10] or response function [11] methods. We refer the\\nreader to a forthcoming publication for details and only state the result:\\n\\n(9)\\nwhere\\n(10)\\nHere Pk is defined as Pk = AkG(ak, Ak). The Kronecker delta in the last term\\nof (10) arises because the training noises of different students are uncorrelated. The\\ngeneralization errors and ambiguities of the individual students are\\n\\nak = ckk - 2 LWlckl\\nI\\n\\n+ LWIWmclm;\\n1m\\n\\nthe result for the Ck can be shown to agree with the single student result (7). In\\nthe following sections, we shall explore the consequences of the general result (9) .\\nWe will concentrate on the case where the training set of each student is sampled\\nrandomly from the total available data set of size NO', For the overlap of the training\\nsets of students k and I (k 'II) one then has akl/a = (ak/a)(al/a) and hence\\n\\nak/ = akal/a\\n\\n(11)\\nup to fluctuations which vanish in the thermodynamic limit. For finite ensembles\\none can construct training sets for which akl < akal/a. This is an advantage,\\nbecause it results in a smaller generalization error, but for simplicity we use (11).\\n\\n4\\n\\nLARGE ENSEMBLE LIMIT\\n\\nWe now use our main result (9) to analyse the generalization performance of an ensemble with a large number K of students, in particular when the size of the training\\nsets for the individual students are chosen optimally. If the ensemble weights Wk\\nare approximately uniform (Wk ~ 1/ K) the off-diagonal elements of the matrix\\n(ckl) dominate the generalization error for large K, and the contributions from the\\ntraining noises\\nare suppressed. For the special case where all students are identical and are trained on training sets of identical size, ak = (1 - c)a, the ensemble\\ngeneralization error is shown in Figure 1(left). The minimum at a nonzero value\\nof c, which is the fraction of the total data set held out for testing each student,\\ncan clearly be seen. This confirms our intuition: when the students are trained\\non smaller, less overlapping training sets, the increase in error of the individual\\nstudents can be more than offset by the corresponding increase in ambiguity.\\n\\nn\\n\\nThe optimal training set sizes ak can be calculated analytically:\\n_\\n\\nCk\\n\\n=1-\\n\\nak/ a\\n\\n1 - Ak/(T2\\n\\n= 1 + G(a, (T2) '\\n\\n(12)\\n\\n\\fP. SOLLICH, A. KROGH\\n\\n194\\n1.0 r - - - , - - - - - , r - - - . , - - - - , . - - - - : .\\n\\n1.0 r - - - , - - - - - , - - - . - - - - r - - - - \\\"\\n\\n0.8\\n\\n0.8\\n\\n0.6\\n\\n0.6\\n\\nw\\n\\n.'\\n\\nw\\n0.4\\n\\n,...-------\\n\\n0.2\\n/\\n\\n/\\n\\n0.0 /\\n\\n0.0\\n\\n/\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\n,,\\n,\\n0.8\\n\\n0.2\\n\\n------,\\n\\n1.0\\n\\n0.0\\n\\n0.0\\n\\nC\\n\\n...\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\n0.8\\n\\n1.0\\n\\nC\\n\\nFigure 1: Generalization error and ambiguity for an infinite ensemble of identical\\nstudents. Solid line: ensemble generalization error, fj dotted line: average generalization error of the individual students, l; dashed line: ensemble ambiguity, a.\\nFor both plots a = 1 and (72 = 0.2 . The left plot corresponds to under-regularized\\nstudents with A = 0.05 < (72. Here the generalization error of the ensemble has\\na minimum at a nonzero value of c. This minimum exists whenever>' < (72. The\\nright plot shows the case of over-regularized students (A = 0.3 > (72), where the\\ngeneralization error is minimal at c = O.\\nThe resulting generalization error is f = (72G(a, (72) + 0(1/ K), which is the globally\\nminimal generalization error that can be obtained using all available training data,\\nas explained in Section 3. Thus, a large ensemble with optimally chosen training\\nset sizes can achieve globally optimal generalization performance. However, we see\\nfrom (12) that a valid solution Ck > 0 exists only for Ak < (72, i.e., if the ensemble\\nis under-regularized. This is exemplified, again for an ensemble of identical students, in Figure 1(right) , which shows that for an over-regularized ensemble the\\ngeneralization error is a: monotonic function of c and thus minimal at c = o.\\nWe conclude this section by discussing how the adaptation of the training set sizes\\ncould be performed in practice, for simplicity confining ourselves to an ensemble of\\nidentical students, where only one parameter c = Ck = 1- ak/a has to be adapted.\\nIf the ensemble is under-regularized one expects a minimum of the generalization\\nerror for some nonzero c as in Figure 1. One could, therefore, start by training\\nall students on a large fraction of the total data set (corresponding to c ~ 0), and\\nthen gradually and randomly remove training examples from the students' training\\nsets. Using (6), the generalization error of each student could be estimated by\\ntheir performance on the examples on which they were not trained, and one would\\nstop removing training examples when the estimate stops decreasing. The resulting\\nestimate of the generalization error will be slightly biased; however, for a large\\nenough ensemble the risk of a strongly biased estimate from systematically testing\\nall students on too 'easy' training examples seems small, due to the random selection\\nof examples.\\n\\n5\\n\\nREALISTIC ENSEMBLE SIZES\\n\\nWe now discuss some effects that occur in learning with ensembles of 'realistic' sizes.\\nIn an over-regularized ensemble nothing can be gained by making the students more\\ndiverse by training them on smaller, less overlapping training sets. One would also\\n\\n\\f195\\n\\nLearning with Ensembles: How Overfitting Can Be Useful\\n\\nFigure 2: The generalization error of\\nan ensemble with 10 identical students as a function of the test set\\nfraction c. From bottom to top the\\ncurves correspond to training noise\\nT = 0,0.1,0.2, ... ,1.0. The star on\\neach curve shows the error of the optimal single perceptron (i. e., with optimal weight decay for the given T)\\ntrained on all examples, which is independent of c. The parameters for\\nthis example are: a = 1, A = 0.05,\\n0'2 = 0.2.\\n\\n0.2\\n0.0 L - _ - - ' - _ - - - '_ _-'--_--'-_~\\n0.0\\n0.2\\n0.4\\n0.6\\n0.8\\n1.0\\nC\\n\\nexpect this kind of 'diversification' to be unnecessary or even counterproductive\\nwhen the training noise is high enough to provide sufficient 'inherent' diversity of\\nstudents. In the large ensemble limit, we saw that this effect is suppressed, but\\nit does indeed occur in finite ensembles. Figure 2 shows the dependence of the\\ngeneralization error on c for an ensemble of 10 identical, under-regularized students\\nwith identical training noises Tk = T. For small T, the minimum of f. at nonzero c\\npersists. For larger T, f. is monotonically increasing with c, implying that further\\ndiversification of students beyond that caused by the learning noise is wasteful. The\\nplot also shows the performance of the optimal single student (with A chosen to\\nminimize the generalization error at the given T), demonstrating that the ensemble\\ncan perform significantly better by effectively averaging out learning noise.\\nFor realistic ensemble sizes the presence of learning noise generally reduces the\\npotential for performance improvement by choosing optimal training set sizes. In\\nsuch cases one can still adapt the ensemble weights to optimize performance, again\\non the basis of the estimate of the ensemble generalization error (6). An example is\\n1.0\\n\\n1.0\\n\\n,,\\n\\n0.8\\n\\nI\\nI\\n\\n0.8\\n,-\\n\\n,-\\n\\n/\\n\\nI\\n\\n0.6\\n\\n0.6\\n\\nI\\n\\ntV\\n\\ntV\\n\\n0.4 ..... -_ .................\\n\\n0.4\\n0.2\\n... ....\\n0.0\\n0.001\\n\\n---0.010\\n\\n0.2\\n\\n0.100\\n\\n02\\n\\n1.000\\n\\n0.0\\n0.001\\n\\n0.010\\n\\n02\\n\\n0.100\\n\\n1.000\\n\\nFigure 3: The generalization error of an ensemble of 10 students with different\\nweight decays (marked by stars on the 0'2-axis) as a function of the noise level\\n0'2. Left: training noise T = 0; right: T = 0.1. The dashed lines are for the\\nensemble with uniform weights, and the solid line is for optimized ensemble weights.\\nThe dotted lines are for the optimal single perceptron trained on all data. The\\nparameters for this example are: a = 1, c = 0.2.\\n\\n\\f196\\n\\nP. SOu...ICH, A. KROGH\\n\\nshown in Figure 3 for an ensemble of size 1< = 10 with the weight decays >'k equally\\nspaced on a logarithmic axis between 10- 3 and 1. For both of the temperatures T\\nshown, the ensemble with uniform weights performs worse than the optimal single\\nstudent. With weight optimization, the generalization performance approaches that\\nof the optimal single student for T = 0, and is actually better at T = 0.1 over\\nthe whole range of noise levels rr2 shown. Even the best single student from the\\nensemble can never perform better than the optimal single student, so combining the\\nstudent outputs in a weighted ensemble average is superior to simply choosing the\\nbest member of the ensemble by cross-validation, i.e., on the basis of its estimated\\ngeneralization error. The reason is that the ensemble average suppresses the learning\\nnoise on the individual students.\\n\\n6\\n\\nCONCLUSIONS\\n\\nWe have studied ensemble learning in the simple, analytically solvable scenario of\\nan ensemble of linear students. Our main findings are: In large ensembles, one\\nshould use under-regularized students in order to maximize the benefits of the\\nvariance-reducing effects of ensemble learning. In this way, the globally optimal\\ngeneralization error on the basis of all the available data can be reached by optimizing the training set sizes of the individual students. At the same time an estimate\\nof the generalization error can be obtained. For ensembles of more realistic size, we\\nfound that for students subjected to a large amount of noise in the training process\\nit is unnecessary to increase the diversity of students by training them on smaller,\\nless overlapping training sets. In this case, optimizing the ensemble weights can\\nstill yield substantially better generalization performance than an optimally chosen\\nsingle student trained on all data with the same amount of training noise. This\\nimprovement is most insensitive to changes in the unknown noise levels rr2 if the\\nweight decays of the individual students cover a wide range. We expect most of these\\nconclusions to carryover, at least qualitatively, to ensemble learning with nonlinear\\nmodels, and this correlates well with experimental results presented in [7].\\n\\nReferences\\n[1]\\n[2]\\n[3]\\n[4]\\n[5]\\n[6]\\n[7]\\n[8]\\n[9]\\n[10]\\n[11]\\n\\nC. Granger, Journal of Forecasting 8, 231 (1989).\\nD. Wolpert, Neural Networks 5, 241 (1992) .\\nL. Breimann, Tutorial at NIPS 7 and personal communication.\\nL. Hansen and P. Salamon, IEEE Trans. Pattern Anal. and Mach. Intell. 12,\\n993 (1990).\\nM. P. Perrone and L. N. Cooper, in Neural Networks for Speech and Image\\nprocessing, ed. R. J. Mammone (Chapman-Hall, 1993).\\nS. Hashem: Optimal Linear Combinations of Neural Networks. Tech. Rep .\\nPNL-SA-25166, submitted to Neural Networks (1995) .\\nA. Krogh and J. Vedelsby, in NIPS 7, ed. G. Tesauro et al., p. 231 (MIT Press,\\n1995).\\nR. Meir, in NIPS 7, ed. G. Tesauro et al., p. 295 (MIT Press, 1995).\\nA. Krogh and J. A. Hertz, J. Phys. A 25,1135 (1992).\\nJ. A. Hertz, A. Krogh, and G. I. Thorbergsson, J. Phys. A 22, 2133 (1989).\\nP. Sollich, J. Phys. A 27, 7771 (1994).\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["papers = papers.drop(columns=['id', 'event_type', 'pdf_name'], axis=1)"],"metadata":{"id":"OeNc9BZDfBuW","executionInfo":{"status":"ok","timestamp":1751185040882,"user_tz":-330,"elapsed":44,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["papers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"o1PqBrizf97e","executionInfo":{"status":"ok","timestamp":1751185044412,"user_tz":-330,"elapsed":1881,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"4d30a479-0d54-412a-e2ac-6add35d478be"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      year                                              title  \\\n","0     1987  Self-Organization of Associative Database and ...   \n","1     1987  A Mean Field Theory of Layer IV of Visual Cort...   \n","2     1988  Storing Covariance by the Associative Long-Ter...   \n","3     1994  Bayesian Query Construction for Neural Network...   \n","4     1994  Neural Network Ensembles, Cross Validation, an...   \n","...    ...                                                ...   \n","7236  1994                Single Transistor Learning Synapses   \n","7237  1994  Bias, Variance and the Combination of Least Sq...   \n","7238  1994          A Real Time Clustering CMOS Neural Engine   \n","7239  1994  Learning direction in global motion: two class...   \n","7240  1994  Correlation and Interpolation Networks for Rea...   \n","\n","              abstract                                         paper_text  \n","0     Abstract Missing  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n","1     Abstract Missing  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n","2     Abstract Missing  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n","3     Abstract Missing  Bayesian Query Construction for Neural\\nNetwor...  \n","4     Abstract Missing  Neural Network Ensembles, Cross\\nValidation, a...  \n","...                ...                                                ...  \n","7236  Abstract Missing  Single Transistor Learning Synapses\\n\\nPaul Ha...  \n","7237  Abstract Missing  Bias, Variance and the Combination of\\nLeast S...  \n","7238  Abstract Missing  A Real Time Clustering CMOS\\nNeural Engine\\nT....  \n","7239  Abstract Missing  Learning direction in global motion: two\\nclas...  \n","7240  Abstract Missing  Correlation and Interpolation Networks for\\nRe...  \n","\n","[7241 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-ba5d183e-23da-4311-9a16-35960b97f86e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>paper_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1987</td>\n","      <td>Self-Organization of Associative Database and ...</td>\n","      <td>Abstract Missing</td>\n","      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1987</td>\n","      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n","      <td>Abstract Missing</td>\n","      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1988</td>\n","      <td>Storing Covariance by the Associative Long-Ter...</td>\n","      <td>Abstract Missing</td>\n","      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1994</td>\n","      <td>Bayesian Query Construction for Neural Network...</td>\n","      <td>Abstract Missing</td>\n","      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1994</td>\n","      <td>Neural Network Ensembles, Cross Validation, an...</td>\n","      <td>Abstract Missing</td>\n","      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7236</th>\n","      <td>1994</td>\n","      <td>Single Transistor Learning Synapses</td>\n","      <td>Abstract Missing</td>\n","      <td>Single Transistor Learning Synapses\\n\\nPaul Ha...</td>\n","    </tr>\n","    <tr>\n","      <th>7237</th>\n","      <td>1994</td>\n","      <td>Bias, Variance and the Combination of Least Sq...</td>\n","      <td>Abstract Missing</td>\n","      <td>Bias, Variance and the Combination of\\nLeast S...</td>\n","    </tr>\n","    <tr>\n","      <th>7238</th>\n","      <td>1994</td>\n","      <td>A Real Time Clustering CMOS Neural Engine</td>\n","      <td>Abstract Missing</td>\n","      <td>A Real Time Clustering CMOS\\nNeural Engine\\nT....</td>\n","    </tr>\n","    <tr>\n","      <th>7239</th>\n","      <td>1994</td>\n","      <td>Learning direction in global motion: two class...</td>\n","      <td>Abstract Missing</td>\n","      <td>Learning direction in global motion: two\\nclas...</td>\n","    </tr>\n","    <tr>\n","      <th>7240</th>\n","      <td>1994</td>\n","      <td>Correlation and Interpolation Networks for Rea...</td>\n","      <td>Abstract Missing</td>\n","      <td>Correlation and Interpolation Networks for\\nRe...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7241 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba5d183e-23da-4311-9a16-35960b97f86e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ba5d183e-23da-4311-9a16-35960b97f86e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ba5d183e-23da-4311-9a16-35960b97f86e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-6ce12c35-ff4f-411f-bba3-19e5fc7a2f01\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ce12c35-ff4f-411f-bba3-19e5fc7a2f01')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-6ce12c35-ff4f-411f-bba3-19e5fc7a2f01 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_2ce88e6c-6aeb-4ea1-8d93-197821981e92\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('papers')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2ce88e6c-6aeb-4ea1-8d93-197821981e92 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('papers');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"papers","summary":"{\n  \"name\": \"papers\",\n  \"rows\": 7241,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1987,\n        \"max\": 2017,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          1992,\n          1990,\n          2012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7241,\n        \"samples\": [\n          \"Independent Component Analysis for Identification of Artifacts in Magnetoencephalographic Recordings\",\n          \"Near-Maximum Entropy Models for Binary Neural Representations of Natural Images\",\n          \"Nearest-Neighbor Sample Compression: Efficiency, Consistency, Infinite Dimensions\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3923,\n        \"samples\": [\n          \"Recommendation for e-commerce with a mix of durable and nondurable goods has characteristics that distinguish it from the well-studied media recommendation problem. The demand for items is a combined effect of form utility and time utility, i.e., a product must both be intrinsically appealing to a consumer and the time must be right for purchase. In particular for durable goods, time utility is a function of inter-purchase duration within product category because consumers are unlikely to purchase two items in the same category in close temporal succession. Moreover, purchase data, in contrast to ratings data, is implicit with non-purchases not necessarily indicating dislike. Together, these issues give rise to the positive-unlabeled demand-aware recommendation problem that we pose via joint low-rank tensor completion and product category inter-purchase duration vector estimation. We further relax this problem and propose a highly scalable alternating minimization approach with which we can solve problems with millions of users and millions of items in a single thread. We also show superior prediction accuracies on multiple real-world data sets.\",\n          \"Stochastic Neighbor Embedding (SNE) has shown to be quite promising for data visualization.  Currently, the most popular implementation, t-SNE, is restricted to a particular Student t-distribution as its embedding distribution. Moreover, it uses a gradient descent algorithm that may require users to tune parameters such as the learning step size, momentum, etc., in finding its optimum. In this paper, we propose the Heavy-tailed Symmetric Stochastic Neighbor Embedding (HSSNE) method, which is a generalization of the t-SNE to accommodate various heavy-tailed embedding similarity functions. With this generalization, we are presented with two difficulties.  The first is how to select the best embedding similarity among all heavy-tailed functions and the second is how to optimize the objective function once the heave-tailed function has been selected. Our contributions then are: (1) we point out that various heavy-tailed embedding similarities can be characterized by their negative score functions. Based on this finding, we present a parameterized subset of similarity functions for choosing the best tail-heaviness for HSSNE; (2) we present a fixed-point optimization algorithm that can be applied to all heavy-tailed functions and does not require the user to set any parameters; and (3) we present two empirical studies, one for unsupervised visualization showing that our optimization algorithm runs as fast and as good as the best known t-SNE implementation and the other for semi-supervised visualization showing quantitative superiority using the homogeneity measure as well as qualitative advantage in cluster separation over t-SNE.\",\n          \"Adaptive schemes, where tasks are assigned based on the data collected thus far, are widely used in practical crowdsourcing systems to efficiently allocate the budget. However, existing theoretical analyses of crowdsourcing systems suggest that the gain of adaptive task assignments is minimal. To bridge this gap, we investigate this question under a strictly more general probabilistic model, which has been recently introduced to model practical crowdsourcing data sets. Under this generalized Dawid-Skene model, we characterize the fundamental trade-off between budget and accuracy, and introduce a novel adaptive scheme that matches this fundamental limit. We further quantify the gain of adaptivity, by comparing the trade-off with the one for non-adaptive schemes, and confirm that the gain is significant and can be made arbitrarily large depending on the distribution of the difficulty level of the tasks at hand.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7237,\n        \"samples\": [\n          \"Statistical Performance of Convex Tensor\\nDecomposition\\nRyota Tomioka?\\nTaiji Suzuki?\\nDepartment of Mathematical Informatics,\\nThe University of Tokyo\\nTokyo 113-8656, Japan\\ntomioka@mist.i.u-tokyo.ac.jp\\ns-taiji@stat.t.u-tokyo.ac.jp\\n\\nKohei Hayashi?\\nGraduate School of Information Science,\\nNara Institute of Science and Technology\\nNara 630-0192, Japan\\nkohei-h@is.naist.jp\\n\\n?\\n\\n?\\n\\nHisashi Kashima?,?\\nBasic Research Programs PRESTO,\\nSynthesis of Knowledge for Information Oriented Society, JST\\nTokyo 102-8666, Japan\\nkashima@mist.i.u-tokyo.ac.jp\\n?\\n\\nAbstract\\nWe analyze the statistical performance of a recently proposed convex tensor decomposition algorithm. Conventionally tensor decomposition has been formulated as non-convex optimization problems, which hindered the analysis of their\\nperformance. We show under some conditions that the mean squared error of\\nthe convex method scales linearly with the quantity we call the normalized rank\\nof the true tensor. The current analysis naturally extends the analysis of convex\\nlow-rank matrix estimation to tensors. Furthermore, we show through numerical\\nexperiments that our theory can precisely predict the scaling behaviour in practice.\\n\\n1 Introduction\\nTensors (multi-way arrays) generalize matrices and naturally represent data having more than two\\nmodalities. For example, multi-variate time-series, for instance, electroencephalography (EEG),\\nrecorded from multiple subjects under various conditions naturally form a tensor. Moreover, in\\ncollaborative ?ltering, users? preferences on products, conventionally represented as a matrix, can\\nbe represented as a tensor when the preferences change over time or context.\\nFor the analysis of tensor data, various models and methods for the low-rank decomposition of\\ntensors have been proposed (see Kolda & Bader [12] for a recent survey). These techniques have\\nrecently become increasingly popular in data-mining [1, 14] and computer vision [25, 26]. Besides\\nthey have proven useful in chemometrics [4], psychometrics [24], and signal processing [20, 7, 8].\\nDespite empirical success, the statistical performance of tensor decomposition algorithms has not\\nbeen fully elucidated. The dif?culty lies in the non-convexity of the conventional tensor decomposition algorithms (e.g., alternating least squares [6]). In addition, studies have revealed many\\ndiscrepancies (see [12]) between matrix rank and tensor rank, which make extension of studies on\\nthe performance of low-rank matrix models (e.g., [9]) challenging.\\nRecently, several authors [21, 10, 13, 23] have focused on the notion of tensor mode-k rank (instead\\nof tensor rank), which is related to the Tucker decomposition [24]. They discovered that regularized\\nestimation based on the Schatten 1-norm, which is a popular technique for recovering low-rank\\nmatrices via convex optimization, can also be applied to tensor decomposition. In particular, the\\n1\\n\\n\\fConvex\\nTucker (exact)\\nOptimization tolerance\\n\\n0\\n\\n10\\n\\n?3\\n\\n10\\n\\n0\\n\\n0.2\\n0.4\\n0.6\\n0.8\\nFraction of observed elements\\n\\n1\\n\\nFigure 1: Result of estimation of rank-(7, 8, 9) tensor of dimensions\\n50???? 50 ? 20 from partial\\n???\\n? ? W ? ??? is plotted against the\\nmeasurements; see [23] for the details. The estimation error ???W\\nF\\nfraction of observed elements m = M/N . Error bars over 10 repetitions are also shown. Convex\\nrefers to the convex tensor decomposition based on the minimization problem (7). Tucker (exact)\\nrefers to the conventional (non-convex) Tucker decomposition [24] at the correct rank. Gray dashed\\nline shows the optimization tolerance 10?3 . The question is how we can predict the point where the\\ngeneralization begins (roughly m = 0.35 in this plot).\\n\\nstudy in [23] showed that there is a clear transition at certain number of samples where the error\\ndrops dramatically from no generalization to perfect generalization (see Figure 1).\\nIn this paper, motivated by the above recent work, we mathematically analyze the performance of\\nconvex tensor decomposition. The new convex formulation for tensor decomposition allows us to\\ngeneralize recent results on Schatten 1-norm-regularized estimation of matrices (see [17, 18, 5, 19]).\\nUnder a general setting we show how the estimation error scales with the mode-k ranks of the true\\ntensor. Furthermore, we analyze the speci?c settings of (i) noisy tensor decomposition and (ii)\\nrandom Gaussian design. In the ?rst setting, we assume that all the elements of a low-rank tensor\\nis observed with noise and the goal is to recover the underlying low-rank structure. This is the most\\ncommon setting a tensor decomposition algorithm is used. In the second setting, we assume that\\nthe unknown tensor is a coef?cient of a tensor-input scalar-output regression problem and the input\\ntensors (design) are randomly given from independent Gaussian distributions. Surprisingly, it turns\\nout that the random Gaussian setting can precisely predict the phase-transition-like behaviour in\\nFigure 1. To the best of our knowledge, this is the ?rst paper that rigorously studies the performance\\nof a tensor decomposition algorithm.\\n\\n2\\n\\nNotation\\n\\nIn this section, we introduce the notations we use in this paper. Moreover, we introduce a H?olderlike inequality (3) and the notion of mode-k decomposability (5), which play central roles in our\\nanalysis.\\nQK\\nLet X ? Rn1 ????nK be a K-way tensor. We denote the number of elements in X by N = k=1 nk .\\n?\\nThe inner product between two tensors ?W, X ? is de?ned as ?W, X ? = vec(W)\\np ), where\\n??? ??? vec(X\\nvec is a vectorization. In addition, we de?ne the Frobenius norm of a tensor ???X ???F = ?X , X ?.\\nQ\\nThe mode-k unfolding X (k) is the nk ? n\\n? \\\\k (?\\nn\\\\k := k? ?=k nk? ) matrix obtained by concatenating\\nthe mode-k ?bers (the vectors obtained by ?xing every index of X but the kth index) of X as column\\nvectors. The mode-k rank of a tensor X , denoted by rankk (X ), is the rank of the mode-k unfolding\\nX (k) (as a matrix). Note that when K = 2 and X is actually a matrix, and X (2) = X (1) ? . We say\\na tensor X is rank (r1 , . . . , rK ) when rk = rankk (X ) for k = 1, . . . , K. Note that the mode-k rank\\ncan be computed in a polynomial time, because it boils down to computing a matrix rank, whereas\\ncomputing tensor rank is NP complete [11]. See [12] for more details.\\nSince for each k, the convex envelope of the mode-k rank is given as the Schatten 1-norm [18]\\n(known as the trace norm [22] or the nuclear norm [3]), it is natural to consider the following\\n2\\n\\n\\f??? ???\\noverlapped Schatten 1-norm ???W ???S of a tensor W ? Rn1 ?????nK (see also [21]):\\n1\\n\\n??? ???\\n???W ???\\n\\nS1\\n\\n=\\n\\nK\\n?\\n1 X?\\n?W (k) ? ,\\nS1\\nK\\n\\n(1)\\n\\nk=1\\n\\nwhere W (k) is the mode-k unfolding of W. Here ? ? ?S1 is the Schatten 1-norm for a matrix\\nXr\\n?W ?S1 =\\n?j (W ),\\nj=1\\n\\nwhere ?j (W ) is the jth largest singular-value of W . The dual norm of the Schatten 1-norm is the\\nSchatten ?-norm (known as the spectral norm) as follows:\\n?X?S? = max ?j (X).\\nj=1,...,r\\n\\nSince the two norms ? ? ?S1 and ? ? ?S? are dual to each other, we have the following inequality:\\n|?W , X?| ? ?W ?S1 ?X?S? ,\\n(2)\\nwhere ?W , X? is the inner product of W and X.\\nThe same inequality holds for the overlapped Schatten 1-norm (1) and its dual norm. The dual norm\\nof the overlapped Schatten 1-norm can be characterized by the following lemma.\\n??? ???\\nLemma 1. The dual norm of the overlapped Schatten 1-norm denoted as ???????S ? is de?ned as the\\n1\\nin?mum of the maximum mode-k spectral norm over the tensors whose average equals the given\\ntensor X as follows:\\n??? ???\\n(k)\\n???X ??? ? =\\nmax ?Y (k) ?S? ,\\ninf\\nS1\\n1\\n(1) +Y (2) +???+Y (K) =X\\nk=1,...,K\\nY\\n(\\n)\\nK\\n(k)\\n\\nwhere Y (k) is the mode-k unfolding of Y (k) . Moreover, the following upper bound on the dual norm\\n??? ???\\n??????? ? is valid:\\nS1\\n\\n??? ???\\n???X ???\\n\\nS1?\\n\\n??? ???\\n1 XK\\n?X (k) ?S? .\\n? ???X ???mean :=\\nk=1\\nK\\n\\n??? ???\\nProof. The ?rst part can be shown by solving the dual of the maximization problem ???X ???S ? :=\\n1\\n??? ???\\nsup ?W, X ? s.t. ???W ???S1 ? 1. The second part is obtained by setting Y (k) = PK K1/c ? X /ck ,\\nwhere ck = ?X (k) ?S? , and using Jensen?s inequality.\\n\\nk? =1\\n\\nk\\n\\nAccording to Lemma 1, we have the ??following\\n? ??? ??? H?\\n?o??lder-like\\n??? inequality\\n??? ??? ???\\n|?W, X ?| ? ???W ???S1 ???X ???S ? ? ???W ???S1 ???X ???mean .\\n\\n(3)\\n??? ??? ??? ???\\nNote that the above bound is tighter than the more intuitive relation | ?W, X ? | ? ???W ???S ???X ???S\\n1\\n?\\n??? ???\\n(???X ???S? := max1,...,K ?X (k) ?S? ), which one might come up as an analogy to the matrix case (2).\\n1\\n\\nFinally, let W ? ? Rn1 ?????nK be the low-rank tensor that we wish to recover. We assume that W ?\\nis rank (r1 , . . . , rK ). Thus, for each k we have\\nW ?(k) = U k S k V k\\n(k = 1, . . . , K),\\nwhere U k ? Rnk ?rk and V k ? Rn? \\\\k ?rk are orthogonal, and S k ? Rrk ?rk is diagonal. Let\\n? ? Rn1 ?????nK be an arbitrary tensor. We de?ne the mode-k orthogonal complement ???k of an\\nunfolding ?(k) ? Rnk ??n\\\\k of ? with respect to the true low-rank tensor W ? as follows:\\n??k\\n\\n???k = (I nk ? U k U k ? )?(k) (I n? \\\\k ? V k V k ? ).\\n\\n(4)\\n\\n:= ?(k) ? ???k is\\nthe true tensor W ?(k) .\\n\\nIn addition\\nthe component having overlapped row/column space with the\\nunfolding of\\nNote that the decomposition ?(k) = ??k + ???k is de?ned for\\neach mode; thus we use subscript k instead of (k).\\nUsing the decomposition de?ned above we have the following equality, which we call mode-k decomposability of the Schatten 1-norm:\\n?W ?(k) + ???k ?S1 = ?W ?(k) ?S1 + ????k ?S1 (k = 1, . . . , K).\\n(5)\\nThe above decomposition is de?ned for each mode and thus it is weaker than the notion of decomposability discussed by Negahban et al. [15].\\n3\\n\\n\\f3\\n\\nTheory\\n\\nIn this section, we ?rst present a deterministic result that holds under a certain choice of regularization constant ?M and an assumption called the restricted strong convexity. Then, we focus on\\nspecial cases to justify the choice of regularization constant and the restricted strong convexity assumption. We analyze the setting of (i) noisy tensor decomposition and (ii) random Gaussian design\\nin Section 3.2 and Section 3.3, respectively.\\n3.1\\n\\nMain result\\n\\nOur goal is to estimate an unknown rank (r1 , . . . , rK ) tensor W ? ? Rn1 ????nK from observations\\nyi = ?Xi , W ? ? + ?i (i = 1, . . . , M ).\\n(6)\\nHere the noise ?i follows the independent zero-mean Gaussian distribution with variance ? 2 .\\nWe employ the regularized empirical risk minimization problem proposed in [21, 10, 13, 23] for the\\nestimation of W as follows:\\n??? ???\\n1\\nminimize\\n?y ? X(W)?22 + ?M ???W ???S1 ,\\n(7)\\nn\\n?????n\\n1\\nK\\n2M\\nW?R\\nwhere y = (y1 , . . . , yM )? is the collection of observations; X : Rn1 ?????nK ? RM is a linear\\noperator that maps W to the M dimensional output vector X(W) = (?X1 , W? , . . . , ?XM , W?) ? ?\\nRM . The Schatten 1-norm term penalizes every mode of W to be jointly low-rank (see Equation (1));\\n?M > 0 is the regularization constant. Accordingly, the solution of the minimization problem (7) is\\ntypically a low-rank tensor when ?M is suf?ciently large. In addition, we denote the adjoint operator\\nPM\\nof X as X? : RM ? Rn1 ?????nK ; that is X? (?) = i=1 ?i Xi ? Rn1 ?????nK .\\n? ? W?\\nThe ?rst step in our analysis is to characterize the particularity of the residual tensor ? := W\\nas in the following lemma.\\n???\\n???\\n? be the solution of the minimization problem (7) with ?M ? 2???X? (?)???\\nLemma 2. Let W\\n/M ,\\nmean\\n? ? W ? , where W ? is the true low-rank tensor. Let ?(k) = ?? + ??? be the\\nand let ? := W\\nk\\nk\\ndecomposition de?ned in Equation (4). Then we have the following inequalities:\\n1. rank(??k ) ? 2rk for each k = 1, . . . , K.\\nPK\\nPK\\n?\\n??\\n2.\\nk=1 ??k ?S1 .\\nk=1 ??k ?S1 ? 3\\nProof. The proof uses the mode-k decomposability (5) and is analogous to that of Lemma 1 in\\n[17].\\nThe second ingredient of our analysis is the restricted strong convexity. Although, ?strong? may\\nsound like a strong assumption, the point is that we require this assumption to hold only for the\\nparticular residual tensor we characterized in Lemma 2. The assumption can be stated as follows.\\nAssumption 1 (Restricted strong convexity). We suppose that there is a positive constant ?(X) such\\nthat the operator X satis?es the inequality\\n??? ???2\\n1\\n?X(?)?22 ??(X)???????F ,\\n(8)\\nM\\nPK\\nfor all ? ? Rn1 ?????nK such that for each k = 1, . . . , K, rank(??k ) ? 2rk and k=1 ????k ?S1 ?\\nPK\\n3 k=1 ???k ?S1 , where ??k and ???k are de?ned through the decomposition (4).\\nNow using the above two ingredients, we are ready to prove the following deterministic guarantee\\non the performance of the estimation procedure (7).\\n???\\n???\\n? be the solution of the minimization problem (7) with ?M ? 2???X? (?)???\\nTheorem 1. Let W\\n/M .\\nmean\\nSuppose that the operator X satis?es the restricted strong convexity condition. Then the following\\nbound is true:\\nPK ?\\n???\\n???\\n? ? W ? ??? ? 32?M k=1 rk .\\n???W\\n(9)\\nF\\n?(X)K\\n4\\n\\n\\f? ? W ? . Combining the fact that the objective value for W\\n?\\nProof. Let ? = W\\n??? ? ???\\n??? is??smaller\\n?\\n??than\\n? ??? that for\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\n?\\nW , the H?older-like inequality (3), the triangular inequality W S ? W S ? ?????S , and\\n1\\n1\\n1\\n???\\n???\\nthe assumption ???X? (?)/M ???\\n? ?M /2, we obtain\\nmean\\n\\n??? ???\\n???\\n???\\n??? ???\\n??? ???\\n1\\n(10)\\n?X(?)?22 ? ???X? (?)/M ???mean ???????S1 + ?M ???????S1 ? 2?M ???????S1 .\\n2M\\nNow the left-hand side can be lower-bounded using the restricted strong convexity (8). On the other\\nhand, using Lemma 2, the right-hand side can be upper-bounded as follows:\\n??? ???\\n??? ???\\n??? ???\\n?\\n??????? ? 1 PK (???k ?S1 + ????k ?S1 ) ? 4 PK ???k ?S1 ? 4 ? F PK\\n2rk , (11)\\nk=1\\nk=1\\nk=1\\nK\\nK\\nK\\nS1\\n??? ???\\nwhere the last inequality follows because ???????F = ??(k) ?F for k = 1, . . . , K. Combining inequalities (8), (10), and (11), we obtain our claim (9).\\nNegahban et al. [15] (see also [17]) pointed out that the key properties for establishing a sharp convergence result for a regularized M -estimator is the decomposability of the regularizer and the restricted strong convexity. What we have shown suggests that the weaker mode-k decomposability (5)\\nsuf?ce to obtain the above convergence result for the overlapped Schatten 1-norm (1) regularization.\\n3.2 Noisy Tensor Decomposition\\nIn this subsection, we consider the setting where all the elements are observed (with noise) and the\\ngoal is to recover the underlying low-rank tensor without noise.\\nSince all the elements are observed only once, X is simply a vectorization\\n(M =\\n???\\n??? N ), and the left2\\n? ? W ? ??? . Therefore, the\\n?\\n?\\n?\\n=\\nW\\nhand side of inequality (10)???gives the\\nquantity\\nof\\ninterest\\n?X(?)?\\n2\\nF\\n???\\nremaining task is to bound ???X? (?)???mean as in the following lemma.\\nLemma 3. Suppose\\n???\\n?that\\n?? X : n1 ?? ? ??nK ? N is a vectorization of a tensor. With high probability\\nthe quantity ???X? (?)???mean is concentrated around its mean, which can be bounded as follows:\\nK\\n???\\n???\\n?\\np\\n? X ??\\nE???X? (?)???mean ?\\nnk + n\\n? \\\\k .\\nK\\n\\n(12)\\n\\nk=1\\n\\n???\\n???\\nSetting the regularization constant as ?M = c0 E???X? (?)???mean /N , we obtain the following theorem.\\nTheorem 2. Suppose that X : n1 ?? ? ??nK ? N is a vectorization of a tensor. There are universal\\nconstants c0 and c1 , such that, with high probability, any solution of the minimization problem (7)\\nPK ?\\np\\nwith regularization constant ?M = c0 ? k=1 ( nk + n\\n? \\\\k )/(KN ) satis?es the following bound:\\n?\\n!2 ?\\n!2\\nK\\nK\\nX\\nX\\n???\\n???2\\n??\\n?\\np\\n?\\n1\\n1\\n?\\n2\\n? ? W ??? ? c1 ?\\n???W\\nnk + n\\n? \\\\k\\nrk .\\nF\\nK\\nK\\nk=1\\n\\nk=1\\n\\nProof. Combining Equations (10)?(11) with the fact that X is simply a vectorization and M = N ,\\nwe have\\n?\\n1\\n? ? W ? ?F ? 16 2?M PK ?rk .\\n?W\\nN\\n\\nK\\n\\nk=1\\n\\nSubstituting the choice of regularization constant ?M and squaring both sides, we obtain our claim.?\\nWe can simplify the result of Theorem 2 by noting that n\\n? \\\\k = N/nk ? nk , when the dimenPK ? 2\\n1\\nsions are of the same order. Introducing the notation ?r?1/2 = ( K\\nrk ) and n?1 :=\\nk=1\\n(1/n1 , . . . , 1/nK ), we have\\n???\\n???\\n? ? W ? ???2\\n???W\\n?\\n?\\nF\\n? Op ? 2 ?n?1 ?1/2 ?r?1/2 .\\n(13)\\nN\\nWe call the quantity r? = ?n?1 ?1/2 ?r?1/2 the normalized rank, because r? = r/n when the dimensions are balanced (nk = n and rk = r for all k = 1, . . . , K).\\n5\\n\\n\\f3.3\\n\\nRandom Gaussian Design\\n\\nIn this subsection, we consider the case the elements of the input tensors Xi (i = 1, . . . , M ) in the\\nobservation model (6) are distributed according to independent identical standard Gaussian distributions. We call this setting random Gaussian design.\\n???\\n???\\nFirst we show an upper bound on the norm ???X? (?)???mean , which we use to specify the scaling of\\nthe regularization constant ?M in Theorem 1.\\nLemma 4. Let X : Rn1 ?????nK ? RM be a random Gaussian design. In addition, we assume\\nthat\\n?i is sampled independently from N (0, ? 2 ). Then with high probability the quantity\\n?\\n??? ? the ??noise\\n???X (?)???\\nis concentrated around its mean, which can be bounded as follows:\\nmean\\n???\\n???\\nE???X? (?)???\\n\\nmean\\n\\n?\\nK\\n?\\np\\n? M X ??\\n?\\nnk + n\\n? \\\\k .\\nK\\nk=1\\n\\nNext the following lemma, which is a generalization of a result presented in Negahban and Wainwright [17, Proposition 1], provides a ground for the restricted strong convexity assumption (8).\\nLemma 5. Let X : Rn1 ?????nK ? RM be a random Gaussian design. Then it satis?es\\n?r\\n!\\nr\\nK\\nn\\n? \\\\k ?????? ??????\\n1 X\\n?X(?)?2\\n1 ?????? ??????\\nnk\\n?\\n? F?\\n+\\n? S1 ,\\n?\\n4\\nK\\nM\\nM\\nM\\nk=1\\n\\nwith probability at least 1 ? 2 exp(?N/32).\\nProof. The proof is analogous to that of Proposition 1 in [17] except that we use H?older-like inequality (3) for tensors instead of inequality (2) for matrices.\\nFinally, we obtain the following convergence bound.\\nTheorem 3. Under the random Gaussian design setup, there are universal constants c0 , c1 , and c2\\nPK ?\\nPK ? 2\\np\\n1\\n1\\nsuch that for a sample size M ? c1 ( K\\nn\\n? \\\\k ))2 ( K\\nrk ) , any solution of the\\nk=1 ( nk +\\n?\\nPk=1\\np\\n?\\nK\\nminimization problem (7) with regularization constant ?M = c0 ? k=1 ( nk + n\\n? \\\\k )/(K M )\\nsatis?es the following bound:\\nPK ?\\nPK ? 2\\np\\n1\\n1\\n???\\n???\\n?2 ( K\\nn\\n? \\\\k ))2 ( K\\nk=1 ( nk +\\nk=1 rk )\\n? ? W ? ???2 ? c2\\n???W\\n,\\nF\\nM\\nwith high probability.\\nAgain we can simplify the result of Theorem 3 as follows: for sample size M ? c1 N r? we have\\n?\\n?\\n?1\\n???\\n???\\n? ? W ? ???2 ? Op ? 2 N ?n ?1/2 ?r?1/2 ,\\n???W\\n(14)\\nF\\nM\\nwhere r? = ?n?1 ?1/2 ?r?1/2 is the normalized rank. Note that the condition on the number of\\nsamples M does not depend on the noise variance ? 2 . Therefore in the limit ? 2 ? 0, the bound (14)\\nis suf?ciently small but only valid for sample size M that exceeds c1 N r?, which implies a threshold\\nbehavior as in Figure 1.\\nNote also that in the matrix case (K = 2), r1 = r2 = r and N ?n?1 ?1/2 = O(n1 + n2 ). Therefore\\n? ? W ? ?2 ?\\nwe can restate the above result as for sample size M ? c1 r(n1 + n2 ), we have ?W\\nF\\nOp (r(n1 + n2 )/M ), which is compatible with the result in [17, 18].\\n\\n4\\n\\nExperiments\\n\\nIn this section, we conduct two numerical experiments to con?rm our analysis in Section 3.2 and\\nSection 3.3.\\n6\\n\\n\\f?4\\n\\n3\\n\\nx 10\\n\\n0.03\\n\\nsize=[50 50 20] ?M=0.03/N\\nsize=[50 50 20] ?M=0.33/N\\n\\nsize=[50 50 20] ?M=2.34/N\\n\\nsize=[50 50 20] ? =0.54/N\\n\\n0.025\\n\\nM\\n\\nsize=[100 100 50] ?M=0.66/N\\n\\nsize=[100 100 50] ?M=0.69/N\\n\\nMean squared error\\n\\nMean squared error\\n\\nsize=[50 50 20] ? =6/N\\nM\\n\\nsize=[100 100 50] ?M=0.06/N\\n2\\n\\nsize=[50 50 20] ?M=0.33/N\\n\\nsize=[100 100 50] ? =1.11/N\\nM\\n\\n1\\n\\n0.02\\n\\nsize=[100 100 50] ? =4.5/N\\nM\\n\\nsize=[100 100 50] ?M=12/N\\n0.015\\n\\n0.01\\n\\n0.005\\n\\n0\\n0\\n\\n0.2\\n\\n0.4\\n0.6\\nNormalized rank\\n\\n0.8\\n\\n0\\n0\\n\\n1\\n\\n(a) Small noise (? = 0.01).\\n\\n0.2\\n\\n0.4\\n0.6\\nNormalized rank\\n\\n0.8\\n\\n1\\n\\n(b) Large noise (? = 0.1).\\n\\nFigure 2: Result of noisy tensor decomposition for tensors of size 50 ? 50 ? 20 and 100 ? 100 ? 50.\\n\\n4.1\\n\\nNoisy Tensor Decomposition\\n\\nWe randomly generated low-rank tensors of dimensions n(1) = (50, 50, 20) and n(2) =\\n(100, 100, 50) for various ranks (r1 , . . . , rK ). For a speci?c rank, we generated the true tensor\\nby drawing elements of the r1 ? ? ? ? ? rK ?core tensor? from the standard normal distribution and\\nmultiplying its each mode by an orthonormal factor randomly drawn from the Haar measure. As\\ndescribed in Section 3.2, the observation y consists of all the elements of the original tensor once\\n(M = N ) with additive independent Gaussian noise with variance ? 2 . We used the alternating\\ndirection method of multipliers (ADMM) for ?constraint? approaches described in [23, 10] to solve\\nthe minimization problem (7). The whole experiment was repeated 10 times and averaged.\\n???\\n???\\n? ? W ? ???2 /N is plotted against\\nThe results are shown in Figure 2. The mean squared error ???W\\nF\\nthe normalized rank r? = ?n?1 ?1/2 ?r?1/2 (of the true tensor) de?ned in Equation (13). Since the\\nchoice of the regularization constant ?M only depends on the size of the tensor and not on the ranks\\nof the underlying tensor in Theorem 2, we ?x the regularization constant to some different values\\nand report the dependency of the estimation error on the normalized rank r? of the true tensor.\\nFigure 2(a) shows the result for small noise (? = 0.01) and Figure 2(b) shows the result for large\\n???\\n???\\n? ? W ? ???2 grows linearly\\nnoise (? = 0.1). As predicted by Theorem 2, the squared error ???W\\nF\\nagainst the normalized rank r?. This behaviour is consistently observed not only around the preferred\\nregularization constant value (triangles) but also in the over-?tting case (circles) and the under?tting case (crosses). Moreover, as predicted by Theorem 2, the preferred regularization constant\\nvalue scales linearly and the squared error scales quadratically to the noise standard deviation ?.\\nAs predicted by Lemma 3, the curves for the smaller 50 ? 50 ? 20 tensor and those for the larger\\n100 ? 100 ? 50 tensor seem to agree when the regularization constant\\nis scaled by the factor two.\\np\\nNote that the dominant term in inequality (12) is the second term n\\n? \\\\k , which is roughly scaled by\\nthe factor two from 50 ? 50 ? 20 to 100 ? 100 ? 50.\\n4.2\\n\\nTensor completion from partial observations\\n\\nIn this subsection, we repeat the simulation originally done by Tomioka et al. [23] and demonstrate\\nthat our results in Section 3.3 can precisely predict the empirical scaling behaviour with respect to\\nboth the size and rank of a tensor.\\nWe present results for both matrix completion (K = 2) and tensor completion (K = 3). For\\nthe matrix case, we randomly generated low-rank matrices of dimensions 50 ? 20, 100 ? 40, and\\n250 ? 200. For the tensor case, we randomly generated low-rank tensors of dimensions 50 ? 50 ? 20\\nand 100 ? 100 ? 50. We generated the matrices or tensors as in the previous subsection for various\\nranks. We randomly selected some elements of the true matrix/tensor for training and kept the\\n7\\n\\n\\f1\\n\\n0.8\\n\\n0.8\\n\\n0.6\\n0.4\\nsize=[50 20]\\nsize=[100 40]\\nsize=[250 200]\\n\\n0.2\\n0\\n0\\n\\n0.1\\n0.2\\n0.3\\n0.4\\n0.5\\nNormalized rank ||n?1|| ||r||\\n1/2\\n\\nFraction at Error<=0.01\\n\\nFraction at err<=0.01\\n\\n1\\n\\n0.6\\n0.4\\n0.2\\n0\\n0\\n\\n0.6\\n\\n1/2\\n\\n(a) Matrix completion (K = 2).\\n\\nsize=[50 50 20]\\nsize=[100 100 50]\\n0.2\\n0.4\\n0.6\\nNormalized rank ||n?1||1/2||r||1/2\\n\\n0.8\\n\\n(b) Tensor completion (K = 3).\\n\\nFigure 3: Scaling behaviour of matrix/tensor completion with respect to the size n and the rank r.\\n\\nremaining elements for testing. No observation noise is added. We used the ADMM for ?as a\\nmatrix? and ?constraint? approaches described in [23] to solve the minimization problem (7) for\\nmatrix completion and tensor completion, respectively. Since there is no observation noise, we\\nchose the regularization constant ? ? 0. A single experiment for a speci?c size and rank can be\\nvisualized as in Figure 1.\\n?In\\n?? Figure ?3,\\n??? we plot the minimum fraction of observations m = M/N that achieved error\\n? ? W ??? smaller than 0.01 against the normalized rank r? = ?n?1 ?1/2 ?r?1/2 (of the true ten???W\\nF\\nsor) de?ned in Equation (13). The matrix case is plotted in Figure 3(a) and the tensor case is plotted\\nin Figure 3(b). Each series (blue crosses or red circles) corresponds to different matrix/tensor size\\nand each data-point corresponds to a different core size (rank). We can see that the fraction of observations m = M/N scales linearly against the normalized rank r?, which agrees with the condition\\nM/N ? c1 ?n?1 ?1/2 ?r?1/2 = c1 r? in Theorem 3 (see Equation (14)). The agreement is especially\\ngood for tensor completion (Figure 3(b)), where the two series almost overlap. Interestingly, we\\ncan see that when compared at the same normalized rank, tensor completion is easier than matrix\\ncompletion. For example, when nk = 50 and rk = 10 for each k = 1, . . . , K, the normalized rank\\nis 0.2. From Figure 3, we can see that we only need to see 30% of the entries in the tensor case to\\nachieve error smaller than 0.01, whereas we need about 60% of the entries in the matrix case.\\n\\n5\\n\\nConclusion\\n\\nWe have analyzed the statistical performance of a tensor decomposition algorithm based on the\\noverlapped Schatten 1-norm regularization (7). Numerical experiments show that our theory can\\npredict the empirical scaling behaviour well. The fraction of observation m = M/N at the threshold\\npredicted by our theory is proportional to the quantity we call the normalized rank, which re?nes\\nconjecture (sum of the mode-k ranks) in [23].\\nThere are numerous directions that the current study can be extended. In this paper, we have focused\\non the convergence of the estimation error; it would be meaningful to also analyze the condition for\\nthe consistency of the estimated rank as in [2]. Second, although we have succeeded in predicting\\nthe empirical scaling behaviour, the setting of random Gaussian design does not match the tensor\\ncompletion setting in Section 4.2. In order to analyze the latter setting, the notion of incoherence in\\n[5] or spikiness in [16] might be useful. This might also explain why tensor completion is easier than\\nmatrix completion at the same normalized rank. Moreover, when the target tensor is only low-rank\\nin a certain mode, Schatten 1-norm regularization fails badly (as predicted by the high normalized\\nrank). It would be desirable to analyze the ?Mixture? approach that aims at this case [23]. In\\na broader context, we believe that the current paper could serve as a basis for re-examining the\\nconcept of tensor rank and low-rank approximation of tensors based on convex optimization.\\nAcknowledgments. We would like to thank Franz Kir?aly and Hiroshi Kajino for their valuable\\ncomments and discussions. This work was supported in part by MEXT KAKENHI 22700138,\\n23240019, 23120004, 22700289, and NTT Communication Science Laboratories.\\n8\\n\\n\\fReferences\\n[1] E. Acar and B. Yener. Unsupervised multiway data analysis: A literature survey. IEEE T. Knowl. Data.\\nEn., 21(1):6?20, 2009.\\n[2] F.R. Bach. Consistency of trace norm minimization. J. Mach. Learn. Res., 9:1019?1048, 2008.\\n[3] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.\\n[4] R. Bro. PARAFAC. Tutorial and applications. Chemometr. Intell. Lab., 38(2):149?171, 1997.\\n[5] E. J. Candes and B. Recht. Exact matrix completion via convex optimization. Found. Comput. Math.,\\n9(6):717?772, 2009.\\n[6] J.D. Carroll and J.J. Chang. Analysis of individual differences in multidimensional scaling via an n-way\\ngeneralization of ?Eckart-Young? decomposition. Psychometrika, 35(3):283?319, 1970.\\n[7] P. Comon. Tensor decompositions. In J. G. McWhirter and I. K. Proudler, editors, Mathematics in signal\\nprocessing V. Oxford University Press, 2002.\\n[8] L. De Lathauwer and J. Vandewalle. Dimensionality reduction in higher-order signal processing and\\nrank-(r1 , r2 , . . . , rn ) reduction in multilinear algebra. Linear Algebra Appl., 391:31?55, 2004.\\n[9] K. Fukumizu. Generalization error of linear neural networks in unidenti?able cases. In Algorithmic\\nLearning Theory, pages 51?62. Springer, 1999.\\n[10] S. Gandy, B. Recht, and I. Yamada. Tensor completion and low-n-rank tensor recovery via convex optimization. Inverse Problems, 27:025010, 2011.\\n[11] J. H?astad. Tensor rank is NP-complete. Journal of Algorithms, 11(4):644?654, 1990.\\n[12] T. G. Kolda and B. W. Bader. Tensor decompositions and applications. SIAM Review, 51(3):455?500,\\n2009.\\n[13] J. Liu, P. Musialski, P. Wonka, and J. Ye. Tensor completion for estimating missing values in visual data.\\nIn Prof. ICCV, 2009.\\n[14] M. M?rup. Applications of tensor (multiway array) factorizations and decompositions in data mining.\\nWiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 1(1):24?40, 2011.\\n[15] S. Negahban, P. Ravikumar, M. Wainwright, and B. Yu. A uni?ed framework for high-dimensional\\nanalysis of m-estimators with decomposable regularizers. In Y. Bengio, D. Schuurmans, J. Lafferty,\\nC. K. I. Williams, and A. Culotta, editors, Advances in NIPS 22, pages 1348?1356. 2009.\\n[16] S. Negahban and M.J. Wainwright. Restricted strong convexity and weighted matrix completion: Optimal\\nbounds with noise. Technical report, arXiv:1009.2118, 2010.\\n[17] S. Negahban and M.J. Wainwright. Estimation of (near) low-rank matrices with noise and highdimensional scaling. Ann. Statist., 39(2), 2011.\\n[18] B. Recht, M. Fazel, and P.A. Parrilo. Guaranteed minimum-rank solutions of linear matrix equations via\\nnuclear norm minimization. SIAM Review, 52(3):471?501, 2010.\\n[19] A. Rohde and A.B. Tsybakov.\\n39(2):887?930, 2011.\\n\\nEstimation of high-dimensional low-rank matrices.\\n\\nAnn. Statist.,\\n\\n[20] N.D. Sidiropoulos, R. Bro, and G.B. Giannakis. Parallel factor analysis in sensor array processing. IEEE\\nT. Signal Proces., 48(8):2377?2388, 2000.\\n[21] M. Signoretto, L. De Lathauwer, and J.A.K. Suykens. Nuclear norms for tensors and their use for convex\\nmultilinear estimation. Technical Report 10-186, ESAT-SISTA, K.U.Leuven, 2010.\\n[22] N. Srebro, J. D. M. Rennie, and T. S. Jaakkola. Maximum-margin matrix factorization. In Lawrence K.\\nSaul, Yair Weiss, and L?eon Bottou, editors, Advances in NIPS 17, pages 1329?1336. MIT Press, Cambridge, MA, 2005.\\n[23] R. Tomioka, K. Hayashi, and H. Kashima. Estimation of low-rank tensors via convex optimization.\\nTechnical report, arXiv:1010.0789, 2011.\\n[24] L. R. Tucker. Some mathematical notes on three-mode factor analysis. Psychometrika, 31(3):279?311,\\n1966.\\n[25] M. Vasilescu and D. Terzopoulos. Multilinear analysis of image ensembles: Tensorfaces. Computer\\nVision?ECCV 2002, pages 447?460, 2002.\\n[26] H. Wang and N. Ahuja. Facial expression decomposition. In Proc. 9th ICCV, pages 958 ? 965, 2003.\\n\\n9\\n\\n\\f\",\n          \"Effects of Spatial and Temporal Contiguity on\\nthe Acquisition of Spatial Information\\n\\nThea B. Ghiselli-Crippa and Paul W. Munro\\nDepartment of Information Science and Telecommunications\\nUniversity of Pittsburgh\\nPittsburgh, PA 15260\\ntbgst@sis.pitt.edu, munro@sis.pitt.edu\\n\\nAbstract\\nSpatial information comes in two forms: direct spatial information (for\\nexample, retinal position) and indirect temporal contiguity information,\\nsince objects encountered sequentially are in general spatially close. The\\nacquisition of spatial information by a neural network is investigated\\nhere. Given a spatial layout of several objects, networks are trained on a\\nprediction task. Networks using temporal sequences with no direct spatial information are found to develop internal representations that show\\ndistances correlated with distances in the external layout. The influence\\nof spatial information is analyzed by providing direct spatial information\\nto the system during training that is either consistent with the layout or\\ninconsistent with it. This approach allows examination of the relative\\ncontributions of spatial and temporal contiguity.\\n\\n1 Introduction\\nSpatial information is acquired by a process of exploration that is fundamentally temporal, whether it be on a small scale, such as scanning a picture, or on a larger one, such as\\nphysically navigating through a building, a neighborhood, or a city. Continuous scanning\\nof an environment causes locations that are spatially close to have a tendency to occur in\\ntemporal proximity to one another. Thus, a temporal associative mechanism (such as a\\nHebb rule) can be used in conjunction with continuous exploration to capture the spatial\\nstructure of the environment [1]. However, the actual process of building a cognitive map\\nneed not rely solely on temporal associations, since some spatial information is encoded in\\nthe sensory array (position on the retina and proprioceptive feedback). Laboratory studies\\nshow different types of interaction between the relative contributions of temporal and spatial contiguities to the formation of an internal representation of space. While Clayton and\\nHabibi's [2] series of recognition priming experiments indicates that priming is controlled\\nonly by temporal associations, in the work of McNamara et al. [3] priming in recognition is observed only when space and time are both contiguous. In addition, Curiel and\\nRadvansky's [4] work shows that the effects of spatial and temporal contiguity depend on\\nwhether location or identity information is emphasized during learning. Moreover, other\\nexperiments ([3]) also show how the effects clearly depend on the task and can be quite\\ndifferent if an explicitly spatial task is used (e.g., additive effects in location judgments).\\n\\n\\fT. B. Ghiselli-Crippa and P W. Munro\\n\\n18\\n\\nlabels\\n\\nlabels\\n\\nlabels\\n(A coeff.)\\n\\nlabels\\n\\nlabels\\n\\ncoordinates\\n\\ncoordinates\\n(B coeff.)\\n\\nlabels\\n\\nFigure 1: Network architectures: temporal-only network (left); spatio-temporal network\\nwith spatial units part of the input representation (center); spatio-temporal network with\\nspatial units part of the output representation (right) .\\n\\n2 Network architectures\\nThe goal of the work presented in this paper is to study the structure of the internal representations that emerge from the integration of temporal and spatial associations. An\\nencoder-like network architecture is used (see Figure 1), with a set of N input units and a\\nset of N output units representing N nodes on a 2-dimensional graph. A set of H units is\\nused for the hidden layer. To include space in the learning process, additional spatial units\\nare included in the network architecture. These units provide a representation of the spatial\\ninformation directly available during the learning/scanning process. In the simulations described in this paper, two units are used and are chosen to represent the (x, y) coordinates of\\nthe nodes in the graph . The spatial units can be included as part of the input representation\\nor as part of the output representation (see Figure 1, center and right panels): both choices\\nare used in the experiments, to investigate whether the spatial information could better benefit training as an input or as an output [5]. In the second case, the relative contribution of\\nthe spatial information can be directly manipulated by introducing weighting factors in the\\ncost function being minimized. A two-term cost function is used, with a cross-entropy term\\nfor the N label units and a squared error term for the 2 coordinate units,\\n\\nri indicates the actual output of unit i and ti its desired output. The relative influence of\\n\\nthe spatial information is controlled by the coefficients A and B.\\n\\n3\\n\\nLearning tasks\\n\\nThe left panel of Figure 2 shows an example of the type of layout used; the effective\\nlayout used in the study consists of N = 28 nodes. For each node, a set of neighboring\\nnodes is defined, chosen on the basis of how an observer might scan the layout to learn the\\nnode labels and their (spatial) relationships; in Figure 2, the neighborhood relationships are\\nrepresented by lines connecting neighboring nodes. From any node in the layout, the only\\nallowed transitions are those to a neighbor, thus defining the set of node pairs used to train\\nthe network (66 pairs out of C(28, 2) = 378 possible pairs). In addition, the probability\\nof occurrence of a particular transition is computed as a function of the distance to the\\ncorresponding neighbor. It is then possible to generate a sequence of visits to the network\\nnodes, aimed at replicating the scanning process of a human observer studying the layout.\\n\\n\\f19\\n\\nSpatiotemporal Contiguity Effects on Spatial Information Acquisition\\n\\neraser\\n\\nknife\\n\\ncup\\n\\ncoin\\n\\neraser\\n\\nbutton\\n\\nFigure 2: Example of a layout (left) and its permuted version (right). Links represent\\nallowed transitions. A larger layout of 28 units was used in the simulations.\\n\\nThe basic learning task is similar to the grammar learning task of Servan-Schreiber et al.\\n[6] and to the neighborhood mapping task described in [1] and is used to associate each of\\nthe N nodes on the graph and its (x, y) coordinates with the probability distribution of the\\ntransitions to its neighboring nodes. The mapping can be learned directly, by associating\\neach node with the probability distribution of the transitions to all its neighbors: in this\\ncase, batch learning is used as the method of choice for learning the mapping. On the\\nother hand, the mapping can be learned indirectly, by associating each node with itself\\nand one of its neighbors, with online learning being the method of choice in this case;\\nthe neighbor chosen at each iteration is defined by the sequence of visits generated on\\nthe basis of the transition probabilities. Batch learning was chosen because it generally\\nconverges more smoothly and more quickly than online learning and gives qualitatively\\nsimilar results. While the task and network architecture described in [1] allowed only\\nfor temporal association learning, in this study both temporal and spatial associations are\\nlearned simultaneously, thanks to the presence of the spatial units. However, the temporalonly (T-only) case, which has no spatial units, is included in the simulations performed\\nfor this study, to provide a benchmark for the evaluation of the results obtained with the\\nspatio-temporal (S- T) networks.\\nThe task described above allows the network to learn neighborhood relationships for which\\nspatial and temporal associations provide consistent information, that is, nodes experienced\\ncontiguously in time (as defined by the sequence) are also contiguous in space (being spatial neighbors). To tease apart the relative contributions of space and time, the task is kept\\nthe same, but the data employed for training the network is modified: the same layout is\\nused to generate the temporal sequence, but the x , y coordinates of the nodes are randomly\\npermuted (see right panel of Figure 2). If the permuted layout is then scanned following the\\nsame sequence of node visits used in the original version, the net effect is that the temporal\\nassociations remain the same, but the spatial associations change so that temporally neighboring nodes can now be spatially close or distant: the spatial associations are no longer\\nconsistent with the temporal associations. As Figure 4 illustrates, the training pairs (filled\\ncircles) all correspond to short distances in the original layout, but can have a distance\\nanywhere in the allowable range in the permuted layout. Since the temporal and spatial\\ndistances were consistent in the original layout, the original spatial distance can be used\\nas an indicator of temporal distance and Figure 4 can be interpreted as a plot of temporal\\ndistance vs. spatial distance for the permuted layout.\\nThe simulations described in the following include three experimental conditions: temporal\\nonly (no direct spatial information available); space and time consistent (the spatial coordinates and the temporal sequence are from the same layout); space and time inconsistent\\n(the spatial coordinates and the temporal sequence are from different layouts).\\n\\n\\fT. B. Ghise/li-Crippa and P. W. Munro\\n\\n20\\n\\nHidden unit representations are compared using Euclidean distance (cosine and inner product measures give consistent results); the internal representation distances are also used to\\ncompute their correlation with Euclidean distances between nodes in the layout (original\\nand permuted). The correlations increase with the number of hidden units for values of\\nH between 5 and 10 and then gradually taper off for values greater than 10. The results\\npresented in the remainder of the paper all pertain to networks trained with H = 20 and\\nwith hidden units using a tanh transfer function; all the results pertaining to S-T networks\\nrefer to networks with 2 spatial output units and cost function coefficients A = 0.625 and\\nB = 6.25.\\n\\n4 Results\\nFigure 3 provides a combined view of the results from all three experiments. The left panel\\nillustrates the evolution of the correlation between internal representation distances and\\nlayout (original and permuted) distances. The right panel shows the distributions of the\\ncorrelations at the end of training (1000 epochs). The first general result is that, when spatial information is available and consistent with the temporal information (original layout),\\nthe correlation between hidden unit distances and layout distances is consistently better\\nthan the correlation obtained in the case of temporal associations alone. The second general result is that, when spatial information is available but not consistent with the temporal\\ninformation (permuted layout), the correlation between hidden unit distances and original\\nlayout distances (which represent temporal distances) is similar to that obtained in the case\\nof temporal associations alone, except for the initial transient. When the correlation is computed with respect to the permuted layout distances, its value peaks early during training\\nand then decreases rapidly, to reach an asymptotic value well below the other three cases.\\nThis behavior is illustrated in the box plots in the right panel of Figure 3, which report the\\ndistribution of correlation values at the end of training.\\n\\n4.1\\n\\nTemporal-only vs. spatio-temporal\\n\\nAs a first step in this study, the effects of adding spatial information to the basic temporal\\nassociations used to train the network can be examined. Since the learning task is the same\\nfor both the T-only and the S-T networks except for the absence or presence of spatial\\ninformation during training, the differences observed can be attributed to the additional\\nspatial information available to the S-T networks. The higher correlation between internal\\nrepresentation distances and original layout distances obtained when spatial information is\\n\\n0\\n\\n~\\n\\n.,\\n\\n8\\n\\n.,\\n\\nS and T CO\\\"Isistent\\n\\n0\\n\\n.\\n\\n0\\n\\n.\\n\\nT-o\\\"\\nSand T InCOnsistent\\n\\n0\\n\\ni:i\\n\\n-==~\\n\\n0\\n\\n(corr with T distance)\\n\\nii\\n\\n...\\n\\n?8 \\\"\\n\\n\\\"0\\n\\n0\\n\\n=s:\\n...........\\nE:2\\n\\nS and T Ir'ICOOSlStent\\n(corr. Wflh S distance)\\n\\n'\\\"ci\\n\\n~\\n\\n--'----'\\n\\nN\\n\\n0\\n\\n0\\n0\\n\\n0\\n0\\n\\n200\\n\\n400\\n600\\nOllnber 01 epochs\\n\\n800\\n\\n1000\\n\\nSandT\\n\\ncon_atent\\n\\nT-only\\n\\nSandT\\nSandT\\nInconsistent\\nineon.stant\\n(corr \\\" th T ast ) (corr wth 5 dst )\\n\\nFigure 3: Evolution of correlation during training (0 - 1000 epochs) (left). Distributions of\\ncorrelations at the end of training (1000 epochs) (right).\\n\\n\\fSpatiotemporal Contiguity Effects on Spatial Information Acquisition\\n\\n-\\n\\n21\\n\\nN\\n\\ndHU = 0.6 + 3.4d T + 0.3ds - 2.1( dT)2 + 0.4( d S )2 - 0.4d T ds\\n\\n0\\n\\n.,\\n\\n25\\n\\n0\\n\\n\\\",\\nE\\n~\\n\\n'\\\"\\n0\\n\\n15\\n\\n...\\n0\\n\\n05\\nN\\n\\n0\\n\\n15\\n0\\n0\\n\\n00\\n\\n02\\n\\n04\\n\\n08\\n\\n10\\n\\n12\\n\\nFigure 4: Distances in the original layout\\n(x) vs_ distances in the permuted layout\\n(y)_ The 66 training pairs are identified by\\nfilled circles_\\n\\n\\\"\\nFigure 5: Similarities (Euclidean distances)\\nbetween internal representations developed\\nby a S-T network (after 300 epochs)_ Figure\\n4 projects the data points onto the x, y plane_\\n\\navailable (see Figure 3) is apparent also when the evolution of the internal representations\\nis examined_ As Figure 6 illustrates, the presence of spatial information results in better\\ngeneralization for the pattern pairs outside the training set While the distances between\\ntraining pairs are mapped to similar distances in hidden unit space for both the T-only and\\nthe S-T networks, the T-only network tends to cluster the non-training pairs into a narrow\\nband of distances in hidden unit space. In the case of the S-T network instead, the hidden\\nunit distances between non-training pairs are spread out over a wider range and tend to\\nreflect the original layout distances.\\n4.2\\n\\nPermuted layout\\n\\nAs described above, with the permuted layout it is possible to decouple the spatial and\\ntemporal contributions and therefore study the effects of each. A comprehensive view of\\nthe results at a particular point during training (300 epochs) is presented in Figure 5, where\\nthe x, y plane represents temporal distance vs. spatial distance (see also Figure 4) and the z\\naxis represents the similarity between hidden unit representations. The figure also includes\\na quadratic regression surface fitted to the data points. The coefficients in the equation of\\nthe surface provide a quantitative measure of the relative contributions of spatial (ds) and\\ntemporal distances (dT ) to the similarity between hidden unit representations (d HU ):\\n(2)\\n\\nIn general, after the transient observed in early training (see Figure 3), the largest and most\\nsignificant coefficients are found for dT and (dT?, indicating a stronger dependence of\\ndHU on temporal distance than on spatial distance.\\nThe results illustrated in Figure 5 represent the situation at a particular point during training\\n(300 epochs). Similar plots can be generated for different points during training, to study\\nthe evolution of the internal representations. A different view of the evolution process is\\nprovided by Figure 7, in which the data points are projected onto the x,Z plane (top panel)\\nand the y,z plane (bottom panel) at four different times during training. In the top panel,\\n\\n14\\n\\n\\fT. B. Ghiselli-Crippa and P W Munro\\n\\n22\\n\\n,.. ,..\\n.. roo\\n:::\\n\\n~\\n_\\n\\n0\\n\\n?\\n\\nN\\n\\n~ ~\\n~ ~\\n\\n~\\n\\n-. .. -\\n\\n:::\\n~\\n\\n~\\n\\n02\\n\\n\\\"\\n\\n06\\n\\nO.\\n\\n\\\"_d\\n\\n\\\"\\n\\n12\\n\\n.\\n\\n,,\\n\\n~'\\n\\n~ :\\n~\\n\\n~\\n~,\\n\\n02\\n\\nos\\n\\n\\\"-'\\n\\n..\\n\\n'\\n\\n02\\n\\n.. .\\n06\\n\\n-\\n\\n,\\n\\ntP\\n\\n.\\n\\nDO\\n\\n0\\n\\n, ,\\n.I'\\n\\n~\\n\\n12\\n\\n.',\\n\\n00\\n\\n02\\n\\n\\\" \\\"-'\\n06\\n\\n.\\\"\\n\\n02\\n\\n~\\n\\n~\\n\\n.~.\\n','\\n\\n~\\n\\n.. .. \\\" \\\"\\n\\n~\\n\\n06\\n\\n00\\n\\n02\\n\\n\\\"_d\\n\\n_\\n\\n0\\n\\n?\\n\\nN\\n\\n~\\n\\n:\\n\\n~,\\n\\n~ ~\\n\\n..\\n\\nf/Po\\n\\n<P\\n\\n\\\"\\n\\ne,\\n\\n.\\n\\nDO\\n\\n.:.\\n\\n~\\n\\n00\\n\\n02\\n\\n\\\"\\n\\n.. ..\\n\\n\\\"-'\\n\\n10\\n\\n12\\n\\n.. .. .. \\\"\\n\\n12\\n\\n\\\" _d\\n\\n:::\\n\\n~\\n,\\n\\n~\\n12\\n\\n0\\nN\\n\\n~ ~\\n\\n',~-,\\n\\n00\\n\\n~\\n\\n~\\n\\n~\\n_\\n?\\n\\n~\\n\\n~\\n\\n12\\n\\n\\\"\\n\\n0\\n\\n00\\n\\n~\\n\\n:::\\n\\ng\\n10\\n\\n~\\n\\n~\\n\\n~ ~\\n\\nO.\\n\\n,\\n\\n:::\\n\\n;; ~\\n\\n.~\\n00\\n\\n00\\n\\n~.\\n\\n~\\n\\n,\\n\\n\\\"_d\\n\\n,\\n\\n:; ~\\n\\n~\\n\\n~\\n\\n~\\n\\n00\\n\\n~\\n\\n~\\n\\n~\\n\\n~\\n\\ni\\n\\n~\\n\\n~\\n\\n~,\\n\\n:::\\n\\n~\\n\\n~\\n\\n~\\n_\\n\\n0\\n\\n?\\n\\nN\\n\\n~\\n\\n~\\n\\n~\\n\\n~\\n\\no\\n\\n,.~,o\\n\\n: s\\n\\nrIP 0\\n\\n00\\n\\n0\\n\\n?\\n\\n','\\n\\n00\\n\\n02\\n\\n\\\"\\n\\nO.\\n\\n\\\"-'\\n\\no.\\n\\n\\\"\\n\\n12\\n\\nFigure 6: Internal representation distances vs. original layout distances: S-T network (top)\\nvs. T-only network (bottom). The training pairs are identified by filled circles. The presence\\nof spatial information results in better generalization for the pairs outside the training set.\\nthe internal representation distances are plotted as a function of temporal distance (i.e., the\\nspatial distance from the original layout), while in the bottom panel they are plotted as a\\nfunction of spatial distance (from the permuted layout). The higher asymptotic correlation\\nbetween internal representation distances and temporal distances, as opposed to spatial\\ndistances (see Figure 3), is apparent also from the examination of the evolutionary plots,\\nwhich show an asymptotic behavior with respect to temporal distances (see Figure 7, top\\npanel) very similar to the T-only case (see Figure 6, bottom panel).\\n\\n5 Discussion\\nThe first general conclusion that can be drawn from the examination of the results described\\nin the previous section is that, when the spatial information is available and consistent with\\nthe temporal information (original layout), the similarity structure of the hidden unit representations is closer to the structure of the original layout than that obtained by using\\ntemporal associations alone. The second general conclusion is that, when the spatial information is available but not consistent with the temporal information (permuted layout),\\nthe similarity structure of the hidden unit representations seems to correspond to temporal\\nmore than spatial proximity. Figures 5 and 7 both indicate that temporal associations take\\nprecedence over spatial associations. This result is in agreement with the results described\\nin [1], showing how temporal associations (plus some high-level constraints) significantly\\ncontribute to the internal representation of global spatial information. However, spatial information certainly is very beneficial to the (temporal) acquisition of a layout, as proven by\\nthe results obtained with the S-T network vs. the T-only network.\\nIn terms of the model presented in this paper, the results illustrated in Figures 5 and 7 can\\nbe compared with the experimental data reported for recognition priming ([2], [3], [4]),\\nwith distance between internal representations corresponding to reaction time. The results\\nof our model indicate that distances in both the spatially far and spatially close condition\\nappear to be consistently shorter for the training pairs (temporally close) than for the nontraining pairs (temporally distant), highlighting a strong temporal effect consistent with the\\ndata reported in [2] and [4] (for spatially far pairs) and in [3] (only for the spatially close\\n\\n\\fSpatiotemporal Contiguity Effects on Spatial Information Acquisition\\n\\n~~\\n\\n0_\\n\\nri\\n\\n; -~-'\\n~. ~~.. .\\nSl\\n...........\\n0\\n\\n\\\" ...... .\\nj!I!A\\n\\n..\\n,.\\n\\n0\\n\\n,.\\n\\n~\\n\\n~\\n\\n~\\n\\n23\\n\\n\\\\\\n\\n0\\n\\n?\\n\\nlfIiiIo\\n\\n'0'\\n\\n110\\n\\n0\\n\\n~'--_ _ _ _ _-.J\\n\\n00\\n\\n02\\n\\nO.\\n\\n01\\n\\n01\\n\\n10\\n\\n12\\n\\n00\\n\\n02\\n\\nO.\\n\\n~\\n\\n01\\n\\n01\\n\\n10\\n\\n12\\n\\n00\\n\\n02\\n\\n0.4\\n\\n01\\n\\n01\\n\\n10\\n\\n12\\n\\n02\\n\\n0\\\"\\n\\n01\\nIn_d (S)\\n\\n01\\n\\n'0\\n\\n12\\n\\n~l.-\\n\\n00\\n\\n0.2\\n\\no.\\n\\not\\n.._d(S)\\n\\n02\\n\\nO.\\n\\n01\\n\\n10\\n\\n12\\n\\n0.0\\n\\n02\\n\\n04\\n\\n08\\n...u:I (S)\\n\\n01\\n\\noa\\n\\n10\\n\\n12\\n\\nIn_den\\n\\nL..-_ _ _ _- . l\\n00\\n\\n0 0\\n\\nl'I_d (T)\\n\\nIn_d(TI\\n\\nIn _d (T}\\n\\nall\\n\\n10\\n\\n12\\n\\n00\\n\\n_ _ _ _ _-.J\\n02\\n\\nO.\\n\\n06\\n\\noa\\n\\n10\\n\\n12\\n\\n!rUi (S)\\n\\nFigure 7: Internal representation distances vs. temporal distances (top) and vs. spatial\\ndistances (bottom) for a S-T network (permuted layout). The training pairs are identified\\nby filled circles. The asymptotic behavior with respect to temporal distances (top panel) is\\nsimilar to the T-only condition. The bottom panel indicates a weak dependence on spatial\\ndistances.\\ncase). For the training pairs (temporally close), slightly shorter distances are obtained for\\nspatially close pairs vs. spatially far pairs; this result does not provide support for the\\nexperimental data reported in either [3] (strong spatial effect) or [2] (no spatial effect).\\nFor the non-training pairs (temporally distant), long distances are found throughout, with\\nno strong dependence on spatial distance; this effect is consistent with all the reported\\nexperimental data. Further simulations and statistical analyses are necessary for a more\\nconclusive comparison with the experimental data.\\nReferences\\n[1] Ghiselli-Crippa, TB. & Munro, P.w. (1994). Emergence of global structure from local associations. In J.D. Cowan, G. Tesauro, & J. Alspector (Eds.), Advances in Neural Information Processing\\nSystems 6, pp. 1101-1108. San Francisco, CA: Morgan Kaufmann.\\n[2] Clayton, K.N. & Habibi, A. (1991). The contribution of temporal contiguity to the spatial priming\\neffect. Journal of Experimental Psychology: Learning. Memory. and Cognition 17:263-271.\\n[3] McNamara, TP., Halpin. J.A. & Hardy, J.K. (1992). Spatial and temporal contributions to the\\nstructure of spatial memory. Journal of Experimental Psychology: Learning. Memory. and Cognition\\n18:555-564.\\n[4] Curiel, J.M. & Radvansky, G.A. (1998). Mental organization of maps. Journal of Experimental\\nPsychology: Learning. Memory. and Cognition 24:202-214.\\n[5] Caruana, R. & de Sa, VR. (1997). Promoting poor features to supervisors: Some inputs work\\nbetter as outputs . In M.e. Mozer, M.I. Jordan, & T Petsche (Eds.), Advances in Neural Information\\nProcessing Systems 9, pp. 389-395. Cambridge, MA: MIT Press.\\n[6] Servan-Schreiber, D., Cleeremans, A. & McClelland, J.L. (1989). Learning sequential structure\\nin simple recurrent networks. In D.S. Touretzky (Ed.), Advances in Neural Information Processing\\nSystems 1, pp. 643-652. San Mateo, CA: Morgan Kaufmann.\\n\\n\\fNeural Representation of Multi-Dimensional\\nStimuli\\n\\nChristian W. Eurich, Stefan D. Wilke and Helmut Schwegler\\nInstitut fUr Theoretische Physik\\nUniversitat Bremen, Germany\\n(eurich,swilke,schwegler)@physik.uni-bremen.de\\n\\nAbstract\\nThe encoding accuracy of a population of stochastically spiking neurons\\nis studied for different distributions of their tuning widths. The situation\\nof identical radially symmetric receptive fields for all neurons, which\\nis usually considered in the literature, turns out to be disadvantageous\\nfrom an information-theoretic point of view. Both a variability of tuning widths and a fragmentation of the neural population into specialized\\nsubpopulations improve the encoding accuracy.\\n\\n1 Introduction\\nThe topic of neuronal tuning properties and their functional significance has focused much\\nattention in the last decades. However, neither empirical findings nor theoretical considerations have yielded a unified picture of optimal neural encoding strategies given a sensory\\nor motor task. More specifically, the question as to whether narrow tuning or broad tuning\\nis advantageous for the representation of a set of stimulus features is still being discussed.\\nEmpirically, both situations are encountered: small receptive fields whose diameter is less\\nthan one degree can, for example, be found in the human retina [7] , and large receptive\\nfields up to 180 0 in diameter occur in the visual system of tongue-projecting salamanders\\n[10]. On the theoretical side, arguments have been put forward for small [8] as well as for\\nlarge [5, 1,9, 3, 13] receptive fields.\\nIn the last years, several approaches have been made to calculate the encoding accuracy\\nof a neural population as a function of receptive field size [5, 1,9,3, 13]. It has turned\\nout that for a firing rate coding, large receptive fields are advantageous provided that D 2:\\n3 stimulus features are encoded [9, 13]. For binary neurons, large receptive fields are\\nadvantageous also for D = 2 [5,3].\\nHowever, so far only radially symmetric tuning curves have been considered. For neural\\npopulations which lack this symmetry, the situation may be very different. Here we study\\nthe encoding accuracy of a popUlation of stochastically spiking neurons. A Fisher information analysis performed on different distributions of tunings widths will indeed reveal a\\nmuch more detailed picture of neural encoding strategies.\\n\\n\\fC. W. Eurich. S. D. Wilke and H. Schwegler\\n\\nJ J6\\n\\n2 Model\\nConsider a D-dimensional stimulus space, X. A stimulus is characterized by a position\\nx\\n(Xl, ... , XD) E X, where the value of feature i, Xi (i\\n1, ... , D), is measured\\nrelative to the total range of values in the i-th dimension such that it is dimensionless.\\nInformation about the stimulus is encoded by a popUlation of N stochastically spiking\\nneurons. They are assumed to have independent spike generation mechanisms such that the\\njoint probability distribution for observing n = (n(l), ... ,n(k), ... ,n(N?) spikes within a\\ntime interval T, Ps(n; x), can be written in the form\\n\\n=\\n\\n=\\n\\nN\\n\\nPs(n;x) =\\n\\nII\\n\\nps(k) (n(k);\\n\\nx),\\n\\n(1)\\n\\nk=l\\nwhere Ps(k) (n(k); x) is the single-neuron probability distribution of the number of observed\\nspikes given the stimulus at position x. Note that (1) does not exclude a correlation of the\\nneural firing rates, i.e., the neurons may have common input or even share the same tuning\\nfunction.\\nThe firing rates depend on the stimulus via the local values of the tuning functions, such that\\nx) can be written in the form Ps(k) (n(k); x) = S (n(k), j(k) (x), T), where the\\ntuning function of neuron k, j(k) (x), gives its mean firing rate in response to the stimulus\\nat position x. We assume here a form of the tuning function that is not necessarily radially\\nsymmetric,\\nPs(k) (n(k);\\n\\nf(') (x)\\n\\n= F4>\\n\\n(t\\n\\n(Xi\\n\\n~~r) )2) =, F? ( e( ')2) ,\\n\\n(2)\\n\\nwhere e(k) = (c~k), ... , c};?) is the center of the tuning curve of neuron k, O'~k) is its\\ntuning width in the i-th dimension, k )2 := (Xi - c~k?)2/O'ik)2 for i = 1, ... ,D, and\\n~(k)2 := ~~k)2 + ... + ~~)2. F > 0 denotes the maximal firing rate of the neurons, which\\nrequires that maxz~o fj>(z) = 1.\\n\\nd\\n\\nWe assume that the tuning widths O't), . .. ,O'~) of each neuron k are drawn from a distribution PO' (0'1, ... ,O'D). For a population oftuning functions with centers e(l), ... , e(N), a\\ndensity 1}(x) is introduced according to 1}(x) := L:~=l 8(x - e(k?).\\nThe encoding accuracy can be quantified by the Fisher information matrix, J, which is\\ndefined as\\n(3)\\n\\nwhere E[ . ..J denotes the expectation value over the probability distribution P(n; x) [2].\\nThe Fisher information yields a lower bound on the expected error of an unbiased estimator\\nthat retrieves the stimulus x from the noisy neural activity (Cramer-Rao inequality) [2]. The\\nminimal estimation error for the i-th feature Xi, ti,min, is given by t;,min = (J - 1 )ii which\\nreduces to t;,min = 1/ Jii(X) if J is diagonal.\\nWe shall now derive a general expression for the popUlation Fisher information. In the\\nnext chapter, several cases and their consequences for neural encoding strategies will be\\ndiscussed.\\nFor model neuron (k), the Fisher information (3) reduces to\\n(k)\\n\\nJ ij\\n\\n.\\n\\n(k)\\n\\n(X'O'I\\n\\n(k) _\\n\\\"\\\"'O'D) -\\n\\n1\\n\\n(k)\\nO'i\\n\\n(k)Aq..\\nO'j\\n\\n(\\n\\n~\\n\\n(k)2\\n\\n,F,T\\n\\n)\\n\\n(k) (k)\\n\\n~i ~j\\n\\n,\\n\\n(4)\\n\\n\\f117\\n\\nNeural Representation of Multi-Dimensional Stimuli\\n\\nwhere the dependence on the tuning widths is indicated by the list of arguments. The\\nfunction A.p depends on the shape of the tuning function and is given in [13]. The independence assumption (1) implies that the population Fisher information is the sum of\\n. d??d\\nI\\n\\\",N J(k)(\\n(k)\\n(k)) . U7\\nt he contn?b?\\nutlOns 0 f the III\\nIVI ua neurons, L.Jk=1 ij x; 0\\\"1 , ... ,0\\\"D\\nne now define\\na population Fisher information which is averaged over the distribution of tuning widths\\nPt:T(0\\\"1, . .. ,O\\\"D):\\nN\\n\\n(Jij (x)) 17 =\\n\\nL / d0\\\"1 . .. dO\\\"D Pt:T(0\\\"1,? .. , O\\\"D) Ji~k) (x; 0\\\"1, ? .. , O\\\"D) .\\n\\n(5)\\n\\nk= 1\\n\\nIntroducing the density of tuning curves, 1J(x), into (5) and assuming a constant distribution, 1J(x) == 1J == const., one obtains the result that the population Fisher information\\nbecomes independentofx and that the off-diagonal elements of J vanish [13]. The average\\npopulation Fisher information then becomes\\n(Jij)t:T =\\n\\n1JD K.p (F, r, D ) \\\\/\\n\\nflt:l\\n0\\\"1) ~\\n0\\\";\\nVij,\\n17\\n\\n(6)\\n\\nwhere K.p depends on the geometry of the tuning curves and is defined in [13].\\n\\n3 Results\\nIn this section, we consider different distributions of tuning widths in (6) and discuss advantageous and disadvantageous strategies for obtaining a high representational accuracy\\nin the neural population.\\nRadially symmetric tuning curves.\\nthe tuning-width distribution reads\\n\\nFor radially symmetric tuning curves of width a,\\nD\\n\\nPt:T(O\\\"l, .. . ,O\\\"D)\\n\\n= II O(O\\\"i -a);\\ni=l\\n\\nsee Fig. 1a for a schematic visualization of the arrangement of the tuning widths for the\\ncase D = 2. The average population Fisher information (6) for i = j becomes\\n(Jii)t:T =\\n\\n1JDK.p(F, r, D) aD -\\n\\n2,\\n\\n(7)\\n\\na result already obtained by Zhang and Sejnowski [13]. Equation (7) basically shows that\\nthe minimal estimation error increases with a for D = 1, that it does not depend on a for\\nD = 2, and that it decreases as a increases for D 2: 3. We shall discuss the relevance of\\nthis case below.\\nIdentical tuning curves without radial symmetry. Next we discuss tuning curves which\\nare identical but not radially symmetric; the tuning-width distribution for this case is\\nD\\n\\nPt:T(0\\\"1, . .. ,O\\\"D)\\n\\n=\\n\\nII\\n\\nO(O\\\"i -\\n\\nad,\\n\\ni=l\\n\\nwhere ai denotes the fixed width in dimension i. For i = j, the average population Fisher\\ninformation (6) reduces to [11,4]\\n(Jii)t:T = 1JDK.p ( F,\\n\\nr,\\n\\nD)\\n\\nDfl 1=1\\n0\\\"1\\n-2\\n\\nO\\\"i\\n\\n.\\n\\n(8)\\n\\n\\fc.\\n\\n118\\n\\n(a)\\n\\nW. Eurich, S. D. Wilke and H. Schwegler\\n\\n(b)\\n\\n/\\n\\nFigure 1: Visualization of different distributions of\\ntuning widths for D = 2. (a) Radially symmetric tuning curves. The dot indicates a fixed (j, while the diagonalline symbolizes a variation in (j discussed in [13].\\n(b) Identical tuning curves which are not radially symmetric. (c) Tuning widths uniformly distributed within\\na small rectangle. (d) Two sUbpopulations each of\\nwhich is narrowly tuned in one dimension and broadly\\ntuned in the other direction.\\n\\n.\\n\\n(c)\\n\\n(d)\\n\\n.\\n\\nb _ b\\n2\\n\\n.\\n\\nEquation (8) contains (7) as a special case. From (8) it becomes immediately clear that the\\nexpected minimal square encoding error for the i-th stimulus feature, ?~ min = 1/ (Jii(X))u,\\ndepends on i, i. e., the population specializes in certain features. The error obtained in\\ndimension i thereby depends on the tuning widths in all dimensions.\\nWhich encoding strategy is optimal for a population whose task it is to encode a single\\nfeature, say feature i, with high accuracy while not caring about the other dimensions? In\\norder to answer this question, we re-write (8) in terms of receptive field overlap.\\nFor the tuning functions f(k) (x) encountered empirically, large values ofthe single-neuron\\nFisher information (4) are typically restricted to a region around the center of the tuning\\nfunction, c(k). The fraction p({3) of the Fisher information that falls into a region ED\\nJ~(k)2 ~ (3 aroundc(k) is given by\\n\\nf\\np({3)\\n\\n:=\\n\\nd\\n\\nE; d\\nX\\n\\nD\\n\\nD\\n\\n\\\"\\\",D\\nX L....i=l\\n\\nX\\n\\n(k) ( )\\nJ ii X\\n\\n2:~t=l J~~)\\n( )\\nu\\nX\\n\\nj3\\n\\nf\\n\\nd~ ~D+l At/>(e, F, T)\\n\\no\\n\\n(9)\\n\\n00\\n\\nf\\n\\nd~ ~D+l At/>(~2, F, T)\\n\\no\\n\\nwhere the index (k) was dropped because the tuning curves are assumed to have identical shapes. Equation (9) allows the definition of an effective receptive field, RF~~,\\ninside of which neuron k conveys a major fraction Po of Fisher information, RF~~ :=\\n\\n{xl~ ~ {3o} , where (3o is chosen such that p({3o)\\n\\n= Po. The Fisher information a\\n\\nneuron k carries is small unless x E RF~~. This has the consequence that a fixed stimulus\\nx is actually encoded only by a subpopulation of neurons. The point x in stimulus space is\\ncovered by\\n27r D/ 2({30)D D _\\n(10)\\nNcode:= 1] Dr(D/2)\\n(Jj\\n\\n}1\\n\\nreceptive fields. With the help of (10), the average population Fisher information (8) can\\nbe re-written as\\n(11)\\n\\nEquation (11) can be interpreted as follows: We assume that the population of neurons\\nencodes stimulus dimension i accurately, while all other dimensions are of secondary importance. The average population Fisher information for dimension i, (Jii ) u, is determined\\nby the tuning width in dimension i, (ji, and by the size of the active subpopulation, N code '\\nThere is a tradeoff between these quantities. On the one hand, the encoding error can be\\ndecreased by decreasing (ji, which enhances the Fisher information carried by each single\\n\\n\\fNeural Representation ofMulti-Dimensional Stimuli\\n\\n119\\n\\nneuron. Decreasing ai, on the other hand, will also shrink the active subpopulation via\\n(10). This impairs the encoding accuracy, because the stimulus position is evaluated from\\nthe activity of fewer neurons. If (11) is valid due to a sufficient receptive field overlap,\\nNcode can be increased by increasing the tuning widths, aj, in all other dimensions j i- i.\\nThis effect is illustrated in Fig. 2 for D = 2.\\n\\nX2\\nc=:>\\n\\nx2, s\\n\\nX2\\n,II\\\"\\\\..\\\\\\n\\nU\\nx2,s\\n\\nFigure 2: Encoding strategy for a stimulus characterized by parameters Xl,s and X2,s' Feature Xl is to be encoded accurately. Effective receptive field shapes are indicated for both\\npopulations. If neurons are narrowly tuned in X2 (left), the active population (solid) is\\nsmall (here: Ncode = 3). Broadly tuned receptive fields for X2 (right) yield a much larger\\npopulation (here: Ncode = 27) thus increasing the encoding accuracy.\\nIt shall be noted that although a narrow tuning width ai is advantageous, the limit ai ---t 0\\nyields a bad representation. For narrowly tuned cells, gaps appear between the receptive\\nfields: The condition 17(X) == const. breaks down, and (6) is no longer valid. A more\\ndetailed calculation shows that the encoding error diverges as ai --* 0 [4]. The fact that\\nthe encoding error decreases for both narrow tuning and broad tuning - due to (11) - proves\\nthe existence of an optimal tuning width, An example is given in Fig. 3a.\\n3\\n\\nrTI~--~------~----~------~\\n\\n1\\\\\\n\\n(b)\\n\\nIi\\n\\n1\\\\\\n\\nIi\\n\\n0.8\\n\\nII\\nII\\nI;\\n\\n2\\n\\n1\\\\\\n\\nI ,\\n\\n;to.6\\n~\\n\\n~~~~;::~-:.~~;:\\n\\nA\\n\\nN~O.4\\nw\\n\\n----- ---- ----- -- ---\\n\\nv\\n\\n0.2\\n\\nO'----~--~--~-----'-------'\\n\\no\\n\\n0.5\\n\\n1\\nA\\n\\n1.5\\n\\n2\\n\\nFigure 3: (a) Example for the encoding behavior with narrow tuning curves arranged on\\na regular lattice of dimension D = 1 (grid spacing ~). Tuning curves are Gaussian, and\\nneural firing is modeled as a Poisson process, Dots indicate the minimal square encoding\\nerror averaged over a uniform distribution of stimuli, (E~in)' as a function ofa. The minimum is clearly visible. The dotted line shows the corresponding approximation according\\nto (8). The inset shows Gaussian tuning curves of optimal width, ao pt ~ 0.4~. (b) 9D()..)\\nas a function of ).. for different values of D.\\n\\n\\fc. W.\\n\\n120\\n\\nEurich, S. D. Wilke and H. Schwegler\\n\\nNarrow distribution of tuning curves. In order to study the effects of encoding the\\nstimulus with distributed tuning widths instead of identical tuning widths as in the previous\\ncases, we now consider the distribution\\n\\ng:i e\\nD\\n\\nPu(lT1,'\\\" ,lTD)\\n\\n=\\n\\n[lTi - (O'i -\\n\\ni)] e [(O'i + i) -lTi] ,\\n\\n(12)\\n\\ne\\n\\ndenotes the Heaviside step function. Equation (12) describes a uniform distriwhere\\nbution in a D-dimensional cuboid of size b1 , ... , bD around (0'1, .. . 0'D); cf. Fig. 1c. A\\nstraightforward calculation shows that in this case, the average population Fisher information (6) for i = j becomes\\n\\n(Jii)u\\n\\n= f/DKtj) (F, T, D) n~l\\nO'~ 0'1\\n\\n{\\n\\n1\\n1 + 12\\n\\n(bO'i 2+ 0 [( O'ib 4] }.\\ni )\\n\\ni )\\n\\n(13)\\n\\nA comparison with (8) yields the astonishing result that an increase in bi results in an\\nincrease in the i-th diagonal element of the average population Fisher information matrix\\nand thus in an improvement in the encoding of the i-th stimulus feature, while the encoding\\nin dimensions j :f. i is not affected. Correspondingly, the total encoding error can be\\ndecreased by increasing an arbitrary number of edge lengths of the cube. The encoding by\\na population with a variability in the tuning curve geometries as described is more precise\\nthan that by a uniform population. This is true/or arbitrary D. Zhang and Sejnowski [13]\\nconsider the more artificial situation of a correlated variability ofthe tuning widths: tuning\\ncurves are always assumed to be radially symmetric. This is indicated by the diagonal\\nline in Fig. 1a. A distribution of tuning widths restricted to this subset yields an average\\npopulation Fisher information ex: (O'D-2) and does not improve the encoding for D = 2 or\\n\\nD=3.\\nFragmentation into D subpopulations. Finally, we study a family of distributions of\\ntuning widths which also yields a lower minimal encoding error than the uniform population. Let the density of tuning curves be given by\\n1 D\\n\\nPu(lT1,'\\\" ,lTD) = D\\n\\nL 6( lTi i=l\\n\\nAO')\\n\\nII 6(lTj - 0'),\\n\\n(14)\\n\\nj?-i\\n\\nwhere A > O. For A = 1, the population is uniform as in (7). For A :f. 1, the population\\nis split up into D subpopulations; in subpopulation i, lTi is modified while lTj == 0' for\\nj :f. i. See Fig. Id for an example. The diagonal elements ofthe average population Fisher\\ninformation are\\n\\n(Jii)u\\n\\n{1 + (D = f/DKtj)(F, T, D) -D-2\\nIT\\nDA\\n\\nI)A 2 }\\n\\n'\\n\\n(15)\\n\\nwhere the term in brackets will be abbreviated as 9D(A). (Jii)u does not depend on i in\\nthis case because of the symmetry in the sUbpopulations. Equation (15) and the uniform\\ncase (7) differ by 9D(A) which will now be discussed. Figure 3b shows 9D(A) for different\\nvalues of D. For A = 1, 9D(A) = 1 and (7) is recovered as expected. 9D(A) = 1\\nalso holds for A = 1/ (D - 1) < 1: narrowing one tuning width in each subpopulation\\nwill at first decrease the resolution provided D 2: 3; this is due to the fact that Ncode is\\ndecreased. For A < 1/(D - 1), however, 9D(A) > 1, and the resolution exceeds (Jii)u in\\n(7) because each neuron in the i-th subpopulation carries a high Fisher information in the\\ni-th dimension. D = 2 is a special case where no impairment of encoding occurs because\\nthe effect of a decrease of Ncode is less pronounced. Interestingly, an increase in A also\\nyields an improvement in the encoding accuracy. This is a combined effect resulting from\\nan increase in Ncode on the one hand and the existence of D subpopulations, D - 1 of\\n\\n\\fNeural Representation of Multi-Dimensional Stimuli\\n\\n121\\n\\nwhich maintain their tuning widths in each dimension on the other hand. The discussion\\nof 9D(>\\\") leads to the following encoding strategy. For small >.., (Jii)u increases rapidly,\\nwhich suggests a fragmentation of the population into D subpopulations each of which\\nencodes one feature with high accuracy, i.e., one tuning width in each subpopulation is\\nsmall whereas the remaining tuning widths are broad. Like in the case discussed above, the\\ntheoretical limit of this method is a breakdown of the approximation of TJ == const. and the\\nvalidity of (6) due to insufficient receptive field overlap.\\n\\n4 Discussion and Outlook\\nWe have discussed the effects of a variation of the tuning widths on the encoding accuracy\\nobtained by a population of stochastically spiking neurons. The question of an optimal\\ntuning strategy has turned out to be more complicated than previously assumed. More\\nspecifically, the case which focused most attention in the literature - radially symmetric\\nreceptive fields [5, 1,9, 3, 13] - yields a worse encoding accuracy than most other cases we\\nhave studied: uniform populations with tuning curves which are not radially symmetric;\\ndistributions of tuning curves around some symmetric or non-symmetric tuning curve; and\\nthe fragmentation of the population into D subpopulations each of which is specialized in\\none stimulus feature.\\nIn a next step, the theoretical results will be compared to empirical data on encoding properties of neural popUlations. One aspect is the existence of sensory maps which consist\\nof neural subpopulations with characteristic tuning properties for the features which are\\nrepresented. For example, receptive fields of auditory neurons in the midbrain of the barn\\nowl have elongated shapes [6]. A second aspect concerns the short-term dynamics of receptive fields. Using single-unit recordings in anaesthetized cats, Worgotter et al. [12]\\nobserved changes in receptive field size taking place in 50-lOOms. Our findings suggest\\nthat these dynamics alter the resolution obtained for the corresponding stimulus features.\\nThe observed effect may therefore realize a mechanism of an adaptable selective signal\\nprocessing.\\n\\nReferences\\n[1] Baldi, P. & HeiJigenberg, W. (1988) BioI. Cybern. 59:313-318.\\n[2] Deco, G. & Obradovic, D. (1997) An Information-Theoretic Approach to Neural Computing.\\nNew York: Springer.\\n[3] Eurich, C. W. & Schwegler, H. (1997) BioI. Cybern. 76: 357-363.\\n\\n[4] Eurich, C. W. & Wilke, S. D. (2000) NeuraL Compo (in press).\\n[5] Hinton, G. E., McClelland, J. L. & Rumelhart, D. E (1986) In Rumelhart, D. E. & McClelland,\\nJ. L. (eds.), ParaLLeL Distributed Processing, Vol. 1, pp. 77-109. Cambridge MA: MIT Press.\\n[6] Knudsen, E. I. & Konishi, M. (1978) Science 200:795-797.\\n[7] Kuffter, S. W. (1953) 1. Neurophysiol. 16:37-68.\\n[8] Lettvin, J. Y., Maturana, H. R., McCulloch, W. S. & Pitts, W. H. (1959) Proc. Inst. Radio Eng.\\nNY 47:1940-1951.\\n[9] Snippe, H. P. & Koenderink, J. J. (1992) BioI. Cybern. 66:543-551.\\n[10] Wiggers, W., Roth, G., Eurich, C. W. & Straub, A. (1995) J. Camp. Physiol. A 176:365-377.\\n[11] Wilke, S. D. & Eurich, C. W. (1999) In Verleysen, M. (ed.), ESANN 99, European Symposium\\non Artificial Neural Networks, pp. 435-440. Brussels: D-Facto.\\n[12] Worgotter, F., Suder, K., Zhao, Y., Kerscher, N., Eysel, U. T. & Funke, K. (1998) Nature\\n396:165-168.\\n[13] Zhang, K. & Sejnowski, T. J. (1999) NeuraL Compo 11:75-84.\\n\\n\\f\",\n          \"Searching for Character Models\\n\\nJaety Edwards\\nDepartment of Computer Science\\nUC Berkeley\\nBerkeley, CA 94720\\njaety@cs.berkeley.edu\\n\\nDavid Forsyth\\nDepartment of Computer Science\\nUC Berkeley\\nBerkeley, CA 94720\\ndaf@cs.berkeley.edu\\n\\nAbstract\\nWe introduce a method to automatically improve character models for a\\nhandwritten script without the use of transcriptions and using a minimum\\nof document specific training data. We show that we can use searches for\\nthe words in a dictionary to identify portions of the document whose\\ntranscriptions are unambiguous. Using templates extracted from those\\nregions, we retrain our character prediction model to drastically improve\\nour search retrieval performance for words in the document.\\n\\n1 Introduction\\nAn active area of research in machine transcription of handwritten documents is reducing\\nthe amount and expense of supervised data required to train prediction models. Traditional\\nOCR techniques require a large sample of hand segmented letter glyphs for training. This\\nper character segmentation is expensive and often impractical to acquire, particularly if the\\ncorpora in question contain documents in many different scripts.\\nNumerous authors have presented methods for reducing the expense of training data by\\nremoving the need to segment individual characters. Both Kopec et al [3] and LeCun et al\\n[5] have presented models that take as input images of lines of text with their ASCII transcriptions. Training with these datasets is made possible by explicitly modelling possible\\nsegmentations in addition to having a model for character templates.\\nIn their research on ?wordspotting?, Lavrenko et al [4] demonstrate that images of entire\\nwords can be highly discriminative, even when the individual characters composing the\\nword are locally ambiguous. This implies that images of many sufficiently long words\\nshould have unambiguous transcriptions, even when the character models are poorly tuned.\\nIn our previous work, [2], the discriminatory power of whole words allowed us to achieve\\nstrong search results with a model trained on a single example per character.\\nThe above results have shown that A) one can learn new template models given images of\\ntext lines and their associated transcriptions, [3, 5] without needing an explicit segmentation\\nand that B) entire words can often be identified unambiguously, even when the models for\\nindividual characters are poorly tuned. [2, 4]. The first of these two points implies that\\ngiven a transcription, we can learn new character models. The second implies that for at\\nleast some parts of a document, we should be able to provide that transcription ?for free?,\\nby matching against a dictionary of known words.\\n\\n\\fs1\\n\\ns2\\n\\ns3\\n\\ns4\\n\\ns5\\n\\ns6\\n\\ns7\\n\\ns8\\n\\n?d\\n\\ndi\\n\\nix\\n\\nxe\\n\\ner\\n\\nri\\n\\nis\\n\\ns?\\n\\nFigure 1: A line, and the states that generate it. Each state st is defined by its left and\\nright characters ctl and ctr (eg ?x? and ?e? for s4 ). In the image, a state spans half of each\\nof these two characters, starting just past the center of the left character and extending to\\nthe center of the right character, i.e. the right half of the ?x? and the left half of the ?e?\\nin s4 . The relative positions of the two characters is given by a displacement vector dt\\n(superimposed on the image as white lines). Associating states with intracharacter spaces\\ninstead of with individual characters allows for the bounding boxes of characters to overlap\\nwhile maintaining the independence properties of the Markov chain.\\nIn this work we combine these two observations in order to improve character models\\nwithout the need for a document specific transcription. We provide a generic dictionary of\\nwords in the target language. We then identify ?high confidence? regions of a document.\\nThese are image regions for which exactly one word from our dictionary scores highly\\nunder our model. Given a set of high confidence regions, we effectively have a training\\ncorpus of text images with associated transcriptions. In these regions, we infer a segmentation and extract new character examples. Finally, we use these new exemplars to learn\\nan improved character prediction model. As in [2], our document in this work is a 12th\\ncentury manuscript of Terence?s Comedies obtained from Oxford?s Bodleian library [1].\\n\\n2 The Model\\nHidden Markov Models are a natural and widely used method for modeling images of text.\\nIn their simplest incarnation, a hidden state represents a character and the evidence variable\\nis some feature vector calculated at points along the line. If all characters were known to\\nbe of a single fixed width, this model would suffice. The probability of a line under this\\nmodel is given as\\nY\\np(line) = p(c1 |?)\\np(ct |ct?1 )p(im[w?(t?1):w?t]|ct )\\n(1)\\nt>1\\n\\nwhere ct represents the tth character on the line, ? represents the start state, w is the width\\nof a character, and im[w(t?1)+1:wt] represents the column of pixels beginning at column\\nw ? (t ? 1) + 1 of the image and ending at column w ? t, (i.e. the set of pixels spanned by\\nc)\\nUnfortunately, character?s widths do vary quite substantially and so we must extend the\\nmodel to accommodate different possible segmentations. A generalized HMM allows us to\\ndo this. In this model a hidden state is allowed to emit a variable length series of evidence\\nvariables. We introduce an explicit distribution over the possible widths of a character.\\nLetting dt be the displacement vector associated with the tth character, and ctx refer to the\\nx location of the left edge of a character on the line, the probability of a line under this\\nrevised model is\\nY\\np(line) = p(c1 |?)\\np(ct |ct?1 )p(dt |ct )p(im[ctx +1:ctx +d] |dt , ct )\\n(2)\\nt>1\\n\\nThis is the model we used in [2]. It performs far better than using an assumption of fixed\\nwidths, but it still imposes unrealistic constraints on the relative positions of characters. In\\n\\n\\fparticular, the portion of the ink generated by the current character is assumed to be independent of the preceding character. In other words, the model assumes that the bounding\\nboxes of characters do not overlap. This constraint is obviously unrealistic. Characters\\nroutinely overlap in our documents. ?f?s, for instance, form ligatures with most following characters. In previous work, we treated this overlap as noise, hurting our ability to\\ncorrectly localize templates. Under this model, local errors of alignment would also often propagate globally, adversely affecting the segmentation of the whole line. For search,\\nthis noisy segmentation still provides acceptable results. In this work, however, we need\\nto extract new templates, and thus correct localization and segmentation of templates is\\ncrucial.\\nIn our current work, we have relaxed this constraint, allowing characters to partially overlap. We achieve this by changing hidden states to represent character bigrams instead of\\nsingle characters (Figure 1). In the image, a state now spans the pixels from just past the\\ncenter of the left character to the pixel containing the center of the right character. We\\nadjust our notation somewhat to reflect this change, letting st now represent the tth hidden state and ctl and ctr be the left and right characters associated with s. dt is now the\\ndisplacement vector between the centers of ctl and ctr .\\nThe probability of a line under this, our actual, model is\\nY\\np(line) = p(s1 |?)\\np(st |st?1 )p(dt |ctl , ctr )p(im[stx +1:stx +dt ]|ctl , ctr , dt )\\n\\n(3)\\n\\nt>1\\n\\nThis model allows overlap of bounding boxes, but it does still make the assumption that\\nthe bounding box of the current character does not extend past the center of the previous\\ncharacter. This assumption does not fully reflect reality either. In Figure 1, for example,\\nthe left descender of the x extends back further than the center of the preceding character.\\nIt does, however, accurately reflect the constraints within the heart of the line (excluding\\nascenders and descenders). In practice, it has proven to generate very accurate segmentations. Moreover, the errors we do encounter no longer tend to affect the entire line, since\\nthe model has more flexibility with which to readjust back to the correct segmentation.\\n2.1 Model Parameters\\nOur transition distribution between states is simply a 3-gram character model. We train this\\nmodel using a collection of ASCII Latin documents collected from the web. This set does\\nnot include the transcriptions of our documents.\\nConditioned on displacement vector, the emission model for generating an image chunk\\ngiven a state is a mixture of gaussians. We associate with each character a set of image\\nwindows extracted from various locations in the document. We initialize these sets with\\none example a piece from our hand cut set (Figure 2). We adjust the probability of an image\\ngiven the state to include the distribution over blocks by expanding the last term of Equation\\n3 to reflect this mixture. Letting bck represent the k th exemplar in the set associated with\\ncharacter c, the conditional probability of an image region spanning the columns from x to\\nx? is given as\\nX\\np(imx:x? |ctl , ctr , dt ) =\\np(imx:x? |bctl i , bctr j , dt )\\n(4)\\ni,j\\n\\nIn principle, the displacement vectors should now be associated with an individual block,\\nnot a character. This is especially true when we have both upper and lower case letters.\\nHowever, our model does not seem particularly sensitive to this displacement distribution\\nand so in practice, we have a single, fairly loose, displacement distribution per character.\\nGiven a displacement vector, we can generate the maximum likelihood template image\\nunder our model by compositing the correct halves of the left and right blocks. Reshaping\\n\\n\\fthe image window into a vector, the likelihood of an image window is then modeled as\\na gaussian, using the corresponding pixels in the template as the means, and assuming\\na diagonal covariance matrix. The covariance matrix largely serves to mask out empty\\nregions of a character?s bounding box, so that we do not pay a penalty when the overlap of\\ntwo characters? bounding boxes contains only whitespace.\\n2.2 Efficiency Considerations\\nThe number of possible different templates for a state is O(|B| ? |B| ? |D|), where |B| is\\nthe number of different possible blocks and |D| is the number of candidate displacement\\nvectors. To make inference in this model computationally feasible, we first restrict the\\ndomain of d. For a given pair of blocks bl and br , we consider only displacement vectors\\nwithin some small x distance from a mean displacement mbl ,br , and we have a uniform\\ndistribution within this region. m is initialized from the known size of our single hand cut\\ntemplate. In the current work, we do not relearn the m. These are held fixed and assumed\\nto be the same for all blocks associated with the same letter.\\nEven when restricting the number of d?s under consideration as discussed above, it is computationally infeasible to consider every possible location and pair of blocks. We therefore\\nprune our candidate locations by looking at the likelihood of blocks in isolation and only\\nconsidering locations where there is a local optimum in the response function and whose\\nvalue is better than a given threshold. In this case our threshold for a given location is that\\nL(block) < .7L(background) (where L(x) represents the negative log likelihood of x).\\nIn other words, a location has to look at least marginally more like a given block than it\\nlooks like the background.\\nAfter pruning locations in this manner, we are left with a discrete set of ?sites,? where we\\ndefine a site as the tuple (block type, x location, y location). We can enumerate the set of\\npossible states by looking at every pair of sites whose displacement vector has a non-zero\\nprobability.\\n2.3 Inference In The Model\\nThe statespace defined above is a directed acyclic graph, anchored at the left edge and\\nright edges of a line of text. A path through this lattice defines both a transcription and\\na segmentation of the line into individual characters. Inference in this model is relatively\\nstraightforward because of our constraint that each character may overlap only one preceding and one following character, and our restriction of displacement vectors to a small\\ndiscrete range. The first restriction means that we need only consider binary relations between templates. The second preserves the independence relationships of an HMM. A\\ngiven state st is independent of the rest of the line given the values of all other states within\\ndmax of either edge of st (where dmax is the legal displacement vector with the longest\\nx component.) We can therefore easily calculate the best path or explicitly calculate the\\nposterior of a node by traversing the state graph in topological order, sorted from left to\\nright. The literature on Weighted Finite State Transducers ([6], [5]) is a good resource for\\nefficient algorithms on these types of statespace graph.\\n\\n3 Learning Better Character Templates\\nWe initialize our algorithm with a set of handcut templates, exactly 1 per character, (Figure\\n2), and our goal is to construct more accurate character models automatically from unsupervised data. As noted above, we can easily calculate the posterior of a given site under\\nour model. (Recall that a site is a particular character template at a given (x,y) location in\\nthe line.) The traditional EM approach to estimating new templates would be to use these\\n\\n\\fFigure 2: Original Training Data These 22 glyphs are our only document specific training\\ndata. We use the model based on these characters to extract the new examples shown below\\n\\nFigure 3: Examples of extracted templates We extract new templates from high confidence\\nregions. From these, we choose a subset to incorporate into the model as new exemplars.\\nTemplates are chosen iteratively to best cover the space of training examples. Notice that\\nfor ?q? and ?a?, we have extracted capital letters, of which there were no examples in\\nour original set of glyphs. This happens when the combination of constraints from the\\ndictionary the surrounding glyphs make a ?q? or ?a? the only possible explanation for\\nthis region, even though its local likelihood is poor.\\n\\nsites as training examples, weighted by their posteriors. Unfortunately, the constraints imposed by 3 and even 4-gram character models seem to be insufficient. The posteriors of\\nsites are not discriminative enough to get learning off the ground.\\nThe key to successfully learning new templates lies is the observation from our previous\\nwork [2], that even when the posteriors of individual characters are not discriminative, one\\ncan still achieve very good search results with the same model. The search word in effect\\nserves as its own language model, only allowing paths through the state graph that actually\\ncontain it, and the longer the word the more it constrains the model. Whole words impose\\nmuch tighter constraints than a 2 or 3-gram character model, and it is only with this added\\npower that we can successfully learn new character templates.\\nWe define the score for a search as the negative log likelihood of the best path containing\\nthat word. With sufficiently long words, it becomes increasingly unlikely that a spurious\\npath will achieve a high score. Moreover, if we are given a large dictionary of words and\\nno alternative word explains a region of ink nearly as well as the best scoring word, then\\nwe can be extremely confident that this is a true transcription of that piece of ink.\\nStarting with a weak character model, we do not expect to find many of these ?high confidence? regions, but with a large enough document, we should expect to find some. From\\nthese regions, we can extract new, reliable templates with which to improve our character\\nmodels. The most valuable of these new templates will be those that are significantly different from any in our current set. For example, in Figure 3, note that our system identifies\\ncapital Q?s, even though our only input template was lower case. It identifies this ink as\\na Q in much the same way that a person solves a crossword puzzle. We can easily infer\\nthe missing character in the string ?obv-ous? because the other letters constrain us to one\\npossible solution. Similarly, if other character templates in a word match well, then we can\\nunambiguously identify the other, more ambiguous ones. In our Latin case, ?Quid? is the\\nonly likely explanation for ?-uid?.\\n3.1 Extracting New Templates and Updating The Model\\nWithin a high confidence region we have both a transcription and a localization of template\\ncenters. It remains only to cut out new templates. We accomplish this by creating a template\\nimage for the column of pixels from the corresponding block templates and then assigning\\nimage pixels to the nearest template character (measured by Euclidean distance).\\nGiven a set of templates extracted from high confidence regions, we choose a subset of\\n\\n\\fScore Under Model\\n\\nworse\\n3400\\n3350\\n3300\\nbest\\nConfidence Margins\\n\\nFigure 4: Each line segment in the lower figure represents a proposed location for a word\\nfrom our dictionary. It?s vertical height is the score of that location under our model. A\\nlower score represents a better fit. The dotted line is the score of our model?s best possible\\npath. Three correct words, ?nec?, ?quin? and ?dari?, are actually on the best path. We\\ndefine the confidence margin of a location as the difference in score between the best\\nfitting word from our dictionary and the next best.\\n\\nFigure 5: Extracting Templates For a region with sufficiently high confidence margin, we\\nconstruct the maximum likelihood template from our current exemplars. left, and we assign\\npixels from the original image to a template based on its distance to the nearest pixel in\\nthe template image, extracting new glyph exemplars right. These new glyphs become the\\nexemplars for our next round of training.\\n\\ntemplates that best explain the remaining examples. We do this in a greedy fashion by\\nchoosing the example whose likelihood is lowest under our current model and adding it to\\nour set. Currently, we threshold the number of new templates for the sake of efficiency. Finally, given the new set of templates, we can add them to the model and rerun our searches,\\npotentially identifying new high confidence regions.\\n\\n4 Results\\nOur algorithm iteratively improves the character model by gathering new training data from\\nhigh confidence regions. Figure 3 shows that this method finds new templates significantly\\ndifferent from the originals. In this document, our set of examples after one round appears\\nto cover the space of character images well, at least those in lower case. Our templates are\\nnot perfect. The ?a?, for instance, has become associated with at least one block that is in\\nfact an ?o?. These mistakes are uncommon, particularly if we restrict ourselves to longer\\nwords. Those that do occur introduce a tolerable level noise into our model. They make\\ncertain regions of the document more ambiguous locally, but that local ambiguity can be\\novercome with the context provided by surrounding characters and a language model.\\nImproved Character Models We evaluate the method more quantitatively by testing the\\nimpact of the new templates on the quality of searches performed against the document.\\nTo search for a given word, we rank lines by the ratio of the maximum likelihood transcription/segmentation that contains the search word to the likelihood of the best possible\\nsegmentation/transcription under our model. The lowest possible search score is 1, happening when the search word is actually a substring of the maximum likelihood transcription.\\nHigher scores mean that the word is increasingly unlikely under our model. In Figure 7, the\\nfigure on the left shows the improvement in ranking of the lines that truly contain selected\\nsearch words. The odd rows (in red) are search results using only the original 22 glyphs,\\n\\n\\f20\\n40\\n60\\n80\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\n600\\n\\nRnd 2\\n\\nRnd 1\\n\\n2700\\n2650\\n2600\\ndotted (wrong):\\nsolid (correct):\\n1920\\n1900\\n1880\\n1860\\n1840\\ndotted (wrong):\\nsolid (correct):\\n\\niam\\n\\nnupta\\nnuptiis\\n\\ninquam\\n\\n(v|u)ideo\\nvidet\\n\\nnupta\\nnuptiis\\n\\npost inquam\\npostquam\\n\\n(v|u)ideo\\nvidet\\n\\nFigure 6: Search Results with (Rnd 1) initial templates only and with (Rnd 2) templates\\nextracted from high confidence regions. We show results that have a score within 5% of the\\nbest path. Solid Lines are the results for the correct word. Dotted lines represent other\\nsearch results, where we have made a few larger in order to show those words that are\\nthe closest competitors to the true word. Many alternative searches, like the highlighted\\n?post? are actually portions of the correct larger words. These restrict our selection of\\nconfidence regions, but do not impinge on search quality.\\nEach correct word has significantly improved after one round of template reestimation.\\n?iam? has been correctly identified, and is a new high confidence region. Both ?nuptiis?\\nand ?postquam? are now the highest likelihood words for their region barring smaller\\nsubsequences, and ?videt? has narrowed the gap between its competitor ?video?.\\nwhile the even rows (in green) use an additional 332 glyphs extracted from high confidence\\nregions. Search results are markedly improved in the second model. The word ?est?, for\\ninstance, only had 15 of 24 of the correct lines in the top 100 under the original model,\\nwhile under the learned model all 24 are not only present but also more highly ranked.\\nImproved Search Figure 6 shows the improved performance of our refitted model for\\na single line. Most words have greatly improved relative to their next best alternative.\\n?postquam? and ?iam? were not even considered by the original model and now are nearly\\noptimal. The right of Figure 7 shows the average precision/recall curve under each model\\nfor 21 words with more than 4 occurrences in the dataset. Precision is the percentage\\nof lines truly containing a word in the top n search results, and recall is the percentage\\nof all lines containing the word returned in the top n results. The learned model clearly\\ndominates. The new model also greatly improves performance for rare words. For 320\\nwords ocurring just once in the dataset, 50% are correctly returned as the top ranked result\\nunder the original model. Under the learned model, this number jumps to 78%.\\n\\n5 Conclusions and Future Work\\nIn most fonts, characters are quite ambiguous locally. An ?n? looks like a ?u?, looks like\\n?ii?, etc. This ambiguity is the major hurdle to the unsupervised learning of character\\ntemplates. Language models help, but the standard n-gram models provide insufficient\\nconstraints, giving posteriors for character sites too uninformative to get EM off the ground.\\n\\n\\fAggregate Precision/Recall Curve\\n\\nSelected Words, Top 100 Returned Lines\\n\\nPrecision\\n\\nest\\n(15,24)/24\\nnescio\\n( 1, 1)/ 1\\npostquam\\n( 0, 2)/ 2\\nquod\\n(14,14)/14\\nmoram\\n( 0, 2)/ 2\\nnon\\n( 8, 8)/ 8\\nquid\\n( 9, 9)/ 9\\n10 20 30 40 50 60 70 80 90100\\n\\n0.75\\n0.7\\n0.65\\n0.6\\n0.55\\n0.5\\n0.45\\n0.4\\n0.35\\n\\nOriginal Model\\nRefit Model\\n0.2\\n\\n0.4\\n0.6\\nRecall\\n\\n0.8\\n\\n1\\n\\nFigure 7: The figure on the left shows the those lines with the top 100 scores that actually\\ncontain the specified word. The first of each set of two rows (in red) is the results from\\nRound 1. The second (in green) is the results for Round 2. Almost all search words in our\\ncorpus show a significant improvement. The numbers to the right (x/y) mean that out of\\ny lines that actually contained the search word in our document, x of them made it into\\nthe top ten. On the right are average precision/recall curves for 21 high frequency words\\nunder the model with our original templates (Rnd 1) and after refitting with new extracted\\ntemplates (Rnd 2). Extracting new templates vastly improves our search quality\\nAn entire word is much different. Given a dictionary, we expect many word images to have\\na single likely transcription even if many characters are locally ambiguous. We show that\\nwe can identify these high confidence regions even with a poorly tuned character model. By\\nextracting new templates only from these regions of the document, we overcome the noise\\nproblem and significantly improve our character models. We demonstrate this improvement\\nfor the task of search where the refitted models have drastically better search responses than\\nwith the original. Our method is indifferent to the form of the actual character emission\\nmodel. There is a rich literature in character prediction from isolated image windows, and\\nwe expect that incorporating more powerful character models should provide even greater\\nreturns and help us in learning less regular scripts.\\nFinding high confidence regions to extract good training examples is a broadly applicable concept. We believe this work should extend to other problems, most notably speech\\nrecognition. Looked at more abstractly, our use of language model in this work is actually encoding spatial constraints. The probability of a character given an image window\\ndepends not only on the identify of surrounding characters but also on their spatial configuration. Integrating context into recognition problems is an area of intense research in\\nthe computer vision community, and we are investigating extending the idea of confidence\\nregions to more general object recognition problems.\\n\\nReferences\\n[1] Early Manuscripts at Oxford University. Bodleian library ms. auct. f. 2.13. http://image.ox.ac.uk/.\\n[2] J. Edwards, Y.W. Teh, D. Forsyth, R. Bock, M. Maire, and G. Vesom. Making latin manuscripts\\nsearchable using ghmm?s. In NIPS 17, pages 385?392. 2005.\\n[3] G. Kopec and M. Lomelin. Document-specific character template estimation. In Proceedings,\\nDocument Image Recognition III, SPIE, 1996.\\n[4] V. Lavrenko, T. Rath, and R. Manmatha. Holistic word recognition for handwritten historical\\ndocuments. In dial, pages 278?287, 2004.\\n[5] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document\\nrecognition. Proceedings of the IEEE, 86(11):2278?2324, 1998.\\n[6] M. Mohri, F. Pereira, and M. Riley. Weighted finite state transducers in speech recognition. ISCA\\nITRW Automatic Speech Recognition, pages 97?106, 2000.\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["papers = papers.sample(100)"],"metadata":{"id":"YxXmZ5q5gAHm","executionInfo":{"status":"ok","timestamp":1751185047194,"user_tz":-330,"elapsed":5,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["papers.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"id":"JDwLOUvakM2x","executionInfo":{"status":"ok","timestamp":1751185049078,"user_tz":-330,"elapsed":169,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"523e3e5e-f95b-4c3f-d8d9-347824a906f0"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      year                                              title  \\\n","4823  2014  Online and Stochastic Gradient Methods for Non...   \n","159   1995                     Factorial Hidden Markov Models   \n","1815  2004  Optimal Information Decoding from Neuronal Pop...   \n","3282  2010     Scrambled Objects for Least-Squares Regression   \n","7176  1994     Learning Prototype Models for Tangent Distance   \n","1084  2001  Information-Geometrical Significance of Sparsi...   \n","499   1997          Prior Knowledge in Support Vector Kernels   \n","1145  2001                      Speech Recognition using SVMs   \n","4750  2014  Capturing Semantically Meaningful Word Depende...   \n","3039  2009  A Rate Distortion Approach for Semi-Supervised...   \n","\n","                                               abstract  \\\n","4823  Modern applications in sensitive domains such ...   \n","159                                    Abstract Missing   \n","1815                                   Abstract Missing   \n","3282  We consider least-squares regression using a r...   \n","7176                                   Abstract Missing   \n","1084                                   Abstract Missing   \n","499                                    Abstract Missing   \n","1145                                   Abstract Missing   \n","4750  We develop a fast algorithm for the Admixture ...   \n","3039  We propose a novel information theoretic appro...   \n","\n","                                             paper_text  \n","4823  Online and Stochastic Gradient Methods for\\nNo...  \n","159   Factorial Hidden Markov Models\\nZoubin Ghahram...  \n","1815  Optimal information decoding from neuronal\\npo...  \n","3282  Scrambled Objects for Least-Squares Regression...  \n","7176  Learning Prototype Models for Tangent\\nDistanc...  \n","1084  Information-Geometrical Significance of\\nSpars...  \n","499   Prior Knowledge in Support Vector Kernels\\n\\nB...  \n","1145  Speech Recognition using SVMs\\n\\nNathan Smith\\...  \n","4750  Capturing Semantically Meaningful Word\\nDepend...  \n","3039  A Rate Distortion Approach for Semi-Supervised...  "],"text/html":["\n","  <div id=\"df-511cff14-e5a3-4eab-9ace-47d7cf6e18d0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>paper_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4823</th>\n","      <td>2014</td>\n","      <td>Online and Stochastic Gradient Methods for Non...</td>\n","      <td>Modern applications in sensitive domains such ...</td>\n","      <td>Online and Stochastic Gradient Methods for\\nNo...</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>1995</td>\n","      <td>Factorial Hidden Markov Models</td>\n","      <td>Abstract Missing</td>\n","      <td>Factorial Hidden Markov Models\\nZoubin Ghahram...</td>\n","    </tr>\n","    <tr>\n","      <th>1815</th>\n","      <td>2004</td>\n","      <td>Optimal Information Decoding from Neuronal Pop...</td>\n","      <td>Abstract Missing</td>\n","      <td>Optimal information decoding from neuronal\\npo...</td>\n","    </tr>\n","    <tr>\n","      <th>3282</th>\n","      <td>2010</td>\n","      <td>Scrambled Objects for Least-Squares Regression</td>\n","      <td>We consider least-squares regression using a r...</td>\n","      <td>Scrambled Objects for Least-Squares Regression...</td>\n","    </tr>\n","    <tr>\n","      <th>7176</th>\n","      <td>1994</td>\n","      <td>Learning Prototype Models for Tangent Distance</td>\n","      <td>Abstract Missing</td>\n","      <td>Learning Prototype Models for Tangent\\nDistanc...</td>\n","    </tr>\n","    <tr>\n","      <th>1084</th>\n","      <td>2001</td>\n","      <td>Information-Geometrical Significance of Sparsi...</td>\n","      <td>Abstract Missing</td>\n","      <td>Information-Geometrical Significance of\\nSpars...</td>\n","    </tr>\n","    <tr>\n","      <th>499</th>\n","      <td>1997</td>\n","      <td>Prior Knowledge in Support Vector Kernels</td>\n","      <td>Abstract Missing</td>\n","      <td>Prior Knowledge in Support Vector Kernels\\n\\nB...</td>\n","    </tr>\n","    <tr>\n","      <th>1145</th>\n","      <td>2001</td>\n","      <td>Speech Recognition using SVMs</td>\n","      <td>Abstract Missing</td>\n","      <td>Speech Recognition using SVMs\\n\\nNathan Smith\\...</td>\n","    </tr>\n","    <tr>\n","      <th>4750</th>\n","      <td>2014</td>\n","      <td>Capturing Semantically Meaningful Word Depende...</td>\n","      <td>We develop a fast algorithm for the Admixture ...</td>\n","      <td>Capturing Semantically Meaningful Word\\nDepend...</td>\n","    </tr>\n","    <tr>\n","      <th>3039</th>\n","      <td>2009</td>\n","      <td>A Rate Distortion Approach for Semi-Supervised...</td>\n","      <td>We propose a novel information theoretic appro...</td>\n","      <td>A Rate Distortion Approach for Semi-Supervised...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-511cff14-e5a3-4eab-9ace-47d7cf6e18d0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-511cff14-e5a3-4eab-9ace-47d7cf6e18d0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-511cff14-e5a3-4eab-9ace-47d7cf6e18d0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-ef7f6ea5-69a4-422e-90a9-b50ccc30c60f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef7f6ea5-69a4-422e-90a9-b50ccc30c60f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-ef7f6ea5-69a4-422e-90a9-b50ccc30c60f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"papers\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 1994,\n        \"max\": 2014,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1995,\n          2001,\n          2014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Capturing Semantically Meaningful Word Dependencies with an Admixture of Poisson MRFs\",\n          \"Factorial Hidden Markov Models\",\n          \"Information-Geometrical Significance of Sparsity in Gallager Codes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Abstract Missing\",\n          \"We propose a novel information theoretic approach for semi-supervised learning of conditional random fields. Our approach defines a training objective that combines the conditional likelihood on labeled data and the mutual information on unlabeled data. Different from previous minimum conditional entropy semi-supervised discriminative learning methods, our approach can be naturally cast into the rate distortion theory framework in information theory. We analyze the tractability of the framework for structured prediction and present a convergent variational training algorithm to defy the combinatorial explosion of terms in the sum over label configurations. Our experimental results show that the rate distortion approach outperforms standard $l_2$ regularization and minimum conditional entropy regularization on both multi-class classification and sequence labeling problems.\",\n          \"We consider least-squares regression using a randomly generated subspace G_P\\\\subset F of finite dimension P, where F is a function space of infinite dimension, e.g.~L_2([0,1]^d).  G_P is defined as the span of P random features  that are linear combinations of the basis functions of F weighted by random Gaussian i.i.d.~coefficients. In particular, we consider multi-resolution random combinations at all scales of a given mother function,  such as a hat function or a wavelet. In this latter case, the resulting Gaussian objects are called {\\\\em scrambled wavelets} and we show that they enable to approximate functions in Sobolev spaces H^s([0,1]^d). As a result, given N data, the least-squares estimate \\\\hat g built from P scrambled wavelets has excess risk ||f^* - \\\\hat g||_\\\\P^2 = O(||f^*||^2_{H^s([0,1]^d)}(\\\\log N)/P + P(\\\\log N )/N) for target functions f^*\\\\in H^s([0,1]^d) of smoothness order s>d/2. An interesting aspect of the resulting bounds is that they do not depend on the distribution \\\\P from which the data are generated, which is important in a statistical regression setting considered here. Randomization enables to adapt to any possible distribution.   We conclude by describing an efficient numerical implementation using lazy expansions with numerical complexity \\\\tilde O(2^d N^{3/2}\\\\log N + N^2), where d is the dimension of the input space.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Capturing Semantically Meaningful Word\\nDependencies with an Admixture of Poisson MRFs\\n\\nDavid I. Inouye\\n\\nPradeep Ravikumar\\nInderjit S. Dhillon\\nDepartment of Computer Science\\nUniversity of Texas at Austin\\n{dinouye,pradeepr,inderjit}@cs.utexas.edu\\n\\nAbstract\\nWe develop a fast algorithm for the Admixture of Poisson MRFs (APM) topic\\nmodel [1] and propose a novel metric to directly evaluate this model. The APM\\ntopic model recently introduced by Inouye et al. [1] is the first topic model that\\nallows for word dependencies within each topic unlike in previous topic models\\nlike LDA that assume independence between words within a topic. Research in\\nboth the semantic coherence of a topic models [2, 3, 4, 5] and measures of model\\nfitness [6] provide strong support that explicitly modeling word dependencies?as\\nin APM?could be both semantically meaningful and essential for appropriately\\nmodeling real text data. Though APM shows significant promise for providing\\na better topic model, APM has a high computational complexity because O(p2 )\\nparameters must be estimated where p is the number of words ([1] could only\\nprovide results for datasets with p = 200). In light of this, we develop a parallel alternating Newton-like algorithm for training the APM model that can handle p = 104 as an important step towards scaling to large datasets. In addition,\\nInouye et al. [1] only provided tentative and inconclusive results on the utility\\nof APM. Thus, motivated by simple intuitions and previous evaluations of topic\\nmodels, we propose a novel evaluation metric based on human evocation scores\\nbetween word pairs (i.e. how much one word ?brings to mind? another word [7]).\\nWe provide compelling quantitative and qualitative results on the BNC corpus\\nthat demonstrate the superiority of APM over previous topic models for identifying semantically meaningful word dependencies. (MATLAB code available at:\\nhttp://bigdata.ices.utexas.edu/software/apm/)\\n\\n1\\n\\nIntroduction and Related Work\\n\\nIn standard topic models such as LDA [8, 9], the primary representation for each topic is simply\\na list of top \\u000110 or 15 words. To understand a topic, a person must manually consider many of the\\npossible 10\\nrelationships and attempt to\\n2 pairwise relationships as well as possibly larger m-wise\\n\\u0001\\n10\\ninfer abstract meaning from this list of words. Of all the 2 pairwise relationships probably a\\nvery small number of them are direct relationships. For example, a topic with the list of words\\n?money?, ?fund?, ?exchange? and ?company? can be understood as referring to investment but this\\ncan only be inferred from a very high-level human abstraction of meaning. This problem has given\\nrise to research on automatically labeling topics with a topic word or phrase that summarizes the\\ntopic [10, 11, 12]. [13] propose to evaluate topic models by randomly replacing a topic word with\\na random word and evaluating whether a human can identify the intruding word. The intuition for\\nthis metric is that the top words of a good topic will be related, and therefore, a person will be\\nable to easily identify the word that does not have any relationship to the other words. [2, 3, 5]\\ncompute statistics related to Pointwise Mutual Information for all pairs of top words in a topic\\nand attempt to correlate this with human judgments. All of these metrics suggest that capturing\\n1\\n\\n\\fsemantically meaningful relationships between pairs of words is fundamental to the interpretability\\nand usefulness of topic models as a document summarization and exploration tool.\\nIn light of these metrics, [1] recently proposed a topic model called Admixture of Poisson MRFs\\n(APM) that relaxes the independence assumption for the topic distributions and explicitly models\\nword dependencies. This can be motivated in part by [6] who investigated whether the Multinomial (i.e. independent) assumption of word-topic distributions actually fits real-world text data.\\nSomewhat unsurprisingly, [6] found that the Multinomial assumption was often violated and thus\\ngives evidence that models with word dependencies?such as APM?may be a fundamentally more\\nappropriate model for text data.\\nPrevious research in topic modeling has implicitly uncovered this issue with model misfit by finding\\nthat models with 50, 100 or even 500 topics tend to perform better on semantic coherence experiments than smaller models with only 10 or 20 topics [4]. Though using more topics may allow topic\\nmodels to ignore the issue of word dependencies, using more topics can make the coherence of a\\ntopic model more difficult as suggested by [4] who found that using 100 or 500 topics did not significantly improve the coherence results over 50 topics. Intuitively, a topic model with a much smaller\\nnumber of topics (e.g. 5 or 10) is easier to comprehend. For instance, if training on newspaper text,\\nthe number of topics could roughly correspond to the number of sections in a newspaper such as\\nnews, weather and sports. Or, if modeling an encyclopedia, the top-level topics could be art, history,\\nscience, and society. Thus, rather than using more topics, APM opens the way for a promising topic\\nmodel that can overcome this model misfit issue while only using a small number of topics.\\nEven though APM shows promise for being a significantly more powerful and more realistic topic\\nmodel than previous models, the original paper acknowledged the significant computational complexity. Instead of needing to fit O(k(n + p)) parameters, APM needs to estimate O(k(n + p2 ))\\nparameters. [1] suggested that by using a sparsity prior (i.e. `1 regularization of the likelihood), this\\ncomputational complexity could be reduced. However, [1] could only produce some quantitative results on a very small dataset with only 200 words. In addition, the quantitative results from [1] were\\ntentative and inconclusive on whether APM could actually perform better than LDA in coherence\\nexperiments.\\nTherefore, in this paper, we seek to answer two major open questions regarding APM: 1) Is there an\\nalgorithm that can overcome the computational complexity of APM and handle real-world datasets?\\n2) Does the APM model actually capture more semantically interesting concepts that were not possible with previous topic models? We answer the first question by developing a parallel alternating\\nalgorithm whose independent subproblems are solved using a Newton-like algorithm similar to the\\nalgorithms developed for sparse inverse covariance estimation [14]. As in [14], this new APM\\nalgorithm exploits the sparsity of the solution to significantly reduce the computational time for\\ncomputing the approximate Newton direction. However, unlike [14], the APM model is solving for\\nk Poisson MRFs simultaneously whereas [14] is only solving for a single Gaussian MRF. Another\\ndifference from [14] is that the whole algorithm can be easily parallelized up to min(n, p).\\nFor the second question about the semantic utility of APM, we develop a novel evaluation metric that\\nmore directly evaluates the APM model against human judgments of semantic relatedness?a notion\\ncalled evocation introduced by [7]. Intuitively, the idea is that humans seek to understand traditional\\ntopic models by looking at the list of top words. They will implicitly attempt to find how these\\nwords are related and extract some more abstract meaning that generalizes the set of words. Thus,\\nthis evaluation metric attempts to explicitly score how well pairs of words capture some semantically\\nmeaningful word dependency. Previous research has evaluated topic models using word similarity\\nmeasures [4]. However, our work is different from [4] in three significant ways: 1) our metrics use\\nevocation rather than similarity (e.g. antonyms should have high evocation but low similarity), 2) we\\nevaluate top individual word pairs instead of rough aggregate statistics, and 3) we evaluate a topic\\nmodel that directly captures word dependencies (i.e. APM). We demonstrate that APM substantially\\noutperforms other topic models in both quantitative and qualitative ways.\\n\\n2\\n\\nBackground on Admixture of Poisson MRFs (APM)\\n\\nAdmixtures The general notion of admixtures introduced by [1] generalizes many previous topic\\nmodels including PLSA [15], LDA [8], and the Spherical Admixture Model (SAM) [16]. Admix2\\n\\n\\ftures have also been known as mixed membership models [17]. In contrast to mixture distributions\\nwhich assume that each observation is drawn from 1 of k component distributions, admixture distributions assume that each observation is drawn from an admixed distribution whose parameters are\\na mixture of component parameters. As examples of admixtures, PLSA and LDA are admixtures of\\nMultinomials whereas SAM is an admixture of Von-Mises Fisher distributions. In addition, because\\nof the connections between Poissons and Multinomials, PLSA and LDA can be seen as admixtures\\nof independent Poisson distributions [1].\\nPoisson MRFs (PMRF) Yang et al. [18] introduced a multivariate generalization of the Poisson\\nthat assumes that the conditional distributions are univariate Poisson which is similar to a Gaussian\\nMRF whose conditionals are Gaussian (unlike a Guassian MRF, however, the marginals are not\\nunivariate Poisson). A PMRF can be parameterized by a node vector ? and an edge matrix ? whose\\nnon-zeros encode the direct\\u0001 dependencies between words: PrPMRF (x | ?, ?) = exp ? T x+xT ?x?\\nPp\\ns=1 ln(xs !) ? A (?, ?) , where A (?, ?) is the log partition function needed for normalization.\\nThis formulation needs to be slightly modified to allow for positive edges using the ideas from [19].\\nThe log partition function can be approximated\\nPpby using the pseudo log-likelihood instead of the\\ntrue likelihood, which means that A (?, ?) ? s=1 exp(?s + xT ?s ). The reader should note that\\nbecause this is an MRF distribution, all the properties of MRFs apply to PMRFs including that a\\nword is independent of all other words given the value of its neighbors. For example, in a chain\\ngraph, all the variables are correlated with each other but they have a much simpler dependency\\nstructure that can be encoded with O(n) parameters. Therefore, PMRFs more directly and succinctly\\ncapture the dependencies between words as opposed to other simple statistics such as covariance or\\npointwise mutual information.\\nAdmixture of Poisson MRFs (APM) Inouye et al. [1] essentially constructed a new admixture model by using Poisson MRFs as the topic-word distributions instead of the usual Multinomial as in LDA. This allows for word dependencies within each topic. For example, if the word\\n?classification? appears in a document, ?supervised? is more likely to appear than in general documents. Given the admixture weights vector for a document the likelihood of a document\\nis sim\\u0001\\nPk\\nPk\\nply: PrAPM (x | w, ? 1...k , ?1...k ) = PrPMRF x | ? = j=1 wj ? j , ? = j=1 wj ?j (please see\\nAppendix A for notational conventions used throughout the paper). Inouye et al. [1] define a\\nDirichlet(?) prior on the admixture weights and a conjugate prior with hyperparameter ? on the\\nPMRF parameters which can be easily incorporated as pseudo counts. For our experiments as described in Sec. 4.1, we set ? = 1 (i.e. a uniform prior on admixture weights) and ? = {0, 1}.\\n\\n3\\n\\nParallel Alternating Newton-like Algorithm for APM\\n\\nIn the original APM paper [1], parameters were estimated by maximizing the joint approximate\\nposterior over all variables.1 Instead of maximizing jointly over all parameters, we split the problem\\ninto alternating convex optimization problems. Let us denote the likelihood part (i.e. the smooth\\npart) of the optimization function as g(W, ? 1...k , ?1...k ) and the non-smooth `1 regularization term\\nas h where the full negative posterior is defined as f = g + h. The smooth part of the approximate\\nposterior can be written as:\\ng=?\\n\\nn p\\nk\\nk\\nX\\n\\u0001i\\n1 XX h X\\nwij xis (?sj + xTi ?js ) ? exp\\nwij (?sj + xTi ?js ) ,\\nn i=1 s=1 j=1\\nj=1\\n\\n(1)\\n\\nwhere xi is the word-count vector for the ith document, wi is the admixture weight vector for the\\nith document, and ? j and ?j are the PMRF parameters for the jth component (see Appendix B for\\nderivation). By writing g in this form, it is straightforward to see that even though the whole optimization problem is not convex because of the interaction between the admixture weights w and the\\nPMRF parameters, the problem is convex if either the admixture weights W or the component parameters ? 1...k , ?1...k are held fixed. To simplify the notation in the following sections, we combine\\n1\\nThis posterior approximation was based on the pseudo-likelihood while ignoring the symmetry constraint\\nso that nodewise regression parameters are independent. This leads to an overcomplete parameterization for\\nAPM. For an overview of composite likelihood methods, see [20]. For a comparison of pseudo-likelihood\\nversus nodewise regressions, see [21].\\n\\n3\\n\\n\\fthe node (which is analogous to an intercept term in regression) and edge parameters by defining\\nzi = [1 xTi ]T , ?js = [?sj (?js )T ]T and ?s = [?1s ?2s ? ? ? ?ks ].\\nThus, we can alternate between optimizing two similar optimization problems where one has a nonsmooth `1 regularization and the other has the constraint that wi must lie on the simplex ?k :\\narg min\\n?1 ,?2 ,??? ,?p\\n\\narg min\\nw1 ,w2 ,??? ,wn ??k\\n\\np\\np\\nn\\ni X\\nX\\n1 Xh\\ns s\\nT s\\n?\\ntr(? ? ) ?\\nexp(zi ? wi ) +\\n?kvec(?s )\\\\1 k1\\nn s=1\\ns=1\\ni=1\\n\\n?\\n\\np\\nn\\ni\\nX\\n1 Xh T\\n?i wi ?\\nexp(ziT ?s wi )) ,\\nn i=1\\ns=1\\n\\n(2)\\n(3)\\n\\nwhere ?i and ?s are constants in the optimization that can be computed from the data matrix X and\\nthe other parameters that are being held fixed (see Alg. 2 in Appendix D for computation of ?s ).\\nThis alternating scheme is analogous to Alternating Least Squares (ALS) for Non-negative Matrix\\nFactorization (NMF) [22] and EM-like algorithms such as k-means. By writing the optimization as\\nin Eq. 2 and Eq. 3, we also expose the simple independence between the subproblems because they\\nare simple summations. Thus, we can easily parallelize both optimization problems upto min(n, p)\\nwith little overhead and simple changes to the code?in our MATLAB implementation, we only\\nchanged a for loop to a parfor loop.\\n3.1\\n\\nNewton-like Algorithms for Subproblems\\n\\nFor each of the subproblems, we develop Newton-like optimization algorithms. For the component\\nPMRFs, we borrow several important ideas from [14] including fixed and free sets of variables for\\nthe `1 regularized optimization problem. The overall idea is to construct a quadratic approximation\\naround the current solution and approximately optimize this simpler function to find a step direction.\\nUsually, finding the Newton direction requires computing the Hessian for all the optimization variables but because of the `1 regularization, we only need to focus on variables that might be non-zero.\\nThis set of free variables, denoted F, can be simply determined from the gradient and current iterate\\n[14]. Since usually there is only a small number of free variables compared to fixed variables (i.e. ?\\nis large enough), we can simply run coordinate descent on these free variables and only implicitly\\ncalculate Hessian information as needed in each coordinate descent step. After finding an approximate Newton direction, we find a step size that satisfies the Armijo rule and then update the iterate\\n(see Alg. 2 in Appendix D).\\nWe also employed a similar Newton-like algorithm for estimating the admixture weights. Instead of\\nthe `1 regularization term, however, this subproblem has the constraint that the admixture weights\\nwi must lie on the simplex so that each document can be properly interpreted as a convex mixture\\nof over topic parameters. For this constraint, we used a dual-coordinate descent algorithm to find\\nthe approximate Newton direction as in [23].\\nFinally, we put both subproblem algorithms together and alternate between the two (see Alg. 1 in\\nAppendix D). For tracing through different ? parameters, ? is initially set to ? so that the model\\ntrains an independent APM model first. Then, the initial ? = ?max is found by computing the largest\\ngradient of the final independent iteration. Every time the alternating algorithm converges, the value\\nof ? is decreased so that a set of models is trained for decreasing values of ?.\\n3.2\\n\\nTiming Results\\n\\nWe conducted two main timing experiments to show that the algorithm can be efficiently parallelized\\nand the algorithm can scale to reasonably large datasets. For the parallel timing experiment, we used\\nthe BNC corpus described in Sec. 4.1 (n = 4049, p = 1646) and fixed k = 5, ? = 8 and a total of\\n30 alternating iterations. For the large data experiment, we used a Wikipedia dataset formed from a\\nrecent Wikipedia dump by choosing the top 10k words neglecting stop words and then selecting the\\nlongest documents. We ran several main iterations of the algorithm with this dataset while fixing\\nthe parameters k = 5 and ? = 0.5. All timing experiments were conducted on the TACC Maverick\\nsystem with Intel Xeon E5-2680 v2 Ivy Bridge CPUs (2.80 GHz), 20 CPUs per node, and 12.8 GB\\nmemory per CPU (https://www.tacc.utexas.edu/).\\n4\\n\\n\\fThe parallel timing results can be seen in Fig. 1 (left) which shows that the algorithm does have\\nalmost linear speedup when parallelizing across multiple workers. Though we only had access to a\\nsingle computer with 20 processors, substantially more speed up could be obtained by using more\\nprocessors on a distributed computing system. This simple parallelism makes this algorithm viable\\nfor much larger datasets. The timing results for the Wikipedia can be seen in Fig. 1 (right). These\\nresults give an approximate computational complexity of O(np2 ) which show that the proposed\\nalgorithm has the potential for scaling to datasets where n is O(105 ) and p is O(104 ). The O(p2 )\\ncomes from the fact that there are p subproblems and each subproblem needs to calculate the gradient\\nwhich is O(p) as well as approximate the Newton direction for a subset of the variables. The\\nfirst iteration takes longer because the initial parameter values are na??vely set to 0 whereas future\\niterations start from reasonable initial value.\\nAPM Training Time on Wikipedia Dataset\\n\\nParallel Speedup on BNC Dataset\\n\\n4\\n\\nPerfect Speedup\\n\\n15\\n\\n1st Iter.\\n\\nTime (hrs)\\n\\nSpeedup\\n\\n20\\n\\nActual Speedup\\n\\n10\\n\\n5\\n\\n2.2\\n\\n5\\n\\n10\\n15\\n# of MATLAB Workers\\n\\n20\\n\\n2.2\\n\\n1\\n1\\n\\n0\\n\\n3.4\\n\\n3.1\\n\\n2\\n\\n0\\n\\n0\\n\\nAvg. Next 3 Iter.\\n\\n3\\n\\n0.6\\n\\nn = 20,000\\np = 5,000\\n# of Words = 50M\\n\\nn = 100,000\\np = 5,000\\n# of Words = 133M\\n\\nn = 20,000\\np = 10,000\\n# of Words = 57M\\n\\nFigure 1: (left) The speedup on the BNC dataset shows that the algorithm scales approximately linearly with the number of workers because the subproblems are all independent. (right) The timing\\nresults on the Wikipedia dataset show that the algorithm scales to larger datasets and has a computational complexity of approximately O(np2 ).\\n\\n4\\n\\nEvocation Metric\\n\\nBoyd-Graber et al. [7] introduced the notion of evocation which denotes the idea of which words\\n?evoke? or ?bring to mind? other words. There can be many types of evocation including the following examples from [7]: [rose - flower] (example), [brave - noble] (kind), [yell - talk] (manner),\\n[eggs - bacon] (co-occurence), [snore - sleep] (setting), [wet - desert] (antonymy), [work - lazy] (exclusivity), and [banana - kiwi] (likeness). This is distinctive from word similarity or synonymy since\\ntwo words can have very different meanings but ?bring to mind? the other word (e.g. antonyms).\\nThis notion of word relatedness is a much simpler but potentially more semantically meaningful and\\ninterpretable than word similarity. For instance, ?work? and ?lazy? do not have similar meanings\\nbut are related through the semantic meanings of the words. Another difference is that?unlike word\\nsemantic similarity? words that generally appear in very different contexts yet mean the same thing\\nwould probably not have a high evocation score. For example, ?networks? and ?graphs? both have a\\ndefinition that means a set of nodes and edges yet usually one word is chosen in a particular context.\\nRecent work in evaluating topic models [2, 3, 4, 5] formulate automated metrics based on automatically scoring all pairs of top words and noticing that they correlate with human judgment of overall\\ntopic coherence. All of these metrics are based on the common assumption that a person should\\nbe able to understand a topic by understanding the abstract semantic connections between the word\\npairs. Thus, evocation is a reasonable notion for evaluating topic modeling because it directly evaluates the level of semantic connection between word pairs. In addition, this new evocation metric\\nprovides a way to explicitly evaluate the edge matrices of APM, which would be ignored in previous\\nmetrics because explicit word dependencies are not modeled in other topic models.\\nWe now formally define our evocation metric. Given human-evaluated scores for a subset of word\\npairs H and the corresponding weights given by a topic model for this subset of word pairs M, let\\nus define ?M (j) to be an ordering of the word pairs induced by M such that M?(1) ? M?(2) ?\\n? ? ? ? M?(|H|) . Then, the top-m evocation metric is simply:\\nm\\nX\\nEvocm (M, H) =\\nH?M(j) .\\n(4)\\nj=1\\n\\nNote that the scaling of M is inconsequential because M is only needed to define an ordering or\\n? = ? exp(M) would yield the same evocation score for all scalar\\nranking of H. For example, M\\n5\\n\\n\\fvalues ? > 0 because the ordering would be maintained. Essentially, M merely induces an ordering\\nof the word pairs and the evocation score is the sum of the human scores for these top m word pairs.\\nFor APM, the word pair weights come primarily from the PMRF edge matrices ?1...k ?the PMRF\\nnode vectors are only used to provide an ordering if there are not enough non-zeros in the edge\\nmatrices. For the other Multinomial-based topic models which do not have parameters explicitly\\nassociated with word-pairs, we can compute the most likely word pairs in a topic by multiplying\\ntheir corresponding marginal probabilities. This weighting corresponds to the probability that two\\nindependent draws from the topic distribution produce the word pair and thus is the most obvious\\nchoice for Multinomial-based topic models.\\nSince this metric only gives a way to evaluate one topic, we consider two ways of determining\\nPk 1\\nj\\nthe overall evocation score for the whole topic model: Evoc-1 =\\nj=1 k Evocm (M , H) and\\nPk 1 j\\nEvoc-2 = Evocm ( j=1 k M , H). In words, these are ?average evocation of topics? and ?evocation of average topic? respectively. Evoc-1 measures whether all or at least most topics capture\\nmeaningful word associations since it can be affected by uninteresting topics. Evoc-2 is reasonable\\nfor measuring whether the topic model as a whole is capturing word semantics even if some of the\\ntopics are not capturing interesting word associations. This second measure has some relation to\\nthe word similarity measure of topic coherence in [4]. However, [4] uses similarity rather than evocation, does not directly evaluate top individual word pairs and does not evaluate any models with\\nword dependencies such as APM.\\n4.1\\n\\nExperimental Setup\\n\\nHuman-Scored Evocation Dataset The original human-scored evocation dataset was produced\\nby a set of trained undergraduates in which 1,000 words were hand selected primarily based on\\ntheir frequency and usage in the British National Corpus (BNC) [7]. From the possible pairwise\\nevaluations, approximately 10% of the word pairs were randomly selected to be manually scored by\\na set of trained undergraduates. The second dataset was constructed by predicting the pairs of words\\nthat were likely to have a high evocation using a standard machine learning classifier. This new set of\\npairs was scored using Amazon MTurk (mturk.com) by using the original dataset as a control [24].\\nThough these scores are between synsets?which are a word, part-of-speech and sense triplet?, we\\nmapped all of the synsets to word, part-of-speech pairs since that is the only information we have\\nfor the BNC corpus. This led to a total of 1646 words. In addition, though the evocation dataset has\\nscores for directed relationships (i.e. word1 ? word2 could have a different score than word2 ?\\nword1), we averaged these two scores because the directionality of the relationship is not modeled\\nby APM or any other topic model.\\nBNC Corpus Because the evocation dataset was based on the BNC corpus, we used the BNC corpus for our experiments. We processed the BNC corpus by lemmatizing each word using the WordNetLemmatizer included in the nltk package (nltk.org) and then attaching the part-of-speech,\\nwhich is already included in the BNC corpus. We only retained the counts for the 1646 words that\\noccurred in the human-scored datasets but processed all 4049 documents in the corpus.\\nAPM Model Parameters We trained APM on the BNC corpus with several different parameter\\nsettings including various ? and ? parameter settings. We also trained two particular APM models\\ndenoted APM-LowReg and APM-HeldOut. APM-LowReg uses a very small regularization parameter so that almost all edges are non-zero. APM-HeldOut automatically selects a reasonable value\\nfor ? based on the likelihood of a held-out set of the documents. Thus, the APM-HeldOut model\\ndoes not require a user-specified ? parameter but?as seen in the following sections?still performs\\nreasonably well even compared to the APM model in which many different parameter settings are\\nattempted. In addition, the APM-HeldOut can stop the training early when the model begins to overfit the data rather than tracing through all the ? parameters?this could lead to a significant gain in\\nmodel training time. The authors suggest that APM-HeldOut is a simple baseline model for future\\ncomparison if a user does not want to specify ?.\\nOther Models For comparison, we trained five other models: Correlated Topic Models (CTM),\\nHierarchical Dirichlet Process (HDP), Latent Dirichlet Allocation (LDA), Replicated Softmax\\n(RSM), and a na??ve random baseline (RND). CTM models correlations between topics [25]. HDP\\n6\\n\\n\\fis a non-parametric Bayesian model that selects the number of topics based input data and hyperparameters [26]. The standard topic model LDA was trained using MALLET [27]. LDA was trained\\nfor at least 5,000 iterations and HDP was trained for at least 300 iterations since HDP is computationally expensive. RSM is an undirected topic model based on Restricted Boltzmann Machines\\n(RBM) [28]. The random model is merely the expected evocation score if edges are ranked at random. We ran a full factorial experimental setting where all the combinations of a set of parameter\\nvalues were trained to give a fair comparison between models (see Appendix C for a summary of\\nparameter values). All these comparison models only indirectly model dependencies between words\\nthrough the latent variables since the topic distributions are Multinomials whereas APM can directly\\nmodel the dependencies between words since the topic distributions are Poisson MRFs.\\nSelecting Best Parameters We randomly split the human scores into a 50% tuning split and 50%\\ntesting split. Note that we have a tuning split rather than a training split because the model training\\nalgorithms are unsupervised (i.e. they never see the human scores) so the only supervision occurs in\\nselecting the final model parameters (i.e. during the tuning phase). Therefore, we selected the final\\nparameters based on the tuning split and computed the final evocation scores on the test split. Thus,\\neven when selecting the parameter settings, the modeling process never sees the test data.\\n4.2\\n\\nMain Results\\n\\nThe Evoc-1 and Evoc-2 scores with m = 50 for all models can be seen in Fig. 2.2 For Evoc-1, the\\nAPM models significantly outperform all other models for a small number of topics and even capture\\nmany semantically meaningful word pairs with a single topic. For higher number of topics, the APM\\nmodels seem to perform only competitively with previous topic models. It seems that APM-LowReg\\nperforms better with a small number of topics whereas APM-HeldOut?which generally chooses a\\nrelatively high ??seems more robust for large number of topics. These trends are likely caused\\nbecause there is a relatively small number of documents (n = 4049) so the APM-LowReg begins to\\nsignificantly overfit the data as the number of topics increases whereas APM-HeldOut does not seem\\nto overfit as much. For all the APM models, the degradation in performance as the number of topics\\nincreases is most likely caused by the fact that a Poisson MRF with O(p2 ) parameters is a much\\nmore flexible distribution than a Multinomial, and thus, fewer topics are needed to appropriately\\nmodel the data. These results also give some evidence that APM can succinctly model the data with\\na much smaller number of topics than is needed for independent topic models; this succinctness\\ncould be particularly helpful for the interpretability and intuitions of topic models.\\n\\nEvocation (m= 50)\\n\\nAPM\\n\\nAPM-LowReg\\n\\nAPM-HeldOut\\n\\nCTM\\n\\nHDP\\n\\nLDA\\n\\nRSM\\n\\nRND\\n\\n1600\\n1400\\n1200\\n1000\\n800\\n600\\n400\\n200\\n0\\n\\nk=1\\n\\n3\\n\\n5\\n\\n10\\n\\n25\\n\\n50\\n\\nEvoc-1 (Avg. Evoc. of Topics)\\n\\nk=1\\n\\n3\\n\\n5\\n\\n10\\n\\n25\\n\\n50\\n\\nEvoc-2 (Evoc. of Avg. Topic)\\n\\nFigure 2: Both Evoc-1 scores (left) and Evoc-2 scores (right) demonstrate that APM usually significantly outperforms other topic models in capturing meaningful word pairs.\\nFor the Evoc-2 score, the APM models?including the APM-HeldOut model which automatically\\ndetermines a ? from the data?significantly outperform previous topic models even for a large number of topics. This supports the idea that APM only needs a small number of topics to capture many\\nof the semantically meaningful word dependencies. Thus, when increasing the number of topics\\nbeyond 5, the performance does not decrease as in Evoc-1. It is likely that this discrepancy is caused\\nby the fact that many of the edges are concentrated in a small number of topics even when the number of topics is 10 or 25. As expected because of previous research in topic models, most other topic\\n2\\nFor simplicity and comparability, we grouped HDP into the topic number that was closest to its discovered\\nnumber of topics because HDP can select a variable number of topics.\\n\\n7\\n\\n\\fmodels perform slightly better with a larger number of topics. Though it is possible that using 100\\nor 500 topics for these topic models might give an evocation score better than APM with 5 topics,\\nthis would only enforce the idea that APM can perform better or at least competitively with previous\\ntopic models while only using a comparatively small number of topics.\\nQualitative Analysis of Top 20 Word Pairs for Best LDA and APM Models To validate the\\nintuition of using evocation as an human-standard evaluation metric, we present the top 20 word\\npairs for the best standard topic model?in this case LDA?and the best APM model for the Evoc-2\\nmetric as seen in Table 1. The best performing LDA model was trained with 50 topics, ? = 1 and\\n? = 0.0001. The best APM model was the APM-LowReg model trained with only 5 topics and a\\nsmall regularization parameter ? = 0.05. It is important to note that the best model for LDA has\\n50 topics while the best model for APM only has 5 topics. As before, this reinforces the theme that\\nAPM can capture more semantically meaningful word pairs with a smaller number of topics than\\nprevious topic models.\\n1:=Top\\nAPM\\n(right)\\nLDALDA\\nEvocation\\nEvocation\\nofTable\\nAvg.\\nof Avg.\\nGraph\\nGraph\\n967\\n= 96720 words for LDA (left) and\\nAPM\\nAPM\\nEvocation\\nEvocation\\nof Avg.\\nof Avg.\\nGraph\\nGraph\\n= 1627\\n= 1627\\nRankRank\\nEvoc.\\nEvoc.\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n\\n1 38\\n2 0\\n3 13\\n4 69\\n5 0\\n6 82\\n7 38\\n8 35\\n9 7\\n10 38\\n\\nEdgeEdge\\n\\nRankRank\\nEvoc.\\nEvoc.\\n\\n38 woman.n\\nwoman.n\\n??\\nman.n\\nman.n 11\\n0 woman.n\\nwoman.n\\n??\\nwife.n\\nwife.n\\n12\\n13\\ntrain.n\\ntrain.n\\n??\\ncar.n\\ncar.n\\n13\\n69 school.n\\nschool.n\\n??\\nclass.n\\nclass.n 14\\n0\\ndrive.v\\ndrive.v\\n??\\ncar.n\\ncar.n\\n15\\n82 teach.v\\nteach.v\\n??\\nschool.n\\nschool.n 16\\n38 engine.n\\nengine.n\\n??\\ncar.n\\ncar.n\\n17\\n35 publish.v\\npublish.v\\n??\\nbook.n\\nbook.n 18\\n7 religious.a\\nreligious.a\\n??\\nchurch.n\\nchurch.n 19\\n38 state.n\\nstate.n\\n??\\ngovernment.n\\ngovernment.n\\n20\\n\\nEdgeEdge\\n\\nRankRank\\nEvoc.\\nEvoc.\\n\\n11 0 0\\ncar.n\\ncar.n\\n??\\nbus.n\\nbus.n\\n12 31 31\\nyear.n\\nyear.n\\n??\\nday.n\\nday.n\\n13 25 25\\ncar.n\\ncar.n\\n??\\nseat.n\\nseat.n\\n14 50 50 teach.v\\nteach.v\\n??\\nstudent.n\\nstudent.n\\n15 0 0\\ntell.v\\ntell.v\\n??\\nget.v\\nget.v\\n16 38 38\\nwife.n\\nwife.n\\n??\\nman.n\\nman.n\\n17100 100\\nrun.v\\nrun.v\\n??\\ncar.n\\ncar.n\\n18 0 0\\ngive.v\\ngive.v\\n??\\nget.v\\nget.v\\n19 16 16 paper.n\\npaper.n\\n??\\nbook.n\\nbook.n\\n20 19 19 white.a\\nwhite.a\\n??\\nblack.a\\nblack.a\\n\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n\\n1 13\\n2 60\\n3 13\\n4 50\\n5 38\\n6 75\\n7 57\\n8 13\\n9 7\\n10 97\\n\\nEdgeEdge\\n\\nRankRank\\nEvoc.\\nEvoc.\\n\\n13 smoke.v\\nsmoke.v\\n??\\ncigarette.n\\ncigarette.n11\\n60\\nlove.v\\nlove.v\\n??\\nlove.n\\nlove.n\\n12\\n13\\neat.v\\neat.v\\n??\\nfood.n\\nfood.n 13\\n50 west.n\\nwest.n\\n??\\neast.n\\neast.n\\n14\\n38 south.n\\nsouth.n\\n??\\nnorth.n\\nnorth.n 15\\n75\\niron.n\\niron.n\\n??\\nsteel.n\\nsteel.n 16\\n57question.n\\nquestion.n\\n??\\nanswer.n\\nanswer.n 17\\n13\\nboil.v\\nboil.v\\n??\\npotato.n\\npotato.n 18\\n7 religious.a\\nreligious.a\\n??\\nchurch.n\\nchurch.n 19\\n97husband.n\\nhusband.n\\n??\\nwife.n\\nwife.n\\n20\\n\\n11 72\\n12 28\\n13 25\\n14 0\\n15 35\\n16 0\\n17 19\\n18 41\\n19 33\\n20 7\\n\\nEdgeEdge\\n\\n72\\naunt.n\\naunt.n\\n??\\nuncle.n\\nuncle.n\\n28\\ntea.n\\ntea.n\\n??\\ncoffee.n\\ncoffee.n\\n25operational.a\\noperational.a\\n??\\naircraft.n\\naircraft.n\\n0competition.n\\ncompetition.n\\n??\\ncompete.v\\ncompete.v\\n35 green.n\\ngreen.n\\n??\\ngreen.a\\ngreen.a\\n0\\nfox.n\\nfox.n\\n??\\nanimal.n\\nanimal.n\\n19 smoke.n\\nsmoke.n\\n??\\nfire.n\\nfire.n\\n41 wine.n\\nwine.n\\n??\\ndrink.v\\ndrink.v\\n33 troop.n\\ntroop.n\\n??\\nforce.n\\nforce.n\\n7\\nlock.n\\nlock.n\\n??\\nkey.n\\nkey.n\\n\\nOne interesting example is that LDA finds two word pairs [woman.n - wife.n] and [wife.n - man.n]\\nthat capture some semantic notion of marriage. However, APM directly captures this semantic\\nmeaning with [husband.n - wife.n]. APM also finds more intuitive verb-noun relationships that are\\nclosely tied semantically and portray a particular context: [smoke.v - cigarette.n], [eat.v - food.n],\\n[boil.v - potato.n], and [drink.v - wine.n] whereas LDA tends to select less interesting verb-noun\\nrelationships such as [run.v - car.n]. In addition, APM finds multiple semantically coherent yet high\\nlevel word pairs such as [iron.n - steel.n], [question.n - answer.n], and [aunt.n - uncle.n], whereas\\nLDA finds several low-level edges such as [year.n - day.n] and [tell.v - get.v]. These overall trends\\nbecome even more evident when looking at the top 50 edges as can be found in the Appendix E.\\nBoth the quantitative evaluation metrics (i.e. Evoc-1 and Evoc-2) as well as a qualitative exploration\\nof the top word pairs give strong evidence that APM can succinctly capture both more interesting\\nand higher-level semantic concepts through word dependencies than independent topic models.\\n\\n5\\n\\nConclusion and Future Work\\n\\nWe motivated the need for more expressive topic models that consider word dependencies?such\\nas APM?by considering previous work on topic model evaluation metrics. We overcame the significant computational barrier of APM by providing a fast alternating Newton-like algorithm which\\ncan be easily parallelized. We proposed a new evaluation metric based on human evocation scores\\nthat seeks to measure whether a model is capturing semantically meaningful word pairs. Finally,\\nwe presented compelling quantitative and qualitative measures showing the superiority of APM in\\ncapturing semantically meaningful word pairs. In addition, this metric suggests new evaluations\\nof topic models based on evaluating top word pairs rather than top words. One drawback with the\\ncurrent human-scored data is that only a small portion of the word pairs have been scored. Thus,\\none extension is to dynamically collect more human scores as needed for evaluation. This work also\\nopens the door for exciting new word-semantic applications for APM such as Word Sense Induction\\nusing topic models [29], keyword expansion or suggestion, document summarization, and document\\nvisualization because APM is capturing semantically meaningful relationships between words.\\nAcknowledgments\\nD. Inouye was supported by the NSF Graduate Research Fellowship via DGE-1110007. P. Ravikumar acknowledges support from ARO via W911NF-12-1-0390 and NSF via IIS-1149803, IIS1447574, and DMS-1264033. I. Dhillon acknowledges support from NSF via CCF-1117055.\\n\\n8\\n\\n\\fReferences\\n[1] D. I. Inouye, P. Ravikumar, and I. S. Dhillon, ?Admixture of Poisson MRFs: A Topic Model with Word\\nDependencies,? in International Conference on Machine Learning (ICML), 2014.\\n[2] D. Mimno, H. M. Wallach, E. Talley, M. Leenders, and A. McCallum, ?Optimizing semantic coherence\\nin topic models,? in EMNLP, pp. 262?272, 2011.\\n[3] D. Newman, Y. Noh, E. Talley, S. Karimi, and T. Baldwin, ?Evaluating topic models for digital libraries,?\\nin ACM/IEEE Joint Conference on Digital Libraries (JCDL), pp. 215?224, 2010.\\n[4] K. Stevens and P. Kegelmeyer, ?Exploring topic coherence over many models and many topics,? in\\nEMNLP-CoNLL, pp. 952?961, 2012.\\n[5] N. Aletras and R. Court, ?Evaluating Topic Coherence Using Distributional Semantics,? in International\\nConference on Computational Semantics (IWCS 2013) - Long Papers, pp. 13?22, 2013.\\n[6] D. Mimno and D. Blei, ?Bayesian Checking for Topic Models,? in EMNLP, pp. 227?237, 2011.\\n[7] J. Boyd-graber, C. Fellbaum, D. Osherson, and R. Schapire, ?Adding Dense, Weighted Connections to\\n{WordNet},? in Proceedings of the Global {WordNet} Conference, 2006.\\n[8] D. Blei, A. Ng, and M. Jordan, ?Latent dirichlet allocation,? JMLR, vol. 3, pp. 993?1022, 2003.\\n[9] T. L. Griffiths and M. Steyvers, ?Finding scientific topics,? Proceedings of the National Academy of\\nSciences of the United States of America, vol. 101, pp. 5228?35, Apr. 2004.\\n[10] J. H. Lau, K. Grieser, D. Newman, and T. Baldwin, ?Automatic Labelling of Topic Models,? in NAACL\\nHLT, pp. 1536?1545, 2011.\\n[11] D. Magatti, S. Calegari, D. Ciucci, and F. Stella, ?Automatic Labeling Of Topics,? in ISDA, 2009.\\n[12] X.-l. Mao, Z.-y. Ming, Z.-j. Zha, T.-s. Chua, H. Yan, and X. Li, ?Automatic Labeling Hierarchical Topics,?\\nin CIKM, pp. 2383?2386, 2012.\\n[13] J. Chang, J. Boyd-Graber, S. Gerrish, C. Wang, and D. Blei, ?Reading tea leaves: How humans interpret\\ntopic models,? NIPS, pp. 1?9, 2009.\\n[14] C.-J. Hsieh, M. A. Sustik, I. S. Dhillon, and P. Ravkiumar, ?Sparse inverse covariance matrix estimation\\nusing quadratic approximation,? NIPS, pp. 1?18, 2011.\\n[15] T. Hofmann, ?Probabilistic latent semantic analysis,? in Uncertainty in Artificial Intelligence (UAI),\\npp. 289?296, Morgan Kaufmann Publishers Inc., 1999.\\n[16] J. Reisinger, A. Waters, B. Silverthorn, and R. J. Mooney, ?Spherical topic models,? in ICML, pp. 903?\\n910, 2010.\\n[17] E. M. Airoldi, D. M. Blei, S. E. Fienberg, and E. P. Xing, ?Mixed Membership Stochastic Blockmodels.,?\\nJMLR, vol. 9, pp. 1981?2014, Sept. 2008.\\n[18] E. Yang, P. Ravikumar, G. I. Allen, and Z. Liu, ?Graphical models via generalized linear models,? in\\nNIPS, pp. 1367?1375, 2012.\\n[19] E. Yang, P. Ravikumar, G. Allen, and Z. Liu., ?On poisson graphical models,? in NIPS, pp. 1718?1726,\\n2013.\\n[20] C. Varin, N. Reid, and D. Firth, ?An overview of composite likelihood methods,? STATISTICA SINICA,\\nvol. 21, pp. 5?42, 2011.\\n[21] J. D. Lee and T. J. Hastie, ?Structure Learning of Mixed Graphical Models,? in AISTATS, vol. 31, pp. 388?\\n396, 2013.\\n[22] D. D. Lee and H. S. Seung, ?Algorithms for Non-negative Matrix Factorization,? in NIPS, pp. 556?562,\\n2000.\\n[23] H.-F. Yu, F.-L. Huang, and C.-J. Lin, ?Dual coordinate descent methods for logistic regression and maximum entropy models,? Machine Learning, vol. 85, pp. 41?75, Nov. 2010.\\n[24] S. Nikolova, J. Boyd-graber, C. Fellbaum, and P. Cook, ?Better Vocabularies for Assistive Communication\\nAids: Connecting Terms using Semantic Networks and Untrained Annotators,? in ACM Conference on\\nComputers and Accessibility, pp. 171?178, 2009.\\n[25] D. M. Blei and J. D. Lafferty, ?Correlated topic models,? in NIPS, pp. 147?154, 2005.\\n[26] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei, ?Hierarchical Dirichlet Processes,? Journal of the\\nAmerican Statistical Association, vol. 101, pp. 1566?1581, Dec. 2006.\\n[27] A. K. McCallum, ?MALLET: A Machine Learning for Language Toolkit,? 2002.\\n[28] G. Hinton and R. Salakhutdinov, ?Replicated softmax: An undirected topic model,? NIPS, 2009.\\n[29] J. H. Lau, P. Cook, D. Mccarthy, D. Newman, and T. Baldwin, ?Word Sense Induction for Novel Sense\\nDetection,? in EACL, pp. 591?601, 2012.\\n\\n9\\n\\n\\f\",\n          \"Factorial Hidden Markov Models\\nZoubin Ghahramani\\nzoubin@psyche.mit.edu\\nDepartment of Computer Science\\nUniversity of Toronto\\nToronto, ON M5S 1A4\\nCanada\\n\\nMichael I. Jordan\\njordan@psyche.mit.edu\\nDepartment of Brain & Cognitive Sciences\\nMassachusetts Institute of Technology\\nCambridge, MA 02139\\nUSA\\n\\nAbstract\\nWe present a framework for learning in hidden Markov models with\\ndistributed state representations. Within this framework , we derive a learning algorithm based on the Expectation-Maximization\\n(EM) procedure for maximum likelihood estimation. Analogous to\\nthe standard Baum-Welch update rules, the M-step of our algorithm is exact and can be solved analytically. However, due to the\\ncombinatorial nature of the hidden state representation, the exact\\nE-step is intractable. A simple and tractable mean field approximation is derived. Empirical results on a set of problems suggest that\\nboth the mean field approximation and Gibbs sampling are viable\\nalternatives to the computationally expensive exact algorithm.\\n\\n1\\n\\nIntroduction\\n\\nA problem of fundamental interest to machine learning is time series modeling. Due\\nto the simplicity and efficiency of its parameter estimation algorithm, the hidden\\nMarkov model (HMM) has emerged as one of the basic statistical tools for modeling\\ndiscrete time series, finding widespread application in the areas of speech recognition (Rabiner and Juang, 1986) and computational molecular biology (Baldi et al. ,\\n1994). An HMM is essentially a mixture model, encoding information about the\\nhistory of a time series in the value of a single multinomial variable (the hidden\\nstate). This multinomial assumption allows an efficient parameter estimation algorithm to be derived (the Baum-Welch algorithm). However, it also severely limits\\nthe representational capacity of HMMs. For example, to represent 30 bits of information about the history of a time sequence, an HMM would need 230 distinct\\nstates. On the other hand an HMM with a distributed state representation could\\nachieve the same task with 30 binary units (Williams and Hinton, 1991). This paper\\naddresses the problem of deriving efficient learning algorithms for hidden Markov\\nmodels with distributed state representations.\\n\\n\\fFactorial Hidden Markov Models\\n\\n473\\n\\nThe need for distributed state representations in HMMs can be motivated in two\\nways. First, such representations allow the state space to be decomposed into\\nfeatures that naturally decouple the dynamics of a single process generating the\\ntime series. Second, distributed state representations simplify the task of modeling\\ntime series generated by the interaction of multiple independent processes. For\\nexample, a speech signal generated by the superposition of multiple simultaneous\\nspeakers can be potentially modeled with such an architecture.\\nWilliams and Hinton (1991) first formulated the problem of learning in HMMs with\\ndistributed state representation and proposed a solution based on deterministic\\nBoltzmann learning. The approach presented in this paper is similar to Williams\\nand Hinton's in that it is also based on a statistical mechanical formulation of hidden\\nMarkov models. However, our learning algorithm is quite different in that it makes\\nuse of the special structure of HMMs with distributed state representation, resulting\\nin a more efficient learning procedure. Anticipating the results in section 2, this\\nlearning algorithm both obviates the need for the two-phase procedure of Boltzmann\\nmachines, and has an exact M-step. A different approach comes from Saul and\\nJordan (1995), who derived a set of rules for computing the gradients required for\\nlearning in HMMs with distributed state spaces. However, their methods can only\\nbe applied to a limited class of architectures.\\n\\n2\\n\\nFactorial hidden Markov models\\n\\nHidden Markov models are a generalization of mixture models. At any time step,\\nthe probability density over the observables defined by an HMM is a mixture of\\nthe densities defined by each state in the underlying Markov model. Temporal\\ndependencies are introduced by specifying that the prior probability of the state at\\ntime t depends on the state at time t -1 through a transition matrix, P (Figure 1a).\\nAnother generalization of mixture models, the cooperative vector quantizer (CVQ;\\nHinton and Zemel, 1994 ), provides a natural formalism for distributed state representations in HMMs. Whereas in simple mixture models each data point must be\\naccounted for by a single mixture component, in CVQs each data point is accounted\\nfor by the combination of contributions from many mixture components, one from\\neach separate vector quantizer. The total probability density modeled by a CVQ\\nis also a mixture model; however this mixture density is assumed to factorize into\\na product of densities, each density associated with one of the vector quantizers.\\nThus, the CVQ is a mixture model with distributed representations for the mixture\\ncomponents.\\nFactorial hidden Markov models! combine the state transition structure of HMMs\\nwith the distributed representations of CVQs (Figure 1b). Each of the d underlying\\nMarkov models has a discrete state s~ at time t and transition probability matrix\\nPi. As in the CVQ, the states are mutually exclusive within each vector quantizer\\nand we assume real-valued outputs. The sequence of observable output vectors is\\ngenerated from a normal distribution with mean given by the weighted combination\\nof the states of the underlying Markov models:\\n\\nwhere C is a common covariance matrix. The k-valued states\\n\\nSi\\n\\nare represented as\\n\\n1 We refer to HMMs with distributed state as factorial HMMs as the features of the\\ndistributed state factorize the total state representation.\\n\\n\\f474\\n\\nZ. GHAHRAMANI. M. I. JORDAN\\n\\ndiscrete column vectors with a 1 in one position and 0 everywhere else; the mean of\\nthe observable is therefore a combination of columns from each of the Wi matrices.\\na)\\n~-------....\\n\\ny\\n\\np\\nFigure 1. a) Hidden Markov model. b) Factorial hidden Markov model.\\n\\nWe capture the above probability model by defining the energy of a sequence of T\\nstates and observations, {(st, yt)};=l' which we abbreviate to {s, y}, as:\\n\\n1l( {s,y}) =\\n\\n~\\n\\nt. k-t. w;s:]'\\n\\nC- 1\\n\\n[yt -\\n\\nt. w;s:]- t. t.\\n\\nsf A;S:-l, (1)\\n\\nwhere [Ai]jl = logP(s~jls~I-I) such that 2::=1 e[Ai]j/ = 1, and I denotes matrix\\ntranspose. Priors for the initial state, sl, are introduced by setting the second term\\nin (1) to - 2:t=1 sf log7ri. The probability model is defined from this energy by\\nthe Boltzmann distribution\\n1\\n(2)\\nP({s,y}) = Z exp{-ll({s,y})}.\\nNote that like in the CVQ (Ghahramani, 1995), the undamped partition function\\nZ =\\n\\nJ\\n\\nd{y} Lexp{-ll({s,y})},\\n{s}\\n\\nevaluates to a constant, independent of the parameters. This can be shown by\\nfirst integrating the Gaussian variables, removing all dependency on {y}, and then\\nsumming over the states using the constraint on e[A,]j/ .\\n\\nThe EM algorithm for Factorial HMMs\\nAs in HMMs, the parameters of a factorial HMM can be estimated via the EM\\n(Baum-Welch) algorithm. This procedure iterates between assuming the current\\nparameters to compute probabilities over the hidden states (E-step), and using\\nthese probabilities to maximize the expected log likelihood of the parameters (Mstep).\\nUsing the likelihood (2), the expected log likelihood of the parameters is\\n\\nQ(4) new l4>)\\n\\n= (-ll({s,y}) -logZ)c ,\\n\\n(3)\\n\\n\\f475\\n\\nFactorial Hidden Markov Models\\n\\nwhere </J = {Wi, Pi, C}f=l denotes the current parameters, and Oc denotes expectation given the damped observation sequence and </J. Given the observation\\nsequence, the only random variables are the hidden states. Expanding equation (3)\\nand limiting the expectation to these random variables we find that the statistics\\nthat need to be computed for the E-step are (sDc, (s~sj')c, and (S~S~-l\\\\. Note\\nthat in standard HMM notation (Rabiner and Juang, 1986), (sDc corresponds to\\nt t I'\\n,\\nIt and (SiSi - )c corresponds to\\nwhereas (s~st?)c has no analogue when there\\nis only a single underlying Markov model. The ~-step uses these expectations to\\nmaximize Q with respect to the parameters.\\n\\net,\\n\\nThe constant partition function allowed us to drop the second term in (3). Therefore, unlike the Boltzmann machine, the expected log likelihood does not depend\\non statistics collected in an undamped phase of learning, resulting in much faster\\nlearning than the traditional Boltzmann machine (Neal, 1992).\\nM-step\\n\\nSetting the derivatives of Q with respect to the output weights to zero, we obtain\\na linear system of equations for W:\\n\\nWnew = [2:(SS')c] t [2:(S)CY'] ,\\nN,t.\\n\\nN,t\\n\\nwhere sand Ware the vector and matrix of concatenated Si and. Wi,\\nrespectively,L: N denotes summation over a data set of N sequences, and t is the\\nMoore-Penrose pseudo-inverse. To estimate the log transition probabilities we solve\\n8Q/8[A i ]jl = 0 subject to the constraint L: j e[A,]i l = 1, obtaining\\n\\n'\\\"\\n)\\n_ I\\ni...JN,t (stij st-l)\\nil\\nc\\n[A ?.]~ew\\nJI\\n- og (\\nt t-l\\n.\\nL:N,t,j(SijSil\\n\\n(4)\\n\\n)c\\n\\nThe covariance matrix can be similarly estimated:\\n\\nc new =\\n\\n2: YY' - 2: y(s)~(ss')!(s)cy'.\\nN,t\\n\\nN,t\\n\\nThe M-step equations can therefore be solved analytically; furthermore, for a single\\nunderlying Markov chain, they reduce to the traditional Baum-Welch re-estimation\\nequations.\\nE-step\\n\\nUnfortunately, as in the simpler CVQ, the exact E-step for factorial HMMs is computationally intractable. For example, the expectation of the lh unit in vector i at\\ntime step t, given {y}, is:\\n\\n(s!j)c\\n\\np(sL = II{y}, </J)\\nk\\n\\n2: P(s~it=I,.\\\",s~j = 1, ... ,s~,jd=ll{y},</J)\\nit,???,jhyt',oo.,jd\\nAlthough the Markov property can be used to obtain a forward-back ward-like factorization of this expectation across time steps, the sum over all possible configurations of the other hidden units within each time step is unavoidable. For a data set\\n\\n\\f476\\n\\nZ. GHAHRAMANI, M. I. JORDAN\\n\\nof N sequences of length T, the full E-ste~ calculated through the forward-backward\\nprocedure has time complexity O(NTk2 ). Although more careful bookkeeping can\\nreduce the complexity to O(NTdk d +1), the exponential time cannot be avoided.\\nThis intractability of the exact E-step is due inherently to the cooperative nature\\nof the model-the setting of one vector only determines the mean of the observable\\nif all the other vectors are fixed.\\nRather than summing over all possible hidden state patterns to compute the exact\\nexpectations, a natural approach is to approximate them through a Monte Carlo\\nmethod such as Gibbs sampling. The procedure starts with a clamped observable\\nsequence {y} and a random setting of the hidden states {sj}. At each time step,\\neach state vector is updated stochastically according to its probability distribution\\nconditioned on the setting of all the other state vectors: s~ '\\\" P (s~ I{y }, {sj : j \\\"#\\ni or T \\\"# t}, ?). These conditional distributions are straightforward to compute and\\na full pass of Gibbs sampling requires O(NTkd) operations. The first and secondorder statistics needed to estimate (sDc, (s~sj\\\\ and (S~s~-l\\\\ are collected using\\nthe S~j'S visited and the probabilities estimated during this sampling process.\\n\\nMean field approximation\\nA different approach to computing the expectations in an intractable system is\\ngiven by mean field theory. A mean field approximation for factorial HMMs can be\\nobtained by defining the energy function\\n\\n~L\\n\\n1l({s,y}) =\\n\\n[yt -Itt]' C- 1 [yt -Itt] - Lsf logm}.\\n\\nt\\n\\nt ,i\\n\\nwhich results in a completely factorized approximation to probability density (2):\\n.P({s,y}) ex\\n\\nII exp{-~ [yt -Itt], C-\\n\\n1\\n\\n[yt -Itt]}\\n\\nII (m~j)3:j\\n\\n(5)\\n\\nt ,i ,j\\n\\nt\\n\\nIn this approximation, the observables are independently Gaussian distributed with\\nmean Itt and each hidden state vector is multinomially distributed with mean m~.\\nThis approximation is made as tight as possible by chosing the mean field parameters Itt and m~ that minimize the ?ullback-Liebler divergence\\nK.q.PIIP) == (logP)p - (log?)p\\nwhere Op denotes expectation over the mean field distribution (5). With the\\nobservables clamped, Itt can be set equal to the observable yt. Minimizing K?(.PIIP)\\nwith respect to the mean field parameters for the states results in a fixed-point\\nequation which can be iterated until convergence:\\n\\nm~ new\\n\\n+ W!C-1Wim~ - ~diag{W!C-IWd -\\n\\nu{W!C- 1 [yt - yt]\\n+At'm~-l\\nt\\n\\n1 (6)\\n\\n+ A~m~+1}\\nt\\n\\nt\\n\\nwhere yt == Ei Wim~ and u{-} is the softmax exponential, normalized over each\\nhidden state vector. The first term is the projection of the error in the observable\\nonto the weights of state vector i-the more a hidden unit can reduce this error, the\\nlarger its mean field parameter. The next three terms arise from the fact that (s;j) p\\nis equal to mij and not m;j. The last two terms introduce dependencies forward\\nand backward in time. Each state vector is asynchronously updated using (6), at\\na time cost of O(NTkd) per iteration. Convergence is diagnosed by monitoring\\nthe K? divergence in the mean field distribution between successive time steps; in\\npractice convergence is very rapid (about 2 to 10 iterations of (6)).\\n\\n\\fFactorial Hidden Markov Models\\n\\n477\\n\\nTable 1: Comparison of factorial HMM on four problems of varying size\\nd k\\nAlg\\nTrain\\nTest\\nCycles\\nTime7Cycle\\n#\\n3 2 HMM 5 649 ?8\\n358 ? 81\\n33 ? 19\\nl.ls\\nExact\\n877 ?O\\n768 ?O\\n22 ?6\\n3.0 s\\nGibbs\\n627 ? 129 28 ?ll\\n710 ? 152\\n6.0 s\\nMF\\n755 ? 168\\n670 ? 137 32 ? 22\\nl.2 s\\n-782 ? 128 23 ? 10\\n3 3 HMM 5 670 ? 26\\n3.6 s\\nExact\\n568 ? 164\\n276 ? 62\\n35 ? 12\\n5.2 s\\nGibbs\\n564 ? 160\\n45 ? 16\\n9.2 s\\n305 ? 51\\nMF\\n495 ? 83\\n326 ? 62\\n38 ? 22\\nl.6 s\\n-2634 ? 566 18 ? 1\\n5.2 s\\n5 2 HMM 5 588 ? 37\\nExact\\n223 ? 76\\n159 ? 80\\n31 ? 17\\n6.9 s\\n123 ? 103\\nGibbs\\n40 ?5\\n12.7 s\\n73 ? 95\\nMF\\n292 ? 101\\n237 ? 103 54 ? 29\\n2.2 s\\n-00,-00 ,-00\\n14,14,12\\n90.0 s\\n5 3 HMM 3 1671,1678,1690\\nExact\\n-55,-354,-295\\n-123,-378 ,-402 90,100,100\\n5l.Os\\n-123,-160 ,-194 -202,-237 ,-307 100,73,100\\nGibbs\\n14.2 s\\n4.7 s\\nMF\\n-287,-286,-296 -364 ,-370,-365 100,100,100\\nTable 1. Data was generated from a factorial HMM with d underlying Markov models of\\nk states each. The training set was 10 sequences of length 20 where the observable was a\\n4-dimensional vector; the test set was 20 such sequences. HMM indicates a hidden Markov\\nmodel with k d states; the other algorithms are factorial HMMs with d underlying k-state\\nmodels. Gibbs sampling used 10 samples of each state. The algorithms were run until\\nconvergence, as monitored by relative change in the likelihood, or a maximum of 100 cycles.\\nThe # column indicates number of runs. The Train and Test columns show the log likelihood\\n? one standard deviation on the two data sets. The last column indicates approximate time\\nper cycle on a Silicon Graphics R4400 processor running Matlab.\\n\\n3\\n\\nEmpirical Results\\n\\nWe compared three EM algorithms for learning in factorial HMMs-using Gibbs\\nsampling, mean field approximation , and the exact (exponential) E step- on the\\nbasis of performance and speed on randomly generated problems. Problems were\\ngenerated from a factorial HMM structure, the parameters of which were sampled from a uniform [0,1] distribution, and appropriately normalized to satisfy the\\nsum-to-one constraints of the transition matrices and priors. Also included in the\\ncomparison was a traditional HMM with as many states (k d ) as the factorial HMM.\\nTable 1 summarizes the results. Even for moderately large state spaces (d ~\\n3 and k ~ 3) the standard HMM with k d states suffers from severe overfitting.\\nFurthermore, both the standard HMM and the exact E-step factorial HMM are\\nextremely slow on the larger problems. The Gibbs sampling and mean field approximations offer roughly comparable performance at a great increase in speed.\\n\\n4\\n\\nDiscussion\\n\\nThe basic contribution of this paper is a learning algorithm for hidden Markov\\nmodels with distributed state representations. The standard Baum-Welch procedure is intractable for such architectures as the size of the state space generated\\nfrom the cross product of d k-valued features is O(kd), and the time complexity of\\nBaum-Welch is quadratic in this size. More importantly, unless special constraints\\nare applied to this cross-product HMM architecture , the number of parameters also\\n\\n\\f478\\n\\nz. GHAHRAMANI, M. 1. JORDAN\\n\\ngrows as O(k2d), which can result in severe overfitting.\\nThe architecture for factorial HMMs presented in this paper did not include any\\ncoupling between the underlying Markov chains. It is possible to extend the algorithm presented to architectures which incorporate such couplings. However, these\\ncouplings must be introduced with caution as they may result either in an exponential growth in parameters or in a loss of the constant partition function property.\\nThe learning algorithm derived in this paper assumed real-valued observables. The\\nalgorithm can also be derived for HMMs with discrete observables, an architecture\\nclosely related to sigmoid belief networks (Neal, 1992). However, the nonlinearities\\ninduced by discrete observables make both the E-step and M-step of the algorithm\\nmore difficult.\\nIn conclusion, we have presented Gibbs sampling and mean field learning algorithms\\nfor factorial hidden Markov models. Such models incorporate the time series modeling capabilities of hidden Markov models and the advantages of distributed representations for the state space. Future work will concentrate on a more efficient\\nmean field approximation in which the forward-backward algorithm is used to compute the E-step exactly within each Markov chain, and mean field theory is used to\\nhandle interactions between chains (Saul and Jordan, 1996).\\nAcknowledgements\\nThis project was supported in part by a grant from the McDonnell-Pew Foundation, by a\\ngrant from ATR Human Information Processing Research Laboratories, by a grant from\\nSiemens Corporation, and by grant N00014-94-1-0777 from the Office of Naval Research.\\n\\nReferences\\nBaldi, P., Chauvin, Y., Hunkapiller, T ., and McClure, M. (1994). Hidden Markov models\\nof biological primary sequence information. Proc. Nat. Acad. Sci. (USA),91(3):10591063.\\nGhahramani, Z. (1995) . Factorial learning and the EM algorithm. In Tesauro, G., Touretzky, D., and Leen, T., editors, Advances in Neural Information Processing Systems\\n7. MIT Press, Cambridge, MA.\\nHinton, G . and Zemel, R. (1994). Autoencoders, minimum description length, and\\nHelmholtz free energy. In Cowan, J., Tesauro, G., and Alspector, J., editors, Advances in Neural Information Processing Systems 6. Morgan Kaufmanm Publishers,\\nSan Francisco, CA .\\nNeal, R. (1992). Connectionist learning of belief networks. Artificial Intelligence, 56:71113.\\nRabiner, 1. and Juang, B. (1986). An Introduction to hidden Markov models.\\nAcoustics, Speech ?1 Signal Processing Magazine , 3:4-16.\\n\\nIEEE\\n\\nSaul, 1. and Jordan, M. (1995). Boltzmann chains and hidden Markov models. In Tesauro,\\nG., Touretzky, D., and Leen, T., editors, Advances in Neural Information Processing\\nSystems 7. MIT Press, Cambridge, MA.\\nSaul, 1. and Jordan, M. (1996) . Exploiting tractable substructures in Intractable networks. In Touretzky, D., Mozer, M., and Hasselmo, M., editors, Advances in Neural\\nInformation Processing Systems 8. MIT Press.\\nWilliams, C. and Hinton, G. (1991) . Mean field networks that learn to discriminate temporally distorted strings. In Touretzky, D., Elman, J., Sejnowski, T., and Hinton, G.,\\neditors, Connectionist Models: Proceedings of the 1990 Summer School, pages 18-22.\\nMorgan Kaufmann Publishers, Man Mateo, CA.\\n\\n\\f\",\n          \"Information-Geometrical Significance of\\nSparsity in Gallager Codes\\n\\nToshiyuki Tanaka\\nDepartment of Electronics and Information Engineering\\nTokyo Metropolitan University\\nTokyo 192-0397, Japan\\ntanaka@eei.metro-u.ac.jp\\nShiro Ikeda\\nKyushu Institute of Technology & JST\\nFukuoka 808-0196, Japan\\nshiro@brain.kyutech.ac.jp\\n\\nShun-ichi Amari\\nRIKEN, Brain Science Institute\\nSaitama 351-0198, Japan\\namari@brain.riken.go.jp\\n\\nAbstract\\nWe report a result of perturbation analysis on decoding error of the belief\\npropagation decoder for Gallager codes. The analysis is based on information geometry, and it shows that the principal term of decoding error\\nat equilibrium comes from the m-embedding curvature of the log-linear\\nsubmanifold spanned by the estimated pseudoposteriors, one for the full\\nmarginal, and K for partial posteriors, each of which takes a single check\\ninto account, where K is the number of checks in the Gallager code. It is\\nthen shown that the principal error term vanishes when the parity-check\\nmatrix of the code is so sparse that there are no two columns with overlap\\ngreater than 1.\\n\\n1\\n\\nIntroduction\\n\\nRecent progress on error-correcting codes has attracted much attention because their decoders, exhibiting performance very close to Shannon's limit, can be implemented as neural networks. Important examples are turbo codes and Gallager codes [1]. It is now well\\nunderstood that application of belief propagation to the respective graphical representations of the decoding problems for both codes yields practically efficient decoding algorithms which are the same as the existing ones (the turbo decoding [2] and the sum-product\\ndecoding [3], respectively). They are, however, not exact but approximate, since the associated graphical representations have loops in both cases. An important problem posed\\nis to quantify the effect that comes from the existence of loops in the underlying graph.\\nThe so-called TAP approach [4] in statistical physics is an alternative way to formulate the\\nsame decoding algorithm [5]. Since this approach also assumes that the underlying graph\\nis locally loop-free, one is faced with the same problem as above.\\nIn this paper, we analyze the properties of the belief propagation decoder to Gallager codes,\\nexpecting that better theoretical understanding of the properties of the belief propagation\\n\\n\\fgenerator\\nmatrix\\n\\nparity-check\\nmatrix\\nBSC(? 0 )\\n\\nBSC(? )\\ns\\n\\nGT\\n\\ninformation\\nvector\\n\\nt\\n\\nr\\n\\ncodeword\\n\\nreceived\\nvector\\n\\nz\\n\\nA\\n\\nsyndrome\\nvector\\n\\nFigure 1: Gallager code\\n\\ndecoder will help understand the properties and efficiency of belief propagation in general,\\napplied to loopy graphs, as well as those of the TAP approach. We specifically make use of\\nthe information geometry [6] and report a result of perturbation analysis on decoding error\\nof the belief propagation decoder.\\n\\n2\\n\\nGallager codes\\n\\nGallager code is defined by its parity-check matrix A, which has the form\\nA = [C1 | C2 ],\\n\\n(1)\\n\\nwhere C1 and C2 are K ? M and K ? K matrices, both of which are taken to be very\\nsparse. C2 is assumed invertible. We define the generator matrix of the Gallager code to be\\n\\u0015\\n\\u0014\\nI\\n(2)\\nGT =\\nC2?1 C1\\nwhere I is the M ? M identity matrix. AG T = O mod 2 holds by definition.\\nThe whole model of communication with the Gallager code is shown in Fig. 1. An information vector s of length M is encoded into a codeword t = GT s mod 2 of length N ? K + M.\\nThe codeword t is then transmitted over a channel. We assume that the transmission channel is a binary symmetric channel (BSC) with bit-error probability ? . The received vector\\nis then r = t + n mod 2, where n is the noise vector. Decoder tries to find the most probable\\nx satisfying the parity-check equation\\nAx = z mod 2,\\n\\n(3)\\nAGT s\\n\\nwhere z ? Ar mod 2 is the syndrome vector. Since At =\\n= 0 mod 2, we have\\nz = An mod 2. Therefore, the solution x serves as an estimate of the noise vector n. If we\\nare successful in finding the true noise vector n, we can reconstruct, from r, the original\\ncodeword t by t = r + n mod 2, and then the information vector s. Since Eq. (3) is\\nunderdetermined, one has to take into account the prior knowledge of the noise in order to\\nsolve it properly.\\nThe decoding problem can be cast into the Bayes framework. In the sequel, we transform\\nexpression of a bit from binary (1, 0) to bipolar (?1, 1). The prior for x is\\n\\u0001\\np(x) = exp ?1 ? x ? N ?(?) , ?(?) ? log(e? + e?? ),\\n(4)\\n\\nwhere 1 is an N -dimensional vector whose elements are all 1, i.e., 1 ? [1, . . . , 1]. ? is a\\nparameter which is related with the bit-error probability ? of the transmission channel by\\n? =\\n\\n1\\n(1 ? tanh ?).\\n2\\n\\n(5)\\n\\n\\fFor the sake of analytical tractability, we assume that the syndrome vector z is observed via\\nanother BSC channel with bit-error probability ? 0 (see Fig. 1). This leads\\nK\\nh X\\ni\\nY\\np(z|x) ? exp ?\\nzr\\nxi ,\\nr=1\\n\\n(6)\\n\\ni? (r)\\n\\nwhere (r ) is the set of all indices of nonzero elements in row r of the parity-check matrix\\nA, i.e., (r ) ? {i | Ari = 1}, and ? is defined by ? 0 = (1/2)(1 ? tanh ?). If we take the\\nlimit ? ? +?, then we recover the conventional situation of observing the syndrome in\\na deterministic way. In what follows, we consider the case in which ? is finite, or equivalently, the case with soft parity-check constraints. Since experimental findings suggest that\\nit is usually the case for decoding results of Gallager codes to violate no parity-check constraints [3], we believe that making the parity-check constraints soft does not alter essential\\nproperties of the problem.\\n\\u0001\\n\\n\\u0001\\n\\n3\\n\\nDecoding\\n\\nThe posterior distribution of x for given observed syndrome z is derived from the prior p(x)\\nand the conditional p(z | x) by applying the Bayes formula, and the result is\\nK\\nh\\ni\\nX\\np(x|z) ? exp c0 (x) + ?\\ncr (x) ,\\n\\n(7)\\n\\nr=1\\n\\nwhere we let\\nc0 (x) ? ?1 ? x,\\n\\ncr (x) ? zr\\n\\nY\\n\\n(r = 1, . . . , K ).\\n\\nxi\\n\\n(8)\\n\\ni? (r)\\n\\nThe objective of decoder of Gallager codes is to obtain the marginal-posterior-mode\\n(MPM) estimate based on the posterior p(x|z):\\nX\\nx?i = arg max\\np(x|z).\\n(9)\\nxi\\n\\nx\\\\x i\\n\\nThe MPM estimation provides the Bayes-optimum decoder minimizing expected bit-error\\nprobability of the decoding results. However, the marginalization is in general computationally hard, which renders the decoding problem intractable. An approximate decoding\\nalgorithm, originally proposed by Gallager himself [1], is known to be efficient in practice.\\nIt has been recently rediscovered by MacKay [3] by application of the belief propagation\\nto the underlying graphical model. Murayama et al. [5] also formulated the same algorithm based on the so-called TAP approach [4]. The decoder implementing the algorithm\\nis called the belief propagation decoder, and is analyzed in the following.\\nWe define a family of distributions with a set of parameters ? = (?1 , . . . , ? N )T and v =\\n(v1 , . . . , v K ):\\n\\f\\nn\\n\\u0002\\n\\u0003o\\n\\f\\nS = p(x; ? , v) \\f p(x; ? , v) = exp ? ? x + v ? c(x) ? ?(? , v) ,\\n(10)\\n\\n\\u0001T\\nwhere c(x) ? c1 (x), . . . , c K (x) . The family S includes the factorizable test distribution p0 (x; ? 0 ) (= p(x; ? 0 , 0)), the true posterior p(x|z) (= p(x; ?1, ?1)), and K partial\\nposteriors pr (x; ? r ) (= p(x; ? r , ?er ); er ? (0, . . . , 0, 1, 0, . . . , 0)T ).\\nr?\\n\\nWe then define the expectation parameter ?(? , v) by\\nX\\n?(? , v) ?\\nx p(x; ? , v).\\nx\\n\\n(11)\\n\\n\\fThe marginalization in Eq. (9) corresponds to evaluating the expectation parameter of the\\ntrue posterior. We now introduce the equimarginal family\\n\\f\\n\\b\\n\\t\\nM(? 0 ) ? p(x; ? , v) \\f ?(? , v) = ?(? 0 , 0) ,\\n(12)\\nand define the marginalization operator 5 as follows: For p ? S, 5? p ? ?0 if p ? M(? 0 ).\\nKnowing ? 0 = 5 ? p is regarded as being equivalent to knowing the expectation parameter\\nof p, since ?(? 0 , 0) is easily evaluated from ? 0 ; in other words, the marginalization is\\ntractable for distributions belonging to the factorizable model:\\n\\b\\n\\t\\nM0 ? p0(x; ? 0 ) ? p(x; ? 0 , 0) = exp(? 0 ? x ? ?0 (? 0 ))\\n(13)\\n\\nThe basic assumption of iterative decoding is that the marginalization is also tractable for\\nthe models corresponding to constituent decoders with single checks, with factorizable\\npriors:\\n\\b\\n\\t\\nMr ? pr (x; ?) ? p(x; ?, ?er ) = exp(? ? x + ?cr (x) ? ?r (?))\\n(14)\\n\\nThe algorithm of the belief propagation decoder is described in the notation employed here\\nas follows:\\nInitialization: Let t = 0 and ? r0 = ?1, r = 1, . . . , K .\\nHorizontal step: Evaluate the marginalization of pr (x; ? rt ) ? Mr to produce a\\nguess ? rt based on the current prior information ?rt and the check zr :\\n? rt = 5 ? pr (x; ? rt ),\\n\\nr = 1, . . . , K ,\\n\\n(15)\\n\\nand calculate a net contribution (the 'cavity field' [7]) from the check zr by subtracting the prior information:\\n? rt = ? rt ? ? rt .\\n\\n(16)\\n\\n(It should be noted that (? rt )i = 0 holds for i 6? (r ) as it should be, since the\\nconstituent decoder with check zr cannot provide any contribution regarding information of xi , i 6 ? (r).)\\nVertical step: Compose the 'leave-one-out' estimates [7]\\nX\\n? rt+1 = ?1 +\\n? rt 0 , r = 1, . . . , K ,\\n(17)\\n\\u0001\\n\\n\\u0001\\n\\nr 0 6 =r\\n\\nand the pseudoposterior\\n? t+1 = ?1 +\\n\\nK\\nX\\n\\n? rt .\\n\\n(18)\\n\\nr=1\\n\\nIterate the above steps until convergence is achieved. The desired decoding result\\n?(?1, ?1) is then approximated by ?(? ? , 0), where ? ? is the convergent value of\\n{? t }.\\n\\n4\\n\\nInformation-geometrical characterization of equilibrium\\n\\nAssume that the convergence is achieved and let (?? , ? ?1 , . . . , ? ?K ) be the equilibrium values\\nof (? t , ? t1 , . . . , ? tK ). Then, from Eqs. (15) and (16), we have\\n5 ? pr (x; ? ? ? ? r? ) = ? ? ,\\n\\nr = 1, . . . , K .\\n\\n(19)\\n\\nThis means that p0(x; ? ? ) and pr (x; ? ? ? ? r? ), r = 1, . . . , K , are equimarginal, that is,\\npr (x; ? ? ? ? r? ) ? M(? ? ),\\n\\nr = 1, . . . , K\\n\\n(20)\\n\\n\\fE(? ? )\\np(x|z)\\n\\nM(? ? )\\np2 (x; ? ? ? ? ?2 )\\n\\np1 (x; ? ? ? ? ?1 )\\n\\nM1\\nM2\\n\\u0002\\n\\n\\u0001\\n\\nMK\\n\\np K (x; ? ? ? ? ?K )\\n\\nS\\n\\nM0\\np0 (x; ? ? )\\n\\nFigure 2: Geometric structure of belief propagation decoder\\n\\nholds. Another property of the equilibrium is the log-linear relation\\n?\\n\\nlog p(x|z) ? log p0 (x; ? ) =\\n\\nK\\nX\\n\\b\\nr=1\\n\\nor, in the (? , v) coordinate,\\n\\n\\t\\nlog pr (x; ? ? ? ? r? ) ? log p0 (x; ? ? ) + const.\\n\\n(?1, ?1) ? (? ? , 0) =\\n\\nK\\nX\\nr=1\\n\\n\\u0001\\n(? ? ? ? r? , ?er ) ? (? ? , 0) .\\n\\n(21)\\n\\n(22)\\n\\nThis means that the true posterior p(x|z) belongs to the 'log-linear submanifold' E(?? ),\\nthe affine subspace in the (? , v)-coordinate rooted at (?? , 0) and spanned by (?? r? , ?er ),\\nr = 1, . . . , K .\\nThese two properties do not imply p(x|z) ? M(?? ). In fact, if we were to assume, instead\\nof the log-linear relation (21), the linear relation\\np(x|z) ? p0 (x; ? ? ) =\\n\\nK\\nX\\n\\b\\nr=1\\n\\n\\t\\npr (x; ? r? ) ? p0 (x; ? ? ) ,\\n\\n(23)\\n\\nthen we would have p(x|z) ? M(? ? ) and thus ?(?1, ?1) = ?(? ? , 0). This is not the\\ncase because of the difference between the linear and log-linear relations. To what degree\\nthe log-linear relation deviates from the linear relation determines the decoding error of\\nbelief propagation decoder. The structure is best described on the basis of information\\ngeometry [6]. Figure 2 illustrates the geometric structure of the belief propagation decoder.\\nIt should be noted that the geometrical structure shown here is essentially the same as that\\nfor the turbo decoding [8, 9].\\n\\n5\\n\\nMain result\\n\\nBased on the information geometry, we have evaluated decoding error, the difference between the true expectation ?(?1, ?1) and its estimate by the belief propagation decoder\\n\\n\\f?(? ? , 0), via perturbation analysis. Taking into account the terms up to second order, we\\nhave\\n?2 X\\n?(?1, ?1) ? ?(? ? , 0) =\\nBrs ?(? ? , 0) + O(? 3 ),\\n(24)\\n2\\nr,s;r6 =s\\n\\nwhere\\nBrs ?\\n\\nN\\nN\\n\\u0010 ?\\n\\u0011\\nX\\nX\\n? \\u0011\\u0010 ?\\nj ?\\n?\\ng kk Ark\\n?\\ng j j As\\n,\\n?vr\\n??k ?vs\\n?? j\\nk=1\\n\\n(25)\\n\\nj=1\\n\\nand\\n\\n\\u0002\\n\\u0003\\n??i (? ? , 0)\\n(26)\\n= Cov? ? ,0 x i , cr (x) .\\n?vr\\n{Brs } are the elements of the m-embedding curvature tensor of the manifold E(?? ) in S.\\ng ii ? 1/(1 ? ?ii (? ? , 0)2 ) are the diagonal elements of the inverse of the Fisher information\\nof p0 (x; ? ? ). This is the generalization of the result obtained for the turbo decoding [8].\\nAri ?\\n\\nExplicit calculation gives the following theorem.\\nTheorem 1. The decoding error of belief propagation decoder is given, within the secondorder with respect to ?, by\\n?i (?1, ?1) ? ?i (? ? , 0)\\n\\\"\\nX\\n2\\n2\\n= ? (1 ? ?i ) ??i\\n\\nX\\n\\nzr z s\\n\\nr,s\\nr 6 =s,i ? (r )? (s)\\n\\n(1 ? ?2j )\\n\\nj?( (r)? (s))\\\\i\\n\\n?\\n\\nY\\n\\nk?( (r )? (s))\\\\i, j\\n\\n+\\n\\nX\\n\\n\\u0010\\nzr z s 1 ?\\n\\nr,s\\nr 6 =s,i ? (r )? (s)\\n\\nY\\n\\nY\\n\\nX\\n\\n(1 ? ?2j )\\n\\nj? (r)? (s)\\n\\nl?[( (r )? (s))\\\\i]?[ (s)? (r )]\\n\\n+ O(? 3 )\\n\\n?l\\n\\nl?( (r )? (s))?( (s)? (r))\\n\\n?2j ?\\n\\nj? (r)? (s)\\n\\n?\\n\\nY\\n\\n?k2\\n\\nY\\n\\n?k2\\n\\nk?( (r )? (s))\\\\ j\\n\\n?l\\n\\n\\u0011\\n\\n#\\n(27)\\n\\nwhere ?i ? ?i (? ? , 0).\\nFrom this theorem, it immediately follows that:\\nCorollary 2. If the parity-check matrix A has no two columns with overlap greater than\\n1, then the principal error term, given in Eq. (27), vanishes.\\nThese are the main result of this paper.\\n\\n6\\n\\nDiscussion\\n\\nThe general result given in Eq. (24) shows that the principal error term is not coordinate\\ninvariant, since the summation with respect to r and s in the right-hand side of Eq. (24)\\nexcludes terms with r = s. This corresponds to the empirical fact that the performance does\\ndepend on the design of the code, that is, the choice of the parity-check matrix A. Explicit\\nevaluation of the principal error term, as in Theorem 1, makes it possible to improve the\\n\\n\\fperformance of a code, just in the same way as the perturbational approach to improving\\nthe naive mean-field approximation [10, 11, 12, 13, 14, 15, 16, 17].\\nIt is believed [3] that Gallager codes have smaller average probability of decoding error\\nif we avoid any two columns of the parity-check matrix A to have overlap greater than 1.\\nAn intuitive explanation to this belief is that such avoidance prevents loops with length 4\\nfrom appearing in the graphical representation. Since short loops are expected to do harm\\nin proper functioning of belief propagation, their existence may raise the possibility of\\ndecoding errors. Our result supports this belief by showing analytically that the principal\\nterm of decoding error vanishes when the parity-check matrix of the code is so sparse and\\nprepared with care so that there are no two columns with overlap greater than 1.\\nLoops with length longer than 4 do not contribute to the decoding error at least via the\\nprincipal term, but they may have effects via higher-order terms. Our analysis presented\\nhere can be extended in a straightforward manner to higher-order perturbation analysis in\\norder to quantify these effects.\\nIt should be noted that our approach taken in this paper is different from the common\\napproach to analyzing the properties of the belief propagation decoder in the literature,\\nin that we do not consider ensembles of codes. A typical reasoning found in the literature\\n(e.g., [18]) is first to consider an ensemble of random parity-check matrices, to state that the\\nprobability (over the ensemble) of containing short loops in the associated graph decreases\\ndown to zero as the size of the parity-check matrix tends to infinity, and to assume that the\\nbehavior of the belief propagation decoder for codes with longer loops is the same as that of\\nbelief propagation for loop-free case. The statistical-mechanical approach to performance\\nanalysis of Gallager-type codes [5] also assumes random ensembles. Our analysis, on the\\nother hand, does not assume ensembles but allows, although asymptotically, performance\\nevaluation of the belief propagation decoder to Gallager codes with any single instance of\\nthe parity-check matrix with finite size.\\nAcknowledgments\\nThe authors would like to thank Dr. Yoshiyuki Kabashima for his helpful suggestions and\\ncomments.\\nReferences\\n[1] R. G. Gallager, Low Density Parity Check Codes, Ph. D. Thesis, Mass. Inst. Tech., 1960.\\n[2] R. J. McEliece, D. J. C. MacKay, and J. Cheng, ?Turbo decoding as an instance of Pearl's `belief\\npropagation' algorithm,? IEEE J. Select. A. Commun., vol. 16, no. 2, pp. 140?152, 1998.\\n[3] D. J. C. MacKay, ?Good error-correcting codes based on very sparse matrices,? IEEE Trans.\\nInform. Theory, vol. 45, no. 2, pp. 399?431, 1999.\\n[4] D. J. Thouless, P. W. Anderson, and R. G. Palmer, ?Solution of `Solvable model of a spin glass',?\\nPhil. Mag., vol. 35, no. 3, pp. 593?601, 1977.\\n[5] T. Murayama, Y. Kabashima, D. Saad, and R. Vicente, ?Statistical physics of regular low-density\\nparity-check error-correcting codes,? Phys. Rev. E, vol. 62, no. 2, pp. 1577?1591, 2000.\\n[6] S. Amari and H. Nagaoka (Transl. by D. Harada), Methods of Information Geometry, Translations of Mathematical Monographs, vol. 191, American Math. Soc., 2000.\\n[7] Y. Kabashima and D. Saad, ?The TAP approach to intensive and extensive connectivity systems,?\\nin M. Opper and D. Saad (eds.), Advanced Mean Field Methods ? Theory and Practice, The\\nMIT Press, 2001, pp. 65?84.\\n[8] S. Ikeda, T. Tanaka, and S. Amari, ?Information geometrical framework for analyzing belief\\npropagation decoder,? in T. G. Dietterich et al. (eds.), Advances in Neural Information Processing Systems, vol. 14 (this volume), The MIT Press, 2002.\\n\\n\\f[9] S. Ikeda, T. Tanaka, and S. Amari, ?Information geometry of turbo codes and low-density paritycheck codes,? submitted to IEEE Trans. Inform. Theory, 2001.\\n[10] H. J. Kappen and F. B. Rodriguez, ?Efficient learning in Boltzmann machines using linear\\nresponse theory,? Neural Computation, vol. 10, no. 5, pp. 1137?1156, 1998.\\n[11] H. J. Kappen and F. B. Rodriguez, ?Boltzmann machine learning using mean field theory and\\nlinear response correction,? in M. I. Jordan et al. (eds.), Advances in Neural Information Processing Systems, vol. 10, The MIT Press, 1998, pp. 280?286.\\n[12] T. Tanaka, ?A theory of mean field approximation,? in M. S. Kearns et al. (eds.), Advances in\\nNeural Information Processing Systems, vol. 11, The MIT Press, 1999, pp. 351?357.\\n[13] T. Tanaka, ?Information geometry of mean-field approximation,? Neural Computation, vol. 12,\\nno. 8, pp. 1951?1968, 2000.\\n[14] J. S. Yedidia, ?An idiosyncratic journey beyond mean field theory,? in M. Opper and D. Saad\\n(eds.), Advanced Mean Field Methods ? Theory and Practice, The MIT Press, 2001, pp. 21?35.\\n[15] H. J. Kappen and W. J. Wiegerinck, ?Mean field theory for graphical models,? in M. Opper and\\nD. Saad (eds.), Advanced Mean Field Methods ? Theory and Practice, The MIT Press, 2001,\\npp. 37?49.\\n[16] S. Amari, S. Ikeda, and H. Shimokawa, ?Information geometry of ?-projection in mean field\\napproximation,? in M. Opper and D. Saad (eds.), Advanced Mean Field Methods ? Theory and\\nPractice, The MIT Press, 2001, pp. 241?257.\\n[17] T. Tanaka, ?Information geometry of mean-field approximation,? in M. Opper and D. Saad\\n(eds.), Advanced Mean Field Methods ? Theory and Practice, The MIT Press, 2001, pp. 259?\\n273.\\n[18] T. J. Richardson and R. L. Urbanke, ?The capacity of low-density parity-check codes under\\nmessage-passing decodeing,? IEEE Trans. Inform. Theory, vol. 47, no. 2, pp. 599?618, 2001.\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["import re"],"metadata":{"id":"nsrYN_4ykQf_","executionInfo":{"status":"ok","timestamp":1751185051446,"user_tz":-330,"elapsed":3,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["papers['clean_text'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))"],"metadata":{"id":"-ZSCoe1ekcwH","executionInfo":{"status":"ok","timestamp":1751185058163,"user_tz":-330,"elapsed":105,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["papers['clean_text']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"2AXvjMmPlMn3","executionInfo":{"status":"ok","timestamp":1751185061718,"user_tz":-330,"elapsed":58,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"75f03f22-212d-4006-bb55-a6c036291e32"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6130    Consistent Kernel Mean Estimation\\nfor Functio...\n","1540    274\\n\\nWeinshalI Edelman and BiiIthofT\\n\\nA se...\n","1999    Sequence and Tree Kernels\\nwith Statistical Fe...\n","661     Tight Bounds for the VC-Dimension of\\nPiecewis...\n","4613    A* Lasso for Learning a Sparse Bayesian Networ...\n","                              ...                        \n","2275    Data Integration for Classification Problems\\n...\n","271     Neural Learning in Structured\\nParameter Space...\n","4544    Bayesian Mixture Modeling and Inference based\\...\n","4945    Neural Word Embedding\\nas Implicit Matrix Fact...\n","4750    Capturing Semantically Meaningful Word\\nDepend...\n","Name: clean_text, Length: 100, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6130</th>\n","      <td>Consistent Kernel Mean Estimation\\nfor Functio...</td>\n","    </tr>\n","    <tr>\n","      <th>1540</th>\n","      <td>274\\n\\nWeinshalI Edelman and BiiIthofT\\n\\nA se...</td>\n","    </tr>\n","    <tr>\n","      <th>1999</th>\n","      <td>Sequence and Tree Kernels\\nwith Statistical Fe...</td>\n","    </tr>\n","    <tr>\n","      <th>661</th>\n","      <td>Tight Bounds for the VC-Dimension of\\nPiecewis...</td>\n","    </tr>\n","    <tr>\n","      <th>4613</th>\n","      <td>A* Lasso for Learning a Sparse Bayesian Networ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2275</th>\n","      <td>Data Integration for Classification Problems\\n...</td>\n","    </tr>\n","    <tr>\n","      <th>271</th>\n","      <td>Neural Learning in Structured\\nParameter Space...</td>\n","    </tr>\n","    <tr>\n","      <th>4544</th>\n","      <td>Bayesian Mixture Modeling and Inference based\\...</td>\n","    </tr>\n","    <tr>\n","      <th>4945</th>\n","      <td>Neural Word Embedding\\nas Implicit Matrix Fact...</td>\n","    </tr>\n","    <tr>\n","      <th>4750</th>\n","      <td>Capturing Semantically Meaningful Word\\nDepend...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 1 columns</p>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["papers['clean_text'] = papers['clean_text'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))"],"metadata":{"id":"oUYEQjHElO1X","executionInfo":{"status":"ok","timestamp":1751185064492,"user_tz":-330,"elapsed":399,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["papers['clean_text'] = papers['clean_text'].map(lambda x: x.lower())"],"metadata":{"id":"vxxtnA3dnnlA","executionInfo":{"status":"ok","timestamp":1751185066128,"user_tz":-330,"elapsed":3,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["papers['clean_text'].sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"8xNR-ih8oG1C","executionInfo":{"status":"ok","timestamp":1751185068072,"user_tz":-330,"elapsed":51,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"e5f7dc85-3321-4d16-ac8d-2e248c1c5f89"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3529    sparse features for pca-like linear regression...\n","6891    towards generalization and simplicity\\nin cont...\n","4424    when in doubt swap: high-dimensional\\nsparse r...\n","382     learning to schedule straight-line code\\n\\neli...\n","1145    speech recognition using svms\\n\\nnathan smith\\...\n","4907    on communication cost of distributed statistic...\n","4750    capturing semantically meaningful word\\ndepend...\n","1540    \\n\\nweinshali edelman and biiithoft\\n\\na self-...\n","3110    sufficient conditions for agnostic active lear...\n","4314    regularized m -estimators with nonconvexity:\\n...\n","Name: clean_text, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3529</th>\n","      <td>sparse features for pca-like linear regression...</td>\n","    </tr>\n","    <tr>\n","      <th>6891</th>\n","      <td>towards generalization and simplicity\\nin cont...</td>\n","    </tr>\n","    <tr>\n","      <th>4424</th>\n","      <td>when in doubt swap: high-dimensional\\nsparse r...</td>\n","    </tr>\n","    <tr>\n","      <th>382</th>\n","      <td>learning to schedule straight-line code\\n\\neli...</td>\n","    </tr>\n","    <tr>\n","      <th>1145</th>\n","      <td>speech recognition using svms\\n\\nnathan smith\\...</td>\n","    </tr>\n","    <tr>\n","      <th>4907</th>\n","      <td>on communication cost of distributed statistic...</td>\n","    </tr>\n","    <tr>\n","      <th>4750</th>\n","      <td>capturing semantically meaningful word\\ndepend...</td>\n","    </tr>\n","    <tr>\n","      <th>1540</th>\n","      <td>\\n\\nweinshali edelman and biiithoft\\n\\na self-...</td>\n","    </tr>\n","    <tr>\n","      <th>3110</th>\n","      <td>sufficient conditions for agnostic active lear...</td>\n","    </tr>\n","    <tr>\n","      <th>4314</th>\n","      <td>regularized m -estimators with nonconvexity:\\n...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["from wordcloud import WordCloud\n","def create_word_cloud(target_df, column_name):\n","  print('Joining all words into long text....')\n","  full_text = ','.join(list(target_df[column_name].values))\n","  wordcloud = WordCloud(background_color=\"black\",\n","                        max_words=100,  # top 100 words in the\n","                        contour_width=2,\n","                        contour_color='yellow')\n","  print('Creating word cloud')\n","  wordcloud.generate(full_text)\n","  return wordcloud"],"metadata":{"id":"Ao-cbCVxoJFV","executionInfo":{"status":"ok","timestamp":1751185073226,"user_tz":-330,"elapsed":136,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["wordcloud = create_word_cloud(papers, 'clean_text')\n","wordcloud.to_image()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"AemV0KpAoWyU","executionInfo":{"status":"ok","timestamp":1751185076724,"user_tz":-330,"elapsed":1917,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"fe8bac69-8a70-4be8-b64f-8f17b427081f"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Joining all words into long text....\n","Creating word cloud\n"]},{"output_type":"execute_result","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=400x200>"],"image/png":"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\n","image/jpeg":"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\n"},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","def create_document_term_matrix(dataframe, column_name):\n","  cv = CountVectorizer(analyzer='word')\n","  data = cv.fit_transform(dataframe[column_name])\n","  df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names_out())\n","  df_dtm.index=dataframe.index\n","  return df_dtm\n",""],"metadata":{"id":"u6rJb-Iwog-3","executionInfo":{"status":"ok","timestamp":1751185081441,"user_tz":-330,"elapsed":14,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["df_dtm = create_document_term_matrix(papers, 'clean_text')"],"metadata":{"id":"0gm2LlOKqYHR","executionInfo":{"status":"ok","timestamp":1751185083500,"user_tz":-330,"elapsed":293,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["df_dtm.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":392},"id":"mdbL9Sd2qwLw","executionInfo":{"status":"ok","timestamp":1751185084628,"user_tz":-330,"elapsed":106,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"6e601849-7369-412b-d827-ec8ac5a42b56"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      __  ___  ____  _____  ______  ________________  _a  _dr  _ij  _l  ...  \\\n","5523   0    0     0      0       0                 0   0    0    0   0  ...   \n","230    0    0     0      0       0                 0   0    0    0   0  ...   \n","2275   0    0     0      0       0                 0   0    0    0   0  ...   \n","6130   0    0     0      0       0                 0   0    0    0   0  ...   \n","1815   0    0     0      0       0                 0   0    0    0   0  ...   \n","3867   0    0     0      0       0                 0   0    0    0   0  ...   \n","1310   0    0     0      0       0                 0   1    0    0   0  ...   \n","5576   0    0     0      0       0                 0   0    0    0   0  ...   \n","5052   0    0     0      0       0                 0   0    0    0   0  ...   \n","5348   0    0     0      0       0                 0   0    0    0   0  ...   \n","\n","      zq  zr  zs  zt  ztj  zto  zurek  zvi  zweig  zwillinger  \n","5523   0   0   0   0    0    0      0    0      0           0  \n","230    0   0   0   0    0    0      0    0      0           0  \n","2275   0   0   0   0    0    0      0    0      0           0  \n","6130   0   0   0   0    0    0      0    0      0           1  \n","1815   0   0   0   0    0    0      0    0      0           0  \n","3867   0   0   0   0    0    0      0    0      0           0  \n","1310   0   0   0   0    0    0      0    0      0           0  \n","5576   0   0   0   0    0    0      0    0      0           0  \n","5052   0   0   0   0    0    0      0    0      0           0  \n","5348   0   0   0   0    0    0      0    0      0           0  \n","\n","[10 rows x 16557 columns]"],"text/html":["\n","  <div id=\"df-1acd325f-1a0c-46fc-bc2b-3baee03da619\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>__</th>\n","      <th>___</th>\n","      <th>____</th>\n","      <th>_____</th>\n","      <th>______</th>\n","      <th>________________</th>\n","      <th>_a</th>\n","      <th>_dr</th>\n","      <th>_ij</th>\n","      <th>_l</th>\n","      <th>...</th>\n","      <th>zq</th>\n","      <th>zr</th>\n","      <th>zs</th>\n","      <th>zt</th>\n","      <th>ztj</th>\n","      <th>zto</th>\n","      <th>zurek</th>\n","      <th>zvi</th>\n","      <th>zweig</th>\n","      <th>zwillinger</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5523</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>230</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2275</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6130</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1815</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3867</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1310</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5576</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5052</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5348</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 16557 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1acd325f-1a0c-46fc-bc2b-3baee03da619')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1acd325f-1a0c-46fc-bc2b-3baee03da619 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1acd325f-1a0c-46fc-bc2b-3baee03da619');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-5239cf67-2eaa-4530-89e5-808578682dee\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5239cf67-2eaa-4530-89e5-808578682dee')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-5239cf67-2eaa-4530-89e5-808578682dee button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72e2baa8","executionInfo":{"status":"ok","timestamp":1751184680269,"user_tz":-330,"elapsed":10293,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"ae1c0ba2-0ebc-427e-f12a-58bd60ad9c54"},"source":["!pip install gensim"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"]}]},{"cell_type":"code","source":["import gensim\n","from gensim.utils import simple_preprocess\n","import nltk"],"metadata":{"id":"9gf-y469vXt_","executionInfo":{"status":"ok","timestamp":1751184697218,"user_tz":-330,"elapsed":7606,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JZI8eNMvcgl","executionInfo":{"status":"ok","timestamp":1751184725798,"user_tz":-330,"elapsed":164,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"da123668-d90b-4485-8c97-53bb218daeac"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from nltk.corpus import stopwords"],"metadata":{"id":"TvOSmzPmvlTc","executionInfo":{"status":"ok","timestamp":1751184843978,"user_tz":-330,"elapsed":5,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["stop_words = stopwords.words('english')\n","stop_words.extend(['has', 'been', 're', 'com', 'edu', 'use'])"],"metadata":{"id":"A7Hg75qBwCMA","executionInfo":{"status":"ok","timestamp":1751184855636,"user_tz":-330,"elapsed":7,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# If you set deacc=True which will removes the punctuations\n","def convert_sentences_to_words(sentences):\n","    for sentence in sentences:\n","        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"],"metadata":{"id":"E2QPPMsfwFCw","executionInfo":{"status":"ok","timestamp":1751184908024,"user_tz":-330,"elapsed":42,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def remove_all_stop_words(texts):\n","    return [[word for word in simple_preprocess(str(doc))\n","             if word not in stop_words] for doc in texts]"],"metadata":{"id":"KLGjTJwpwR03","executionInfo":{"status":"ok","timestamp":1751184940633,"user_tz":-330,"elapsed":9,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["text_to_list = papers.clean_text.values.tolist()"],"metadata":{"id":"ttcM1DDswZxM","executionInfo":{"status":"ok","timestamp":1751185088448,"user_tz":-330,"elapsed":17,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["len(text_to_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t0qOJkoWwoKX","executionInfo":{"status":"ok","timestamp":1751185100609,"user_tz":-330,"elapsed":53,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"96398f89-0015-423f-eebb-39e3ab30bd5d"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["text_to_list[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"0-VkqQCqxA1w","executionInfo":{"status":"ok","timestamp":1751185115420,"user_tz":-330,"elapsed":61,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"64c09e83-e404-4d53-a849-93207dd3c4ab"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'consistent kernel mean estimation\\nfor functions of random variables\\n\\n\\ncarl-johann simon-gabriel  adam scibior\\n ilya tolstikhin bernhard schlkopf\\ndepartment of empirical inference max planck institute for intelligent systems\\nspemanstrae   tbingen germany\\n\\njoint first authors;  also with: engineering department cambridge university\\ncjsimon@ adamscibior@ ilya@ bs@tuebingenmpgde\\n\\nabstract\\nwe provide a theoretical foundation for non-parametric estimation of functions of\\nrandom variables using kernel mean embeddings we show that for any continuous\\nfunction f  consistent estimators of the mean embedding of a random variable x\\nlead to consistent estimators of the mean embedding of f (x) for matrn kernels\\nand sufficiently smooth functions we also provide rates of convergence\\nour results extend to functions of multiple random variables if the variables\\nare dependent we require an estimator of the mean embedding of their joint\\ndistribution as a starting point; if they are independent it is sufficient to have\\nseparate estimators of the mean embeddings of their marginal distributions in\\neither case our results cover both mean embeddings based on iid samples as well\\nas reduced set expansions in terms of dependent expansion points the latter\\nserves as a justification for using such expansions to limit memory resources when\\napplying the approach as a basis for probabilistic programming\\n\\n\\n\\nintroduction\\n\\na common task in probabilistic modelling is to compute the distribution of f (x) given a measurable\\nfunction f and a random variable x in fact the earliest instances of this problem date back at least\\nto poisson () sometimes this can be done analytically for example if f is linear and x is\\ngaussian that is f (x) = ax + b and x  n (; ) we have f (x)  n (a + b; a ) there exist\\nvarious methods for obtaining such analytical expressions (mathai ) but outside a small subset\\nof distributions and functions the formulae are either not available or too complicated to be practical\\nan alternative to the analytical approach is numerical approximation ideally implemented as a\\nflexible software library the need for such tools is recognised in the general programming languages\\ncommunity (mckinley ) but no standards were established so far the main challenge is in\\nfinding a good approximate representation for random variables\\ndistributions on integers for example are usually represented as lists of (xi  p(xi )) pairs for real\\nvalued distributions integral transforms (springer ) mixtures of gaussians (milios ) laguerre polynomials (williamson ) and chebyshev polynomials (korzen and jaroszewicz )\\nwere proposed as convenient representations for numerical computation for strings probabilistic\\nfinite automata are often used all those approaches have their merits but they only work with a\\nspecific input type\\nthere is an alternative based on monte carlo sampling (kalos and whitlock ) which is to\\nrepresent x by a (possibly weighted) sample {(xi  wi )}ni= (with wi ) this representation has\\nseveral advantages: (i) it works for any input type (ii) the sample size controls the time-accuracy\\ntrade-off and (iii) applying functions to random variables reduces to applying the functions pointwise\\n conference on neural information processing systems (nips ) barcelona spain\\n\\n\\x0cto the sample ie {(f (xi ) wi )} representsp\\nf (x) furthermore\\nexpectations of functions of random\\np\\nvariables can be estimated as e [f (x)]  i wi f (xi )/ i wi  sometimes with guarantees for the\\nconvergence rate\\n\\nthe flexibility of this monte carlo approach comes at a cost: without further assumptions on the\\nunderlying input space x  it is hard to quantify the accuracy of this representation for instance\\ngiven two samples of the same size {(xi  wi )}ni= and {(   )}ni=  how can we tell which one is a\\nbetter representation of x more generally how could we optimize a representation with predefined\\nsample size\\nthere exists an alternative to the monte carlo approach called kernel mean embeddings (kme)\\n(berlinet and thomas-agnan ; smola et al ) it also represents random variables as\\nsamples but additionally defines a notion of similarity between sample points as a result (i) it\\nkeeps all the advantages of the monte carlo scheme (ii) it includes the monte carlo method as\\na special case (iii) it overcomes its pitfalls described above and (iv) it can be tailored to focus\\non different properties of x depending on the users needs and prior assumptions the kme\\napproach identifies both sample points and distributions with functions in an abstract hilbert space\\ninternally the latter are still represented as weighted samples but the weights can be negative and\\nthe straightforward monte carlo interpretation is no longer valid schlkopf et al () propose\\nusing kmes as approximate representation of random variables for the purpose of computing their\\nfunctions however they only provide theoretical justification for it in rather idealised settings which\\ndo not meet practical implementation requirements\\nin this paper we build on this work and provide general theoretical guarantees for the proposed estimators specifically we prove statements of the form if {(xi  wi )}ni= provides a good estimate for\\nthe kme of x then {(f (xi ) wi )}ni= provides a good estimate for the kme of f (x) importantly\\nour results do not assume joint independence of the observations xi (and weights wi ) this makes\\nthem a powerful tool for instance imagine we are given data {(xi  wi )}ni= from a random variable\\nx that we need to compress then our theorems guarantee that whatever compression algorithm we\\nuse as long as the compressed representation {(   )}nj= still provides a good estimate for the\\nkme of x the pointwise images {(f ( )  )}nj= provide good estimates of the kme of f (x)\\n\\nin the remainder of this section we first introduce kmes and discuss their merits then we explain\\nwhy and how we extend the results of schlkopf et al () section  contains our main results in\\nsection  we show consistency of the relevant estimator in a general setting and in section  we\\nprovide finite sample guarantees when matrn kernels are used in section  we show how our results\\napply to functions of multiple variables both interdependent and independent section  concludes\\nwith a discussion\\n\\n\\nbackground on kernel mean embeddings\\n\\nlet x be a measurable input space we use a positive definite bounded and measurable kernel\\n := {(xi  wi )}n\\nk : x  x  r to represent random variables x  p and weighted samples x\\ni=\\nk\\nk\\nas two functions x and \\nx in the corresponding reproducing kernel hilbert space (rkhs) hk by\\ndefining\\nz\\nx\\nkx := k(x ) dp (x) and \\nkx :=\\nwi k(xi  ) \\ni\\n\\nthese are guaranteed to exist since we assume the kernel is bounded (smola et al ) when\\nclear from the context we omit the kernel k in the superscript x is called the kme of p  but we\\nalso refer to it as the kme of x in this paper we focus on computing functions of random variables\\nfor f : x  z where z is a measurable space and for a positive definite bounded kz : z  z  r\\nwe also write\\nz\\nx\\nkf z(x) := kz (f (x) ) dp (x) and \\nkf z(x) :=\\nwi kz (f (xi ) ) \\n()\\ni\\n\\n to functions in the rkhs is that\\nthe advantage of mapping random variables x and samples x\\n\\nwe may now say that x is a good approximation for x if the rkhs distance k\\nx x k is\\nsmall this distance depends on the choice of the kernel and different kernels emphasise different\\ninformation about x for example if on x := [a b]  r we choose k(x  ) := x   +  then\\n\\n\\n\\x0cx (x) = exp [x] x +  thus any two distributions and/or samples with equal means are mapped\\nto the same function in hk so the distance between them is zero therefore using this particular k\\nwe keep track only of the mean of the distributions if instead we prefer to keep track of all first\\np moments we may use the kernel k(x  ) := (x   + )p  and if we do not want to loose any\\ninformation at all we should choose k such that k is injective over all probability measures on x \\nsuch kernels are called characteristic for standard spaces such as x = rd  many widely used\\nkernels were proven characteristic such as gaussian laplacian and matrn kernels (sriperumbudur\\net al  )\\nkx\\n\\n \\n\\n \\nthe gaussian kernel k(x  ) := e\\nmay serve as another good illustration of the flexibility\\nof this representation whatever positive bandwidth  >  we do not lose any information about\\ndistributions because k is characteristic nevertheless if  grows all distributions start looking the\\nsame because their embeddings converge to a constant function  if on the other hand  becomes\\nsmall distributions look increasingly different and \\nx becomes a function with bumps of height wi\\nat every xi  in the limit when  goes to zero each point is only similar to itself so \\nx reduces to\\nthe monte carlo method choosing  can be interpreted as controlling the degree of smoothing in\\nthe approximation\\n\\n\\n\\nreduced set methods\\n\\nan attractive feature when using kme estimators is the ability to reduce the number of expansion points (ie the size of the weighted sample) in a principled way specifically if\\n  := {(  /n )}n then the objective is to construct x\\n := {(xi  wi )}n that minimises\\nx\\nj\\nj=\\ni=\\nk\\nx  \\nx k with n < n  often the resulting xi are mutually dependent and the wi certainly\\ndepend on them the algorithms for constructing such expansions are known as reduced set methods\\nand have been studied by the machine learning community (schlkopf and smola  chapter )\\nalthough reduced set methods provide significant efficiency gains their application raises certain\\nconcerns when it comes to computing functions of random variables let p q be distributions\\nof x\\np\\nand f (x) respectively if  iid p  then f ( ) iid q and so \\nf (x  ) =  j k(f ( ) )\\np\\nreduces to the commonly used n -consistent empirical estimator of f (x) (smola et al )\\nunfortunately this is not the case after applying reduced set methods and it is not known under\\nwhich conditions \\nf (x) is a consistent estimator for f (x) \\nschlkopf et al () advocate the use of reduced expansion set methods to save computational\\nresources they also provide some reasoning why this should be the right thing to do for characteristic\\nkernels but as they state themselves their rigorous analysis does not cover practical reduced set\\nmethods motivated by this and other concerns listed in section  we provide a generalised analysis\\nof the estimator \\nf (x)  where we do not make assumptions on how xi and wi were generated\\nbefore doing that however we first illustrate how the need for reduced set methods naturally emerges\\non a concrete problem\\n\\n\\nillustration with functions of two random variables\\n\\n  = {  /n }n and y  =\\nsuppose that we want to estimate f (xy ) given iid samples x\\ni\\ni=\\n{  /n }n\\nj= from two independent random variables x  x and y  y respectively let q be\\nthe distribution of z = f (x y )\\npn\\nthe first option is to consider what we will call the diagonal estimator \\n  :=  i= kz f (   )  \\np\\nsince f (   ) iid q \\n  is n -consistent (smola et al ) another option is to p\\nconpn\\n\\n\\n\\nsider the u-statistic estimator \\n  := n  ij= kz f (xi  yj )   which is also known to be n consistent experiments show that \\n  is more accurate and has lower variance than \\n  (see figure )\\nhowever the u-statistic estimator \\n  needs o( ) memory rather than o(n) for this reason\\n  and y  to get new samschlkopf et al () propose to use a reduced set method both on x\\nn\\nn\\n\\n\\nples x = {xi  wi }i= and y = {yj  uj }j= of size n  n  and then estimate f (xy ) using\\npn\\n\\n  := ij= wi uj kx (f (xi  yj ) )\\n\\n\\n\\x0cwe ran experiments on synthetic data to show how accurately \\n  \\n  and \\n  approximate f (xy )\\nwith growing sample size n  we considered three basic arithmetic operations: multiplication\\nx  y  division x/y  and exponentiation x y  with x  n (; ) and y  n (; ) as the\\ntrue embedding f (xy ) is unknown we approximated it by a u-statistic estimator based on a large\\nsample ( points) for \\n  we used the simplest possible reduced set method: we randomly sampled\\nsubsets of size n =   n of the xi  and optimized the weights wi and ui to best approximate \\nx\\nand \\ny  the results are summarised in figure  and corroborate our expectations: (i) all estimators\\nconverge (ii) \\n  converges fastest and has the lowest variance and (iii) \\n  is worse than \\n   but\\nmuch better than the diagonal estimator \\n   note moreover that unlike the u-statistic estimator\\n\\n   the reduced set based estimator \\n  can be used with a fixed storage budget even if we perform\\na sequence of function applicationsa situation naturally appearing in the context of probabilistic\\nprogramming\\nschlkopf et al () prove the consistency of \\n  only for a rather limited case when the points\\nof the reduced expansions {xi }ni= and {yi }ni= are iid copies of x and y  respectively and\\nthe weights {(wi  ui )}ni= are constants using our new results we will prove in section  the\\nconsistency of \\n  under fairly general conditions even in the case when both expansion points and\\nweights are interdependent random variables\\n\\nfigure : error of kernel mean estimators for basic arithmetic functions of two variables x  y \\nx/y and x y  as a function of sample size n  the u -statistic estimator \\n works best closely\\nfollowed by the proposed estimator \\n  which outperforms the diagonal estimator \\n \\n\\n\\nother sources of non-iid samples\\n\\nalthough our discussion above focuses on reduced expansion set methods there are other popular\\nalgorithms that produce kme expansions where the samples are not iid here we briefly discuss\\nseveral examples emphasising that our selection is not comprehensive they provide additional\\nmotivation for stating convergence guarantees in the most general setting possible\\nan important notion in probability theory is that of a conditional distribution which can also be\\nrepresented using kme (song et al ) with this representation the standard laws of probability\\nsuch as sum product and bayes rules can be stated using kme (fukumizu et al ) applying\\nthose rules results in kme estimators with strong dependencies between samples and their weights\\nanother possibility is that even though iid samples are available they may not produce the best\\nestimator various approaches such as kernel herding (chen et al ; lacoste-julien et al\\n) attempt to produce a better kme estimator by actively generating pseudo-samples that are not\\niid from the underlying distribution\\n\\n\\n\\nmain results\\n\\nthis section contains our main results regarding consistency and finite sample guarantees for the\\nestimator \\nf (x) defined in () they are based on the convergence of \\nx and avoid simplifying\\nassumptions about its structure\\n\\n\\n\\x0c\\n\\nconsistency\\n\\nif kx is  -universal (see sriperumbudur et al ()) consistency of \\nf (x) can be shown in a rather\\ngeneral setting\\ntheorem  let x and z be compact hausdorff spaces equipped with their borel -algebras\\nf : x  z a continuous function kx  kz continuous\\nkernels on x  z respectively assume kx is\\np\\n -universal and that there exists c such that i |wi |  c independently of n the following holds:\\nif\\n\\n\\nkxx  kxx\\n\\n\\nkf z(x)  kf z(x)\\n\\nthen\\n\\nas n  \\n\\npn\\nproof let p be the distribution of x and pn =\\ni= wi xi  define a new kernel on x by\\ne\\nkx (   ) := kz f ( ) f ( )  x is compact and {pn | n  n} [ {p } is a bounded set (in\\npn\\ntotal variation norm) of finite measures because kpn kt v = i= |wi |  c furthermore kx\\nis continuous and  -universal using corollary  of simon-gabriel and schlkopf () we\\nconclude that: \\nkxx  kxx implies that p converges weakly to p  now kz and f being continuous\\ne\\ne\\nso is e\\nkx  thus if p converges weakly to p  then \\nkx  kx (simon-gabriel and schlkopf \\nx\\nkxx\\n\\n\\nkxx\\n\\nx\\n\\ne\\n\\ne\\n\\ntheorem  points () and (iii)) overall\\n\\nimplies \\nkxx  kxx  we conclude the proof\\nby showing that convergence in hekx leads to convergence in hkz :\\n\\nkf z(x)\\n\\nkf z(x)\\n\\n\\n\\nkz\\n\\ne\\n\\n= \\nkxx\\n\\nfor a detailed version of the above see appendix a\\n\\ne\\n\\nkxx\\n\\n\\n\\ne\\nkx\\n\\n \\n\\nthe continuity assumption is rather unrestrictive all kernels and functions defined on a discrete\\nspace are continuous with respect to the discrete topology so the theorem applies in this case for\\nx = rd  many kernels used in practice are continuous including gaussian laplacian matrn and\\nother radial kernels the slightly limiting factor of this theorem is that kx must be  -universal which\\noften can be tricky to verify however most standard kernelsincluding all radial non-constant\\nkernelsare  -universal (see sriperumbudur et al ) the assumption that the input domain\\nis compact is satisfied in most applications since any measurements\\np coming from physical sensors\\nare contained in a bounded range finally the assumption that i |wi |  c can be enforced for\\ninstance by applying a suitable regularization in reduced set methods\\n\\n\\nfinite sample guarantees\\n\\ntheorem  guarantees that the estimator \\nf (x) converges to f (x) when \\nx converges to x \\nhowever it says nothing about the speed of convergence in this section we provide a convergence\\nrate when working with matrn kernels which are of the form\\nkxs (x  ) =\\n\\n s\\nkx\\n(s)\\n\\ns d/\\n\\n \\n\\nbd/\\n\\ns\\n\\n(kx\\n\\n  ) \\n\\n()\\n\\nwhere b is a modified bessel function of the third kind (also known as macdonald function) of\\norder  is the gamma function and s >  is a smoothness parameter the rkhs induced by\\nkxs is the sobolev space  (rd ) (wendland  theorem  & ) containing s-times\\ndifferentiable functions the finite-sample bound of theorem  is based on the analysis of kanagawa\\net al () which requires the following assumptions:\\n =\\nassumptions  let x be a random variable over x = rd with distribution p and let x\\n{(xi  wi )}ni= be random variables over x n  rn with joint distribution s there exists a probability\\ndistribution q with full support on rd and a bounded density satisfying the following properties:\\n(i) p has a bounded density function wrt q;\\n(ii) there is a constant d >  independent of n such that\\n\" n\\n#\\n \\n\\ng (xi )  d  (q) \\ne\\ns n\\ni=\\n\\n\\n   (q) \\n\\n\\x0cthese assumptions were shown to be fairly general and we refer to kanagawa et al ( section\\n) for various examples where they are met next we state the main result of this section\\n\\n\\ntheorem  let x = rd  z = rd  and f : x  z be an -times differentiable function (  n+ )\\ntake  > d/ and  >  such that    /  n+  let  and  be matrn kernels over x and\\n = {(xi  wi )}n  s satisfy  moreover\\nz respectively as defined in () assume x  p and x\\ni=\\nassume that p and the marginals of      xn have a common compact support suppose that for\\nsome constants b >  and  < c  /:\\nh\\ni\\n\\n(i) es k\\nx x  = o(n  ) ;\\npn\\n\\n\\n(ii)\\n) (with probability ) \\ni= wi = o(n\\n\\nlet  = min( \\n   ) and assume b (/ c)( ) >  then\\n \\n\\n\\n\\n\\nf (x) f (x)  = o (log n)d n  (b (/\\ne \\nkz\\n\\ns\\n\\nc)( ))\\n\\n\\n\\n\\n\\n()\\n\\nbefore we provide a short sketch of the proof let us briefly comment on this result as a benchmark\\n = {(xi  /n)}n  we get\\nremember that when      xn are iid observations from x and x\\ni=\\n\\n\\nk\\nf (x) f (x) k = op (n ) which was recently shown to be a minimax optimal rate (tolstikhin\\net al ) how do we compare to this benchmark in this case we have b = c = / and our rate\\nis defined by  if f is smooth enough say  > d/ +  and by setting  >  =  we recover\\n\\nthe o(n  ) rate up to an extra (log n)d factor\\nhowever theorem  applies to much more general settings importantly it makes no iid assumptions on the data points and weights allowing for complex interdependences instead it asks the\\nconvergence of the estimator \\nx to the embedding x to be sufficiently fast on the downside the\\nupper bound is affected by the smoothness of f  even in the iid setting: if   d/ the rate will\\nbecome slower as  = /  also the rate depends both on d and   whether these are artefacts of\\nour proof remains an open question\\nproof here we sketch the main ideas of the proof and develop the details in appendix c throughout\\nthe proof c will designate a constant that depends neither on the sample size n nor on the variable r\\n(to be introduced) c may however change from line to line we start by showing that:\\n\\n\\nz\\n\\n\\n\\nkz\\nkz\\n\\nf (x) f (x)\\n= ()\\nhf(x) hf(x) ](z)\\ndz\\n()\\ne \\ne [\\nkz\\n\\ns\\n\\nz s\\n\\nwhere h is matrn kernel over z with smoothness parameter  / second we upper bound the\\nintegrand by roughly imitating the proof idea of theorem  from kanagawa et al () this\\neventually yields:\\n\\n\\nhf(x) hf(x) ](z)\\n cn  \\n()\\ne [\\ns\\n\\nwhere  := b (/ c)( ) unfortunately this upper bound does not depend on z and can\\nnot be integrated over the whole z in () denoting br the ball of radius r centred on the origin of\\nz we thus decompose the integral in () as:\\n\\nz\\n\\nhf(x) hf(x) ](z)\\ndz\\ne [\\nz\\n\\n\\nz\\nz\\n\\n\\nh\\nh\\n=\\nf (x) f (x) ](z)\\ndz +\\nhf(x) hf(x) ](z)\\ndz\\ne [\\ne [\\nz\\\\br\\n\\nbr\\n\\non br we upper bound the integral by () times the balls volume (which grows like rd ):\\n\\nz\\n\\nhf(x) hf(x) ](z)\\ndz  crd n  \\ne [\\n\\n()\\n\\nbr\\n\\non x \\\\br  we upper bound the integral by a value that decreases with r which is of the form:\\n\\nz\\n\\n\\nhf(x) hf(x) ](z)\\ndz    (r c  )  e (r c )\\n()\\ne [\\nz\\\\br\\n\\n\\n\\n\\x0cwith c  >  being a constant smaller than r in essence this upper bound decreases with r because\\n[\\nhf(x) hf(x) ](z) decays with the same speed as h when kzk grows indefinitely we are now left\\nwith two rates () and () which respectively increase and decrease with growing r we complete\\nthe proof by balancing these two terms which results in setting r  (log n)/ \\n\\n\\n\\nfunctions of multiple arguments\\n\\nthe previous section applies to functions f of one single variable x however we can apply its\\nresults to functions of multiple variables if we take the argument x to be a tuple containing multiple\\nvalues in this section we discuss how to do it using two input variables from spaces x and y but\\nthe results also apply to more inputs to be precise our input space changes from x to x  y input\\nrandom variable from x to (x y ) and the kernel on the input space from kx to kxy \\nto apply our results from section  all we need is a consistent estimator \\n(xy ) of the joint embedding\\n(xy )  there are different ways to get such an estimator one way is to sample (   ) iid from\\nthe joint distribution of (x y ) and construct the usual empirical estimator or approximate it using\\nreduced set methods alternatively we may want to construct \\n(xy ) based only on consistent\\nestimators of x and y  for example this is how \\n  was defined in section  below we show\\nthat this can indeed be done if x and y are independent\\n\\n\\napplication to section \\n\\nfollowing schlkopf et al () we consider two independent random variables x  px and\\ny  py  their p\\njoint distribution is px  py  pconsistent estimators of their embeddings are\\nn\\nn\\ngiven by \\nx =\\ny =\\ni= wi kx (xi  ) and \\nj= uj ky (yi  ) in this section we show that\\npn\\n\\nf (xy ) = ij= wi uj kz f (xi  yj )  is a consistent estimator of f (xy ) \\n\\nwe choose a product kernel kxy (   ) (   ) = kx (   )ky (   ) so the corresponding\\nrkhs is a tensor product hkxy = hkx  hky (steinwart and christmann  lemma ) and\\nthe mean embedding of the product random variable (x y ) is a tensor product of their marginal\\nmean embeddings (xy ) = x  y  with consistent estimators for the marginal embeddings we\\ncan estimate the joint embedding using their tensor product\\n\\n(xy ) = \\nx  \\ny =\\n\\nn\\nx\\n\\nij=\\n\\nwi uj kx (xi  )  ky (yj  ) =\\n\\nn\\nx\\n\\nwi uj kxy (xi  yj ) (  ) \\n\\nij=\\n\\nif points are iid and wi = ui = /n this reduces to the u-statistic estimator \\n from section \\nlemma  let (sn )n be any positive real sequence converging to zero suppose kxy = kx ky is a\\nproduct kernel (xy ) = x  y  and \\n(xy ) = \\nx  \\ny  then:\\n(\\nk\\nx x kkx = o(sn );\\nimplies\\n\\n(xy ) (xy )\\n= o(sn ) \\nk\\ny y kky = o(sn )\\nkxy\\nproof for a detailed expansion of the first inequality see appendix b\\n\\n(xy )\\n\\n(xy )\\n\\n+ k\\nx\\ncorollary  if \\nx\\n\\nkxy\\n\\n kx kkx k\\ny\\n\\nx kkx k\\ny\\n x and \\ny\\n\\n\\n\\ny kky + ky kky k\\nx\\n\\nx kkx\\n\\ny kky = o(sn ) + o(sn ) + o( ) = o(sn )\\n y  then \\n(xy )\\n\\n\\n\\n (xy ) \\n\\n\\n\\ntogether with the results from section  this lets us reason about estimators resulting from applying\\nfunctions to multiple independent random variables write\\nkxy\\n\\nxy\\n\\n=\\n\\nn\\nx\\n\\n\\n\\nwi uj kxy (xi  yj )  =\\n\\nij=\\n\\nn\\nx\\n`=\\n\\n\\n\\n` kxy (`  )\\n\\n\\x0cwhere ` enumerates the (i j) pairs and ` = (xi  yj ) ` = wi uj  now if \\nkxx  kxx\\nky\\nky\\nkxy\\nkxy\\nand \\n  y then \\nxy  (xy ) (according to corollary ) and theorem  shows that\\npn y\\nw\\nu\\nk\\nf\\n(x\\n\\ny\\ni j )  is consistent as well unfortunately we cannot apply theorem  to get\\nij= i j z\\nthe speed of convergence because a product of matrn kernels is not a matrn kernel any more\\n\\none downside of this overall approach is that the number of expansion points used for the estimation\\nof the joint increases exponentially with the number of arguments of f  this can lead to prohibitively\\nlarge computational costs especially if the result of such an operation is used as an input to another\\nfunction of multiple arguments to alleviate this problem we may use reduced expansion set methods\\nbefore or after applying f  as we did for example in section \\n\\nto conclude this section let us summarize the implications of our results for two practical scenarios\\nthat should be distinguished\\n if we have separate samples from two random variables x and y  then our results justify\\nhow to provide an estimate of the mean embedding of f (x y ) provided that x and y are\\nindependent the samples themselves need not be iid  we can also work with weighted\\nsamples computed for instance by a reduced set method\\n how about dependent random variables for instance imagine that y = x and\\nf (x y ) = x + y  clearly in this case the distribution of f (x y ) is a delta measure on  and there is no way to predict this from separate samples of x and y  however\\nit should be stressed that our results (consistency and finite sample bound) apply even to\\nthe case where x and y are dependent in that case however they require a consistent\\nestimator of the joint embedding (xy ) \\n it is also sufficient to have a reduced set expansion of the embedding of the joint distribution\\nthis setting may sound strange but it potentially has significant applications imagine that\\none has a large database of user data sampled from a joint distribution if we expand the\\njoints embedding in terms of synthetic expansion points using a reduced set construction\\nmethod then we can pass on these (weighted) synthetic expansion points to a third party\\nwithout revealing the original data using our results the third party can nevertheless\\nperform arbitrary continuous functional operations on the joint distribution in a consistent\\nmanner\\n\\n\\n\\nconclusion and future work\\n\\nthis paper provides a theoretical foundation for using kernel mean embeddings as approximate\\nrepresentations of random variables in scenarios where we need to apply functions to those random\\nvariables we show that for continuous functions f (including all functions on discrete domains)\\nconsistency of the mean embedding estimator of a random variable x implies consistency of the\\nmean embedding estimator of f (x) furthermore if the kernels are matrn and the function f\\nis sufficiently smooth we provide bounds on the convergence rate importantly our results apply\\nbeyond iid samples and cover estimators based on expansions with interdependent points and\\nweights one interesting future direction is to improve the finite-sample bounds and extend them to\\ngeneral radial and/or translation-invariant kernels\\nour work is motivated by the field of probabilistic programming using our theoretical results\\nkernel mean embeddings can be used to generalize functional operations (which lie at the core of\\nall programming languages) to distributions over data types in a principled manner by applying the\\noperations to the points or approximate kernel expansions this is in principle feasible for any data\\ntype provided a suitable kernel function can be defined on it we believe that the approach holds\\nsignificant potential for future probabilistic programming systems\\nacknowledgements\\nwe thank krikamol muandet for providing the code used to generate figure  paul rubenstein\\nmotonobu kanagawa and bharath sriperumbudur for very useful discussions and our anonymous\\nreviewers for their valuable feedback carl-johann simon-gabriel is supported by a google european\\nfellowship in causal inference\\n\\n\\n\\x0creferences\\nr a adams and j j f fournier sobolev spaces academic press \\nc bennett and r sharpley interpolation of operators pure and applied mathematics elsevier science \\na berlinet and c thomas-agnan rkhs in probability and statistics springer \\ny chen m welling and a smola super-samples from kernel herding in uai \\nk fukumizu l song and a gretton kernel bayes rule: bayesian inference with positive definite kernels\\njournal of machine learning research : \\ni s gradshteyn and i m ryzhik table of integrals series and products elsevier/academic press amsterdam\\n edited by alan jeffrey and daniel zwillinger\\nm kalos and p whitlock monte carlo methods wiley \\nm kanagawa b k sriperumbudur and k fukumizu convergence guarantees for kernel-based quadrature\\nrules in misspecified settings arxiv: [stat]  arxiv: \\ny katznelson an introduction to harmonic analysis cambridge university press \\nm korzen and s jaroszewicz pacal: a python package for arithmetic computations with random variables\\njournal of statistical software () \\ns lacoste-julien f lindsten and f bach sequential kernel herding : frank-wolfe optimization for particle\\nfiltering in artificial intelligence and statistics volume  pages  \\na mathai a review of the different techniques used for deriving the exact distributions of multivariate test\\ncriteria sankhya: the indian journal of statistics series a pages  \\nk mckinley programming the world of uncertain things (keynote) in acm sigplan-sigact symposium on\\nprinciples of programming languages pages  \\nd milios probability distributions as program variables phd thesis university of edinburgh \\ns poisson recherches sur la probabilitdes jugements en matire criminelle et en matire civile prcdes des\\nrgles gnrales du calcul des probabilits \\nb schlkopf and a j smola learning with kernels: support vector machines regularization optimization\\nand beyond mit press \\nb schlkopf k muandet k fukumizu s harmeling and j peters computing functions of random variables\\nvia reproducing kernel hilbert space representations statistics and computing (): \\nc scovel d hush i steinwart and j theiler radial kernels and their reproducing kernel hilbert spaces\\njournal of complexity  \\nc-j simon-gabriel and b schlkopf kernel distribution embeddings: universal kernels characteristic kernels\\nand kernel metrics on distributions technical report max planck institute for intelligent systems \\na smola a gretton l song and b schlkopf a hilbert space embedding for distributions in alt \\nl song j huang a smola and k fukumizu hilbert space embeddings of conditional distributions with\\napplications to dynamical systems in international conference on machine learning pages  \\nm d springer the algebra of random variables wiley \\nb k sriperumbudur a gretton k fukumizu b schlkopf and g r lanckriet hilbert space embeddings\\nand metrics on probability measures journal of machine learning research : \\nb k sriperumbudur k fukumizu and g r g lanckriet universality characteristic kernels and rkhs\\nembedding of measures journal of machine learning research : \\ni steinwart and a christmann support vector machines information science and statistics springer \\ni steinwart and c scovel mercers theorem on general domains: on the interaction between measures\\nkernels and rkhss constructive approximation (): \\ni tolstikhin b sriperumbudur and k muandet\\narxiv: [math stat] \\n\\nminimax estimation of kernel mean embeddings\\n\\nh wendland scattered data approximation cambridge university press \\nr williamson probabilistic arithmetic phd thesis university of queensland \\n\\n\\n\\n\\x0c'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["text_as_words = list(convert_sentences_to_words(text_to_list))"],"metadata":{"id":"MonNFDHhxEdA","executionInfo":{"status":"ok","timestamp":1751185228875,"user_tz":-330,"elapsed":2098,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["len(text_as_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEfGpWssxfph","executionInfo":{"status":"ok","timestamp":1751185253972,"user_tz":-330,"elapsed":44,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"c5608f2a-e576-481e-8c62-44b2aa5dfc73"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["print(text_as_words[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4MM2b9_xxmSA","executionInfo":{"status":"ok","timestamp":1751185272310,"user_tz":-330,"elapsed":52,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"23120630-4fa2-4f88-dcfc-daf3f221f71c"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["['consistent', 'kernel', 'mean', 'estimation', 'for', 'functions', 'of', 'random', 'variables', 'carl', 'johann', 'simon', 'gabriel', 'adam', 'scibior', 'ilya', 'tolstikhin', 'bernhard', 'schlkopf', 'department', 'of', 'empirical', 'inference', 'max', 'planck', 'institute', 'for', 'intelligent', 'systems', 'spemanstrae', 'tbingen', 'germany', 'joint', 'first', 'authors', 'also', 'with', 'engineering', 'department', 'cambridge', 'university', 'cjsimon', 'adamscibior', 'ilya', 'bs', 'tuebingenmpgde', 'abstract', 'we', 'provide', 'theoretical', 'foundation', 'for', 'non', 'parametric', 'estimation', 'of', 'functions', 'of', 'random', 'variables', 'using', 'kernel', 'mean', 'embeddings', 'we', 'show', 'that', 'for', 'any', 'continuous', 'function', 'consistent', 'estimators', 'of', 'the', 'mean', 'embedding', 'of', 'random', 'variable', 'lead', 'to', 'consistent', 'estimators', 'of', 'the', 'mean', 'embedding', 'of', 'for', 'matrn', 'kernels', 'and', 'sufficiently', 'smooth', 'functions', 'we', 'also', 'provide', 'rates', 'of', 'convergence', 'our', 'results', 'extend', 'to', 'functions', 'of', 'multiple', 'random', 'variables', 'if', 'the', 'variables', 'are', 'dependent', 'we', 'require', 'an', 'estimator', 'of', 'the', 'mean', 'embedding', 'of', 'their', 'joint', 'distribution', 'as', 'starting', 'point', 'if', 'they', 'are', 'independent', 'it', 'is', 'sufficient', 'to', 'have', 'separate', 'estimators', 'of', 'the', 'mean', 'embeddings', 'of', 'their', 'marginal', 'distributions', 'in', 'either', 'case', 'our', 'results', 'cover', 'both', 'mean', 'embeddings', 'based', 'on', 'iid', 'samples', 'as', 'well', 'as', 'reduced', 'set', 'expansions', 'in', 'terms', 'of', 'dependent', 'expansion', 'points', 'the', 'latter', 'serves', 'as', 'justification', 'for', 'using', 'such', 'expansions', 'to', 'limit', 'memory', 'resources', 'when', 'applying', 'the', 'approach', 'as', 'basis', 'for', 'probabilistic', 'programming', 'introduction', 'common', 'task', 'in', 'probabilistic', 'modelling', 'is', 'to', 'compute', 'the', 'distribution', 'of', 'given', 'measurable', 'function', 'and', 'random', 'variable', 'in', 'fact', 'the', 'earliest', 'instances', 'of', 'this', 'problem', 'date', 'back', 'at', 'least', 'to', 'poisson', 'sometimes', 'this', 'can', 'be', 'done', 'analytically', 'for', 'example', 'if', 'is', 'linear', 'and', 'is', 'gaussian', 'that', 'is', 'ax', 'and', 'we', 'have', 'there', 'exist', 'various', 'methods', 'for', 'obtaining', 'such', 'analytical', 'expressions', 'mathai', 'but', 'outside', 'small', 'subset', 'of', 'distributions', 'and', 'functions', 'the', 'formulae', 'are', 'either', 'not', 'available', 'or', 'too', 'complicated', 'to', 'be', 'practical', 'an', 'alternative', 'to', 'the', 'analytical', 'approach', 'is', 'numerical', 'approximation', 'ideally', 'implemented', 'as', 'flexible', 'software', 'library', 'the', 'need', 'for', 'such', 'tools', 'is', 'recognised', 'in', 'the', 'general', 'programming', 'languages', 'community', 'mckinley', 'but', 'no', 'standards', 'were', 'established', 'so', 'far', 'the', 'main', 'challenge', 'is', 'in', 'finding', 'good', 'approximate', 'representation', 'for', 'random', 'variables', 'distributions', 'on', 'integers', 'for', 'example', 'are', 'usually', 'represented', 'as', 'lists', 'of', 'xi', 'xi', 'pairs', 'for', 'real', 'valued', 'distributions', 'integral', 'transforms', 'springer', 'mixtures', 'of', 'gaussians', 'milios', 'laguerre', 'polynomials', 'williamson', 'and', 'chebyshev', 'polynomials', 'korzen', 'and', 'jaroszewicz', 'were', 'proposed', 'as', 'convenient', 'representations', 'for', 'numerical', 'computation', 'for', 'strings', 'probabilistic', 'finite', 'automata', 'are', 'often', 'used', 'all', 'those', 'approaches', 'have', 'their', 'merits', 'but', 'they', 'only', 'work', 'with', 'specific', 'input', 'type', 'there', 'is', 'an', 'alternative', 'based', 'on', 'monte', 'carlo', 'sampling', 'kalos', 'and', 'whitlock', 'which', 'is', 'to', 'represent', 'by', 'possibly', 'weighted', 'sample', 'xi', 'wi', 'ni', 'with', 'wi', 'this', 'representation', 'has', 'several', 'advantages', 'it', 'works', 'for', 'any', 'input', 'type', 'ii', 'the', 'sample', 'size', 'controls', 'the', 'time', 'accuracy', 'trade', 'off', 'and', 'iii', 'applying', 'functions', 'to', 'random', 'variables', 'reduces', 'to', 'applying', 'the', 'functions', 'pointwise', 'conference', 'on', 'neural', 'information', 'processing', 'systems', 'nips', 'barcelona', 'spain', 'to', 'the', 'sample', 'ie', 'xi', 'wi', 'representsp', 'furthermore', 'expectations', 'of', 'functions', 'of', 'random', 'variables', 'can', 'be', 'estimated', 'as', 'wi', 'xi', 'wi', 'sometimes', 'with', 'guarantees', 'for', 'the', 'convergence', 'rate', 'the', 'flexibility', 'of', 'this', 'monte', 'carlo', 'approach', 'comes', 'at', 'cost', 'without', 'further', 'assumptions', 'on', 'the', 'underlying', 'input', 'space', 'it', 'is', 'hard', 'to', 'quantify', 'the', 'accuracy', 'of', 'this', 'representation', 'for', 'instance', 'given', 'two', 'samples', 'of', 'the', 'same', 'size', 'xi', 'wi', 'ni', 'and', 'ni', 'how', 'can', 'we', 'tell', 'which', 'one', 'is', 'better', 'representation', 'of', 'more', 'generally', 'how', 'could', 'we', 'optimize', 'representation', 'with', 'predefined', 'sample', 'size', 'there', 'exists', 'an', 'alternative', 'to', 'the', 'monte', 'carlo', 'approach', 'called', 'kernel', 'mean', 'embeddings', 'kme', 'berlinet', 'and', 'thomas', 'agnan', 'smola', 'et', 'al', 'it', 'also', 'represents', 'random', 'variables', 'as', 'samples', 'but', 'additionally', 'defines', 'notion', 'of', 'similarity', 'between', 'sample', 'points', 'as', 'result', 'it', 'keeps', 'all', 'the', 'advantages', 'of', 'the', 'monte', 'carlo', 'scheme', 'ii', 'it', 'includes', 'the', 'monte', 'carlo', 'method', 'as', 'special', 'case', 'iii', 'it', 'overcomes', 'its', 'pitfalls', 'described', 'above', 'and', 'iv', 'it', 'can', 'be', 'tailored', 'to', 'focus', 'on', 'different', 'properties', 'of', 'depending', 'on', 'the', 'users', 'needs', 'and', 'prior', 'assumptions', 'the', 'kme', 'approach', 'identifies', 'both', 'sample', 'points', 'and', 'distributions', 'with', 'functions', 'in', 'an', 'abstract', 'hilbert', 'space', 'internally', 'the', 'latter', 'are', 'still', 'represented', 'as', 'weighted', 'samples', 'but', 'the', 'weights', 'can', 'be', 'negative', 'and', 'the', 'straightforward', 'monte', 'carlo', 'interpretation', 'is', 'no', 'longer', 'valid', 'schlkopf', 'et', 'al', 'propose', 'using', 'kmes', 'as', 'approximate', 'representation', 'of', 'random', 'variables', 'for', 'the', 'purpose', 'of', 'computing', 'their', 'functions', 'however', 'they', 'only', 'provide', 'theoretical', 'justification', 'for', 'it', 'in', 'rather', 'idealised', 'settings', 'which', 'do', 'not', 'meet', 'practical', 'implementation', 'requirements', 'in', 'this', 'paper', 'we', 'build', 'on', 'this', 'work', 'and', 'provide', 'general', 'theoretical', 'guarantees', 'for', 'the', 'proposed', 'estimators', 'specifically', 'we', 'prove', 'statements', 'of', 'the', 'form', 'if', 'xi', 'wi', 'ni', 'provides', 'good', 'estimate', 'for', 'the', 'kme', 'of', 'then', 'xi', 'wi', 'ni', 'provides', 'good', 'estimate', 'for', 'the', 'kme', 'of', 'importantly', 'our', 'results', 'do', 'not', 'assume', 'joint', 'independence', 'of', 'the', 'observations', 'xi', 'and', 'weights', 'wi', 'this', 'makes', 'them', 'powerful', 'tool', 'for', 'instance', 'imagine', 'we', 'are', 'given', 'data', 'xi', 'wi', 'ni', 'from', 'random', 'variable', 'that', 'we', 'need', 'to', 'compress', 'then', 'our', 'theorems', 'guarantee', 'that', 'whatever', 'compression', 'algorithm', 'we', 'use', 'as', 'long', 'as', 'the', 'compressed', 'representation', 'nj', 'still', 'provides', 'good', 'estimate', 'for', 'the', 'kme', 'of', 'the', 'pointwise', 'images', 'nj', 'provide', 'good', 'estimates', 'of', 'the', 'kme', 'of', 'in', 'the', 'remainder', 'of', 'this', 'section', 'we', 'first', 'introduce', 'kmes', 'and', 'discuss', 'their', 'merits', 'then', 'we', 'explain', 'why', 'and', 'how', 'we', 'extend', 'the', 'results', 'of', 'schlkopf', 'et', 'al', 'section', 'contains', 'our', 'main', 'results', 'in', 'section', 'we', 'show', 'consistency', 'of', 'the', 'relevant', 'estimator', 'in', 'general', 'setting', 'and', 'in', 'section', 'we', 'provide', 'finite', 'sample', 'guarantees', 'when', 'matrn', 'kernels', 'are', 'used', 'in', 'section', 'we', 'show', 'how', 'our', 'results', 'apply', 'to', 'functions', 'of', 'multiple', 'variables', 'both', 'interdependent', 'and', 'independent', 'section', 'concludes', 'with', 'discussion', 'background', 'on', 'kernel', 'mean', 'embeddings', 'let', 'be', 'measurable', 'input', 'space', 'we', 'use', 'positive', 'definite', 'bounded', 'and', 'measurable', 'kernel', 'xi', 'wi', 'to', 'represent', 'random', 'variables', 'and', 'weighted', 'samples', 'as', 'two', 'functions', 'and', 'in', 'the', 'corresponding', 'reproducing', 'kernel', 'hilbert', 'space', 'rkhs', 'hk', 'by', 'defining', 'kx', 'dp', 'and', 'kx', 'wi', 'xi', 'these', 'are', 'guaranteed', 'to', 'exist', 'since', 'we', 'assume', 'the', 'kernel', 'is', 'bounded', 'smola', 'et', 'al', 'when', 'clear', 'from', 'the', 'context', 'we', 'omit', 'the', 'kernel', 'in', 'the', 'superscript', 'is', 'called', 'the', 'kme', 'of', 'but', 'we', 'also', 'refer', 'to', 'it', 'as', 'the', 'kme', 'of', 'in', 'this', 'paper', 'we', 'focus', 'on', 'computing', 'functions', 'of', 'random', 'variables', 'for', 'where', 'is', 'measurable', 'space', 'and', 'for', 'positive', 'definite', 'bounded', 'kz', 'we', 'also', 'write', 'kf', 'kz', 'dp', 'and', 'kf', 'wi', 'kz', 'xi', 'to', 'functions', 'in', 'the', 'rkhs', 'is', 'that', 'the', 'advantage', 'of', 'mapping', 'random', 'variables', 'and', 'samples', 'we', 'may', 'now', 'say', 'that', 'is', 'good', 'approximation', 'for', 'if', 'the', 'rkhs', 'distance', 'is', 'small', 'this', 'distance', 'depends', 'on', 'the', 'choice', 'of', 'the', 'kernel', 'and', 'different', 'kernels', 'emphasise', 'different', 'information', 'about', 'for', 'example', 'if', 'on', 'we', 'choose', 'then', 'exp', 'thus', 'any', 'two', 'distributions', 'and', 'or', 'samples', 'with', 'equal', 'means', 'are', 'mapped', 'to', 'the', 'same', 'function', 'in', 'hk', 'so', 'the', 'distance', 'between', 'them', 'is', 'zero', 'therefore', 'using', 'this', 'particular', 'we', 'keep', 'track', 'only', 'of', 'the', 'mean', 'of', 'the', 'distributions', 'if', 'instead', 'we', 'prefer', 'to', 'keep', 'track', 'of', 'all', 'first', 'moments', 'we', 'may', 'use', 'the', 'kernel', 'and', 'if', 'we', 'do', 'not', 'want', 'to', 'loose', 'any', 'information', 'at', 'all', 'we', 'should', 'choose', 'such', 'that', 'is', 'injective', 'over', 'all', 'probability', 'measures', 'on', 'such', 'kernels', 'are', 'called', 'characteristic', 'for', 'standard', 'spaces', 'such', 'as', 'rd', 'many', 'widely', 'used', 'kernels', 'were', 'proven', 'characteristic', 'such', 'as', 'gaussian', 'laplacian', 'and', 'matrn', 'kernels', 'sriperumbudur', 'et', 'al', 'kx', 'the', 'gaussian', 'kernel', 'may', 'serve', 'as', 'another', 'good', 'illustration', 'of', 'the', 'flexibility', 'of', 'this', 'representation', 'whatever', 'positive', 'bandwidth', 'we', 'do', 'not', 'lose', 'any', 'information', 'about', 'distributions', 'because', 'is', 'characteristic', 'nevertheless', 'if', 'grows', 'all', 'distributions', 'start', 'looking', 'the', 'same', 'because', 'their', 'embeddings', 'converge', 'to', 'constant', 'function', 'if', 'on', 'the', 'other', 'hand', 'becomes', 'small', 'distributions', 'look', 'increasingly', 'different', 'and', 'becomes', 'function', 'with', 'bumps', 'of', 'height', 'wi', 'at', 'every', 'xi', 'in', 'the', 'limit', 'when', 'goes', 'to', 'zero', 'each', 'point', 'is', 'only', 'similar', 'to', 'itself', 'so', 'reduces', 'to', 'the', 'monte', 'carlo', 'method', 'choosing', 'can', 'be', 'interpreted', 'as', 'controlling', 'the', 'degree', 'of', 'smoothing', 'in', 'the', 'approximation', 'reduced', 'set', 'methods', 'an', 'attractive', 'feature', 'when', 'using', 'kme', 'estimators', 'is', 'the', 'ability', 'to', 'reduce', 'the', 'number', 'of', 'expansion', 'points', 'ie', 'the', 'size', 'of', 'the', 'weighted', 'sample', 'in', 'principled', 'way', 'specifically', 'if', 'then', 'the', 'objective', 'is', 'to', 'construct', 'xi', 'wi', 'that', 'minimises', 'with', 'often', 'the', 'resulting', 'xi', 'are', 'mutually', 'dependent', 'and', 'the', 'wi', 'certainly', 'depend', 'on', 'them', 'the', 'algorithms', 'for', 'constructing', 'such', 'expansions', 'are', 'known', 'as', 'reduced', 'set', 'methods', 'and', 'have', 'been', 'studied', 'by', 'the', 'machine', 'learning', 'community', 'schlkopf', 'and', 'smola', 'chapter', 'although', 'reduced', 'set', 'methods', 'provide', 'significant', 'efficiency', 'gains', 'their', 'application', 'raises', 'certain', 'concerns', 'when', 'it', 'comes', 'to', 'computing', 'functions', 'of', 'random', 'variables', 'let', 'be', 'distributions', 'of', 'and', 'respectively', 'if', 'iid', 'then', 'iid', 'and', 'so', 'reduces', 'to', 'the', 'commonly', 'used', 'consistent', 'empirical', 'estimator', 'of', 'smola', 'et', 'al', 'unfortunately', 'this', 'is', 'not', 'the', 'case', 'after', 'applying', 'reduced', 'set', 'methods', 'and', 'it', 'is', 'not', 'known', 'under', 'which', 'conditions', 'is', 'consistent', 'estimator', 'for', 'schlkopf', 'et', 'al', 'advocate', 'the', 'use', 'of', 'reduced', 'expansion', 'set', 'methods', 'to', 'save', 'computational', 'resources', 'they', 'also', 'provide', 'some', 'reasoning', 'why', 'this', 'should', 'be', 'the', 'right', 'thing', 'to', 'do', 'for', 'characteristic', 'kernels', 'but', 'as', 'they', 'state', 'themselves', 'their', 'rigorous', 'analysis', 'does', 'not', 'cover', 'practical', 'reduced', 'set', 'methods', 'motivated', 'by', 'this', 'and', 'other', 'concerns', 'listed', 'in', 'section', 'we', 'provide', 'generalised', 'analysis', 'of', 'the', 'estimator', 'where', 'we', 'do', 'not', 'make', 'assumptions', 'on', 'how', 'xi', 'and', 'wi', 'were', 'generated', 'before', 'doing', 'that', 'however', 'we', 'first', 'illustrate', 'how', 'the', 'need', 'for', 'reduced', 'set', 'methods', 'naturally', 'emerges', 'on', 'concrete', 'problem', 'illustration', 'with', 'functions', 'of', 'two', 'random', 'variables', 'and', 'suppose', 'that', 'we', 'want', 'to', 'estimate', 'xy', 'given', 'iid', 'samples', 'from', 'two', 'independent', 'random', 'variables', 'and', 'respectively', 'let', 'be', 'the', 'distribution', 'of', 'pn', 'the', 'first', 'option', 'is', 'to', 'consider', 'what', 'we', 'will', 'call', 'the', 'diagonal', 'estimator', 'kz', 'since', 'iid', 'is', 'consistent', 'smola', 'et', 'al', 'another', 'option', 'is', 'to', 'conpn', 'sider', 'the', 'statistic', 'estimator', 'ij', 'kz', 'xi', 'yj', 'which', 'is', 'also', 'known', 'to', 'be', 'consistent', 'experiments', 'show', 'that', 'is', 'more', 'accurate', 'and', 'has', 'lower', 'variance', 'than', 'see', 'figure', 'however', 'the', 'statistic', 'estimator', 'needs', 'memory', 'rather', 'than', 'for', 'this', 'reason', 'and', 'to', 'get', 'new', 'samschlkopf', 'et', 'al', 'propose', 'to', 'use', 'reduced', 'set', 'method', 'both', 'on', 'ples', 'xi', 'wi', 'and', 'yj', 'uj', 'of', 'size', 'and', 'then', 'estimate', 'xy', 'using', 'pn', 'ij', 'wi', 'uj', 'kx', 'xi', 'yj', 'we', 'ran', 'experiments', 'on', 'synthetic', 'data', 'to', 'show', 'how', 'accurately', 'and', 'approximate', 'xy', 'with', 'growing', 'sample', 'size', 'we', 'considered', 'three', 'basic', 'arithmetic', 'operations', 'multiplication', 'division', 'and', 'exponentiation', 'with', 'and', 'as', 'the', 'true', 'embedding', 'xy', 'is', 'unknown', 'we', 'approximated', 'it', 'by', 'statistic', 'estimator', 'based', 'on', 'large', 'sample', 'points', 'for', 'we', 'used', 'the', 'simplest', 'possible', 'reduced', 'set', 'method', 'we', 'randomly', 'sampled', 'subsets', 'of', 'size', 'of', 'the', 'xi', 'and', 'optimized', 'the', 'weights', 'wi', 'and', 'ui', 'to', 'best', 'approximate', 'and', 'the', 'results', 'are', 'summarised', 'in', 'figure', 'and', 'corroborate', 'our', 'expectations', 'all', 'estimators', 'converge', 'ii', 'converges', 'fastest', 'and', 'has', 'the', 'lowest', 'variance', 'and', 'iii', 'is', 'worse', 'than', 'but', 'much', 'better', 'than', 'the', 'diagonal', 'estimator', 'note', 'moreover', 'that', 'unlike', 'the', 'statistic', 'estimator', 'the', 'reduced', 'set', 'based', 'estimator', 'can', 'be', 'used', 'with', 'fixed', 'storage', 'budget', 'even', 'if', 'we', 'perform', 'sequence', 'of', 'function', 'applicationsa', 'situation', 'naturally', 'appearing', 'in', 'the', 'context', 'of', 'probabilistic', 'programming', 'schlkopf', 'et', 'al', 'prove', 'the', 'consistency', 'of', 'only', 'for', 'rather', 'limited', 'case', 'when', 'the', 'points', 'of', 'the', 'reduced', 'expansions', 'xi', 'ni', 'and', 'yi', 'ni', 'are', 'iid', 'copies', 'of', 'and', 'respectively', 'and', 'the', 'weights', 'wi', 'ui', 'ni', 'are', 'constants', 'using', 'our', 'new', 'results', 'we', 'will', 'prove', 'in', 'section', 'the', 'consistency', 'of', 'under', 'fairly', 'general', 'conditions', 'even', 'in', 'the', 'case', 'when', 'both', 'expansion', 'points', 'and', 'weights', 'are', 'interdependent', 'random', 'variables', 'figure', 'error', 'of', 'kernel', 'mean', 'estimators', 'for', 'basic', 'arithmetic', 'functions', 'of', 'two', 'variables', 'and', 'as', 'function', 'of', 'sample', 'size', 'the', 'statistic', 'estimator', 'works', 'best', 'closely', 'followed', 'by', 'the', 'proposed', 'estimator', 'which', 'outperforms', 'the', 'diagonal', 'estimator', 'other', 'sources', 'of', 'non', 'iid', 'samples', 'although', 'our', 'discussion', 'above', 'focuses', 'on', 'reduced', 'expansion', 'set', 'methods', 'there', 'are', 'other', 'popular', 'algorithms', 'that', 'produce', 'kme', 'expansions', 'where', 'the', 'samples', 'are', 'not', 'iid', 'here', 'we', 'briefly', 'discuss', 'several', 'examples', 'emphasising', 'that', 'our', 'selection', 'is', 'not', 'comprehensive', 'they', 'provide', 'additional', 'motivation', 'for', 'stating', 'convergence', 'guarantees', 'in', 'the', 'most', 'general', 'setting', 'possible', 'an', 'important', 'notion', 'in', 'probability', 'theory', 'is', 'that', 'of', 'conditional', 'distribution', 'which', 'can', 'also', 'be', 'represented', 'using', 'kme', 'song', 'et', 'al', 'with', 'this', 'representation', 'the', 'standard', 'laws', 'of', 'probability', 'such', 'as', 'sum', 'product', 'and', 'bayes', 'rules', 'can', 'be', 'stated', 'using', 'kme', 'fukumizu', 'et', 'al', 'applying', 'those', 'rules', 'results', 'in', 'kme', 'estimators', 'with', 'strong', 'dependencies', 'between', 'samples', 'and', 'their', 'weights', 'another', 'possibility', 'is', 'that', 'even', 'though', 'iid', 'samples', 'are', 'available', 'they', 'may', 'not', 'produce', 'the', 'best', 'estimator', 'various', 'approaches', 'such', 'as', 'kernel', 'herding', 'chen', 'et', 'al', 'lacoste', 'julien', 'et', 'al', 'attempt', 'to', 'produce', 'better', 'kme', 'estimator', 'by', 'actively', 'generating', 'pseudo', 'samples', 'that', 'are', 'not', 'iid', 'from', 'the', 'underlying', 'distribution', 'main', 'results', 'this', 'section', 'contains', 'our', 'main', 'results', 'regarding', 'consistency', 'and', 'finite', 'sample', 'guarantees', 'for', 'the', 'estimator', 'defined', 'in', 'they', 'are', 'based', 'on', 'the', 'convergence', 'of', 'and', 'avoid', 'simplifying', 'assumptions', 'about', 'its', 'structure', 'consistency', 'if', 'kx', 'is', 'universal', 'see', 'sriperumbudur', 'et', 'al', 'consistency', 'of', 'can', 'be', 'shown', 'in', 'rather', 'general', 'setting', 'theorem', 'let', 'and', 'be', 'compact', 'hausdorff', 'spaces', 'equipped', 'with', 'their', 'borel', 'algebras', 'continuous', 'function', 'kx', 'kz', 'continuous', 'kernels', 'on', 'respectively', 'assume', 'kx', 'is', 'universal', 'and', 'that', 'there', 'exists', 'such', 'that', 'wi', 'independently', 'of', 'the', 'following', 'holds', 'if', 'kxx', 'kxx', 'kf', 'kf', 'then', 'as', 'pn', 'proof', 'let', 'be', 'the', 'distribution', 'of', 'and', 'pn', 'wi', 'xi', 'define', 'new', 'kernel', 'on', 'by', 'kx', 'kz', 'is', 'compact', 'and', 'pn', 'is', 'bounded', 'set', 'in', 'pn', 'total', 'variation', 'norm', 'of', 'finite', 'measures', 'because', 'kpn', 'kt', 'wi', 'furthermore', 'kx', 'is', 'continuous', 'and', 'universal', 'using', 'corollary', 'of', 'simon', 'gabriel', 'and', 'schlkopf', 'we', 'conclude', 'that', 'kxx', 'kxx', 'implies', 'that', 'converges', 'weakly', 'to', 'now', 'kz', 'and', 'being', 'continuous', 'so', 'is', 'kx', 'thus', 'if', 'converges', 'weakly', 'to', 'then', 'kx', 'kx', 'simon', 'gabriel', 'and', 'schlkopf', 'kxx', 'kxx', 'theorem', 'points', 'and', 'iii', 'overall', 'implies', 'kxx', 'kxx', 'we', 'conclude', 'the', 'proof', 'by', 'showing', 'that', 'convergence', 'in', 'hekx', 'leads', 'to', 'convergence', 'in', 'hkz', 'kf', 'kf', 'kz', 'kxx', 'for', 'detailed', 'version', 'of', 'the', 'above', 'see', 'appendix', 'kxx', 'kx', 'the', 'continuity', 'assumption', 'is', 'rather', 'unrestrictive', 'all', 'kernels', 'and', 'functions', 'defined', 'on', 'discrete', 'space', 'are', 'continuous', 'with', 'respect', 'to', 'the', 'discrete', 'topology', 'so', 'the', 'theorem', 'applies', 'in', 'this', 'case', 'for', 'rd', 'many', 'kernels', 'used', 'in', 'practice', 'are', 'continuous', 'including', 'gaussian', 'laplacian', 'matrn', 'and', 'other', 'radial', 'kernels', 'the', 'slightly', 'limiting', 'factor', 'of', 'this', 'theorem', 'is', 'that', 'kx', 'must', 'be', 'universal', 'which', 'often', 'can', 'be', 'tricky', 'to', 'verify', 'however', 'most', 'standard', 'all', 'radial', 'non', 'constant', 'kernelsare', 'universal', 'see', 'sriperumbudur', 'et', 'al', 'the', 'assumption', 'that', 'the', 'input', 'domain', 'is', 'compact', 'is', 'satisfied', 'in', 'most', 'applications', 'since', 'any', 'measurements', 'coming', 'from', 'physical', 'sensors', 'are', 'contained', 'in', 'bounded', 'range', 'finally', 'the', 'assumption', 'that', 'wi', 'can', 'be', 'enforced', 'for', 'instance', 'by', 'applying', 'suitable', 'regularization', 'in', 'reduced', 'set', 'methods', 'finite', 'sample', 'guarantees', 'theorem', 'guarantees', 'that', 'the', 'estimator', 'converges', 'to', 'when', 'converges', 'to', 'however', 'it', 'says', 'nothing', 'about', 'the', 'speed', 'of', 'convergence', 'in', 'this', 'section', 'we', 'provide', 'convergence', 'rate', 'when', 'working', 'with', 'matrn', 'kernels', 'which', 'are', 'of', 'the', 'form', 'kxs', 'kx', 'bd', 'kx', 'where', 'is', 'modified', 'bessel', 'function', 'of', 'the', 'third', 'kind', 'also', 'known', 'as', 'macdonald', 'function', 'of', 'order', 'is', 'the', 'gamma', 'function', 'and', 'is', 'smoothness', 'parameter', 'the', 'rkhs', 'induced', 'by', 'kxs', 'is', 'the', 'sobolev', 'space', 'rd', 'wendland', 'theorem', 'containing', 'times', 'differentiable', 'functions', 'the', 'finite', 'sample', 'bound', 'of', 'theorem', 'is', 'based', 'on', 'the', 'analysis', 'of', 'kanagawa', 'et', 'al', 'which', 'requires', 'the', 'following', 'assumptions', 'assumptions', 'let', 'be', 'random', 'variable', 'over', 'rd', 'with', 'distribution', 'and', 'let', 'xi', 'wi', 'ni', 'be', 'random', 'variables', 'over', 'rn', 'with', 'joint', 'distribution', 'there', 'exists', 'probability', 'distribution', 'with', 'full', 'support', 'on', 'rd', 'and', 'bounded', 'density', 'satisfying', 'the', 'following', 'properties', 'has', 'bounded', 'density', 'function', 'wrt', 'ii', 'there', 'is', 'constant', 'independent', 'of', 'such', 'that', 'xi', 'these', 'assumptions', 'were', 'shown', 'to', 'be', 'fairly', 'general', 'and', 'we', 'refer', 'to', 'kanagawa', 'et', 'al', 'section', 'for', 'various', 'examples', 'where', 'they', 'are', 'met', 'next', 'we', 'state', 'the', 'main', 'result', 'of', 'this', 'section', 'theorem', 'let', 'rd', 'rd', 'and', 'be', 'an', 'times', 'differentiable', 'function', 'take', 'and', 'such', 'that', 'let', 'and', 'be', 'matrn', 'kernels', 'over', 'and', 'xi', 'wi', 'satisfy', 'moreover', 'respectively', 'as', 'defined', 'in', 'assume', 'and', 'assume', 'that', 'and', 'the', 'marginals', 'of', 'xn', 'have', 'common', 'compact', 'support', 'suppose', 'that', 'for', 'some', 'constants', 'and', 'es', 'pn', 'ii', 'with', 'probability', 'wi', 'let', 'min', 'and', 'assume', 'then', 'log', 'kz', 'before', 'we', 'provide', 'short', 'sketch', 'of', 'the', 'proof', 'let', 'us', 'briefly', 'comment', 'on', 'this', 'result', 'as', 'benchmark', 'xi', 'we', 'get', 'remember', 'that', 'when', 'xn', 'are', 'iid', 'observations', 'from', 'and', 'op', 'which', 'was', 'recently', 'shown', 'to', 'be', 'minimax', 'optimal', 'rate', 'tolstikhin', 'et', 'al', 'how', 'do', 'we', 'compare', 'to', 'this', 'benchmark', 'in', 'this', 'case', 'we', 'have', 'and', 'our', 'rate', 'is', 'defined', 'by', 'if', 'is', 'smooth', 'enough', 'say', 'and', 'by', 'setting', 'we', 'recover', 'the', 'rate', 'up', 'to', 'an', 'extra', 'log', 'factor', 'however', 'theorem', 'applies', 'to', 'much', 'more', 'general', 'settings', 'importantly', 'it', 'makes', 'no', 'iid', 'assumptions', 'on', 'the', 'data', 'points', 'and', 'weights', 'allowing', 'for', 'complex', 'instead', 'it', 'asks', 'the', 'convergence', 'of', 'the', 'estimator', 'to', 'the', 'embedding', 'to', 'be', 'sufficiently', 'fast', 'on', 'the', 'downside', 'the', 'upper', 'bound', 'is', 'affected', 'by', 'the', 'smoothness', 'of', 'even', 'in', 'the', 'iid', 'setting', 'if', 'the', 'rate', 'will', 'become', 'slower', 'as', 'also', 'the', 'rate', 'depends', 'both', 'on', 'and', 'whether', 'these', 'are', 'artefacts', 'of', 'our', 'proof', 'remains', 'an', 'open', 'question', 'proof', 'here', 'we', 'sketch', 'the', 'main', 'ideas', 'of', 'the', 'proof', 'and', 'develop', 'the', 'details', 'in', 'appendix', 'throughout', 'the', 'proof', 'will', 'designate', 'constant', 'that', 'depends', 'neither', 'on', 'the', 'sample', 'size', 'nor', 'on', 'the', 'variable', 'to', 'be', 'introduced', 'may', 'however', 'change', 'from', 'line', 'to', 'line', 'we', 'start', 'by', 'showing', 'that', 'kz', 'kz', 'hf', 'hf', 'dz', 'kz', 'where', 'is', 'matrn', 'kernel', 'over', 'with', 'smoothness', 'parameter', 'second', 'we', 'upper', 'bound', 'the', 'integrand', 'by', 'roughly', 'imitating', 'the', 'proof', 'idea', 'of', 'theorem', 'from', 'kanagawa', 'et', 'al', 'this', 'eventually', 'yields', 'hf', 'hf', 'cn', 'where', 'unfortunately', 'this', 'upper', 'bound', 'does', 'not', 'depend', 'on', 'and', 'can', 'not', 'be', 'integrated', 'over', 'the', 'whole', 'in', 'denoting', 'br', 'the', 'ball', 'of', 'radius', 'centred', 'on', 'the', 'origin', 'of', 'we', 'thus', 'decompose', 'the', 'integral', 'in', 'as', 'hf', 'hf', 'dz', 'dz', 'hf', 'hf', 'dz', 'br', 'br', 'on', 'br', 'we', 'upper', 'bound', 'the', 'integral', 'by', 'times', 'the', 'balls', 'volume', 'which', 'grows', 'like', 'rd', 'hf', 'hf', 'dz', 'crd', 'br', 'on', 'br', 'we', 'upper', 'bound', 'the', 'integral', 'by', 'value', 'that', 'decreases', 'with', 'which', 'is', 'of', 'the', 'form', 'hf', 'hf', 'dz', 'br', 'with', 'being', 'constant', 'smaller', 'than', 'in', 'essence', 'this', 'upper', 'bound', 'decreases', 'with', 'because', 'hf', 'hf', 'decays', 'with', 'the', 'same', 'speed', 'as', 'when', 'kzk', 'grows', 'indefinitely', 'we', 'are', 'now', 'left', 'with', 'two', 'rates', 'and', 'which', 'respectively', 'increase', 'and', 'decrease', 'with', 'growing', 'we', 'complete', 'the', 'proof', 'by', 'balancing', 'these', 'two', 'terms', 'which', 'results', 'in', 'setting', 'log', 'functions', 'of', 'multiple', 'arguments', 'the', 'previous', 'section', 'applies', 'to', 'functions', 'of', 'one', 'single', 'variable', 'however', 'we', 'can', 'apply', 'its', 'results', 'to', 'functions', 'of', 'multiple', 'variables', 'if', 'we', 'take', 'the', 'argument', 'to', 'be', 'tuple', 'containing', 'multiple', 'values', 'in', 'this', 'section', 'we', 'discuss', 'how', 'to', 'do', 'it', 'using', 'two', 'input', 'variables', 'from', 'spaces', 'and', 'but', 'the', 'results', 'also', 'apply', 'to', 'more', 'inputs', 'to', 'be', 'precise', 'our', 'input', 'space', 'changes', 'from', 'to', 'input', 'random', 'variable', 'from', 'to', 'and', 'the', 'kernel', 'on', 'the', 'input', 'space', 'from', 'kx', 'to', 'kxy', 'to', 'apply', 'our', 'results', 'from', 'section', 'all', 'we', 'need', 'is', 'consistent', 'estimator', 'xy', 'of', 'the', 'joint', 'embedding', 'xy', 'there', 'are', 'different', 'ways', 'to', 'get', 'such', 'an', 'estimator', 'one', 'way', 'is', 'to', 'sample', 'iid', 'from', 'the', 'joint', 'distribution', 'of', 'and', 'construct', 'the', 'usual', 'empirical', 'estimator', 'or', 'approximate', 'it', 'using', 'reduced', 'set', 'methods', 'alternatively', 'we', 'may', 'want', 'to', 'construct', 'xy', 'based', 'only', 'on', 'consistent', 'estimators', 'of', 'and', 'for', 'example', 'this', 'is', 'how', 'was', 'defined', 'in', 'section', 'below', 'we', 'show', 'that', 'this', 'can', 'indeed', 'be', 'done', 'if', 'and', 'are', 'independent', 'application', 'to', 'section', 'following', 'schlkopf', 'et', 'al', 'we', 'consider', 'two', 'independent', 'random', 'variables', 'px', 'and', 'py', 'their', 'joint', 'distribution', 'is', 'px', 'py', 'pconsistent', 'estimators', 'of', 'their', 'embeddings', 'are', 'given', 'by', 'wi', 'kx', 'xi', 'and', 'uj', 'ky', 'yi', 'in', 'this', 'section', 'we', 'show', 'that', 'pn', 'xy', 'ij', 'wi', 'uj', 'kz', 'xi', 'yj', 'is', 'consistent', 'estimator', 'of', 'xy', 'we', 'choose', 'product', 'kernel', 'kxy', 'kx', 'ky', 'so', 'the', 'corresponding', 'rkhs', 'is', 'tensor', 'product', 'hkxy', 'hkx', 'hky', 'steinwart', 'and', 'christmann', 'lemma', 'and', 'the', 'mean', 'embedding', 'of', 'the', 'product', 'random', 'variable', 'is', 'tensor', 'product', 'of', 'their', 'marginal', 'mean', 'embeddings', 'xy', 'with', 'consistent', 'estimators', 'for', 'the', 'marginal', 'embeddings', 'we', 'can', 'estimate', 'the', 'joint', 'embedding', 'using', 'their', 'tensor', 'product', 'xy', 'ij', 'wi', 'uj', 'kx', 'xi', 'ky', 'yj', 'wi', 'uj', 'kxy', 'xi', 'yj', 'ij', 'if', 'points', 'are', 'iid', 'and', 'wi', 'ui', 'this', 'reduces', 'to', 'the', 'statistic', 'estimator', 'from', 'section', 'lemma', 'let', 'sn', 'be', 'any', 'positive', 'real', 'sequence', 'converging', 'to', 'zero', 'suppose', 'kxy', 'kx', 'ky', 'is', 'product', 'kernel', 'xy', 'and', 'xy', 'then', 'kkx', 'sn', 'implies', 'xy', 'xy', 'sn', 'kky', 'sn', 'kxy', 'proof', 'for', 'detailed', 'expansion', 'of', 'the', 'first', 'inequality', 'see', 'appendix', 'xy', 'xy', 'corollary', 'if', 'kxy', 'kx', 'kkx', 'kkx', 'and', 'kky', 'ky', 'kky', 'kkx', 'kky', 'sn', 'sn', 'sn', 'then', 'xy', 'xy', 'together', 'with', 'the', 'results', 'from', 'section', 'this', 'lets', 'us', 'reason', 'about', 'estimators', 'resulting', 'from', 'applying', 'functions', 'to', 'multiple', 'independent', 'random', 'variables', 'write', 'kxy', 'xy', 'wi', 'uj', 'kxy', 'xi', 'yj', 'ij', 'kxy', 'where', 'enumerates', 'the', 'pairs', 'and', 'xi', 'yj', 'wi', 'uj', 'now', 'if', 'kxx', 'kxx', 'ky', 'ky', 'kxy', 'kxy', 'and', 'then', 'xy', 'xy', 'according', 'to', 'corollary', 'and', 'theorem', 'shows', 'that', 'pn', 'is', 'consistent', 'as', 'well', 'unfortunately', 'we', 'cannot', 'apply', 'theorem', 'to', 'get', 'ij', 'the', 'speed', 'of', 'convergence', 'because', 'product', 'of', 'matrn', 'kernels', 'is', 'not', 'matrn', 'kernel', 'any', 'more', 'one', 'downside', 'of', 'this', 'overall', 'approach', 'is', 'that', 'the', 'number', 'of', 'expansion', 'points', 'used', 'for', 'the', 'estimation', 'of', 'the', 'joint', 'increases', 'exponentially', 'with', 'the', 'number', 'of', 'arguments', 'of', 'this', 'can', 'lead', 'to', 'prohibitively', 'large', 'computational', 'costs', 'especially', 'if', 'the', 'result', 'of', 'such', 'an', 'operation', 'is', 'used', 'as', 'an', 'input', 'to', 'another', 'function', 'of', 'multiple', 'arguments', 'to', 'alleviate', 'this', 'problem', 'we', 'may', 'use', 'reduced', 'expansion', 'set', 'methods', 'before', 'or', 'after', 'applying', 'as', 'we', 'did', 'for', 'example', 'in', 'section', 'to', 'conclude', 'this', 'section', 'let', 'us', 'summarize', 'the', 'implications', 'of', 'our', 'results', 'for', 'two', 'practical', 'scenarios', 'that', 'should', 'be', 'distinguished', 'if', 'we', 'have', 'separate', 'samples', 'from', 'two', 'random', 'variables', 'and', 'then', 'our', 'results', 'justify', 'how', 'to', 'provide', 'an', 'estimate', 'of', 'the', 'mean', 'embedding', 'of', 'provided', 'that', 'and', 'are', 'independent', 'the', 'samples', 'themselves', 'need', 'not', 'be', 'iid', 'we', 'can', 'also', 'work', 'with', 'weighted', 'samples', 'computed', 'for', 'instance', 'by', 'reduced', 'set', 'method', 'how', 'about', 'dependent', 'random', 'variables', 'for', 'instance', 'imagine', 'that', 'and', 'clearly', 'in', 'this', 'case', 'the', 'distribution', 'of', 'is', 'delta', 'measure', 'on', 'and', 'there', 'is', 'no', 'way', 'to', 'predict', 'this', 'from', 'separate', 'samples', 'of', 'and', 'however', 'it', 'should', 'be', 'stressed', 'that', 'our', 'results', 'consistency', 'and', 'finite', 'sample', 'bound', 'apply', 'even', 'to', 'the', 'case', 'where', 'and', 'are', 'dependent', 'in', 'that', 'case', 'however', 'they', 'require', 'consistent', 'estimator', 'of', 'the', 'joint', 'embedding', 'xy', 'it', 'is', 'also', 'sufficient', 'to', 'have', 'reduced', 'set', 'expansion', 'of', 'the', 'embedding', 'of', 'the', 'joint', 'distribution', 'this', 'setting', 'may', 'sound', 'strange', 'but', 'it', 'potentially', 'has', 'significant', 'applications', 'imagine', 'that', 'one', 'has', 'large', 'database', 'of', 'user', 'data', 'sampled', 'from', 'joint', 'distribution', 'if', 'we', 'expand', 'the', 'joints', 'embedding', 'in', 'terms', 'of', 'synthetic', 'expansion', 'points', 'using', 'reduced', 'set', 'construction', 'method', 'then', 'we', 'can', 'pass', 'on', 'these', 'weighted', 'synthetic', 'expansion', 'points', 'to', 'third', 'party', 'without', 'revealing', 'the', 'original', 'data', 'using', 'our', 'results', 'the', 'third', 'party', 'can', 'nevertheless', 'perform', 'arbitrary', 'continuous', 'functional', 'operations', 'on', 'the', 'joint', 'distribution', 'in', 'consistent', 'manner', 'conclusion', 'and', 'future', 'work', 'this', 'paper', 'provides', 'theoretical', 'foundation', 'for', 'using', 'kernel', 'mean', 'embeddings', 'as', 'approximate', 'representations', 'of', 'random', 'variables', 'in', 'scenarios', 'where', 'we', 'need', 'to', 'apply', 'functions', 'to', 'those', 'random', 'variables', 'we', 'show', 'that', 'for', 'continuous', 'functions', 'including', 'all', 'functions', 'on', 'discrete', 'domains', 'consistency', 'of', 'the', 'mean', 'embedding', 'estimator', 'of', 'random', 'variable', 'implies', 'consistency', 'of', 'the', 'mean', 'embedding', 'estimator', 'of', 'furthermore', 'if', 'the', 'kernels', 'are', 'matrn', 'and', 'the', 'function', 'is', 'sufficiently', 'smooth', 'we', 'provide', 'bounds', 'on', 'the', 'convergence', 'rate', 'importantly', 'our', 'results', 'apply', 'beyond', 'iid', 'samples', 'and', 'cover', 'estimators', 'based', 'on', 'expansions', 'with', 'interdependent', 'points', 'and', 'weights', 'one', 'interesting', 'future', 'direction', 'is', 'to', 'improve', 'the', 'finite', 'sample', 'bounds', 'and', 'extend', 'them', 'to', 'general', 'radial', 'and', 'or', 'translation', 'invariant', 'kernels', 'our', 'work', 'is', 'motivated', 'by', 'the', 'field', 'of', 'probabilistic', 'programming', 'using', 'our', 'theoretical', 'results', 'kernel', 'mean', 'embeddings', 'can', 'be', 'used', 'to', 'generalize', 'functional', 'operations', 'which', 'lie', 'at', 'the', 'core', 'of', 'all', 'programming', 'languages', 'to', 'distributions', 'over', 'data', 'types', 'in', 'principled', 'manner', 'by', 'applying', 'the', 'operations', 'to', 'the', 'points', 'or', 'approximate', 'kernel', 'expansions', 'this', 'is', 'in', 'principle', 'feasible', 'for', 'any', 'data', 'type', 'provided', 'suitable', 'kernel', 'function', 'can', 'be', 'defined', 'on', 'it', 'we', 'believe', 'that', 'the', 'approach', 'holds', 'significant', 'potential', 'for', 'future', 'probabilistic', 'programming', 'systems', 'we', 'thank', 'krikamol', 'muandet', 'for', 'providing', 'the', 'code', 'used', 'to', 'generate', 'figure', 'paul', 'rubenstein', 'motonobu', 'kanagawa', 'and', 'bharath', 'sriperumbudur', 'for', 'very', 'useful', 'discussions', 'and', 'our', 'anonymous', 'reviewers', 'for', 'their', 'valuable', 'feedback', 'carl', 'johann', 'simon', 'gabriel', 'is', 'supported', 'by', 'google', 'european', 'fellowship', 'in', 'causal', 'inference', 'references', 'adams', 'and', 'fournier', 'sobolev', 'spaces', 'academic', 'press', 'bennett', 'and', 'sharpley', 'interpolation', 'of', 'operators', 'pure', 'and', 'applied', 'mathematics', 'elsevier', 'science', 'berlinet', 'and', 'thomas', 'agnan', 'rkhs', 'in', 'probability', 'and', 'statistics', 'springer', 'chen', 'welling', 'and', 'smola', 'super', 'samples', 'from', 'kernel', 'herding', 'in', 'uai', 'fukumizu', 'song', 'and', 'gretton', 'kernel', 'bayes', 'rule', 'bayesian', 'inference', 'with', 'positive', 'definite', 'kernels', 'journal', 'of', 'machine', 'learning', 'research', 'gradshteyn', 'and', 'ryzhik', 'table', 'of', 'integrals', 'series', 'and', 'products', 'elsevier', 'academic', 'press', 'amsterdam', 'edited', 'by', 'alan', 'jeffrey', 'and', 'daniel', 'zwillinger', 'kalos', 'and', 'whitlock', 'monte', 'carlo', 'methods', 'wiley', 'kanagawa', 'sriperumbudur', 'and', 'fukumizu', 'convergence', 'guarantees', 'for', 'kernel', 'based', 'quadrature', 'rules', 'in', 'misspecified', 'settings', 'arxiv', 'stat', 'arxiv', 'katznelson', 'an', 'introduction', 'to', 'harmonic', 'analysis', 'cambridge', 'university', 'press', 'korzen', 'and', 'jaroszewicz', 'pacal', 'python', 'package', 'for', 'arithmetic', 'computations', 'with', 'random', 'variables', 'journal', 'of', 'statistical', 'software', 'lacoste', 'julien', 'lindsten', 'and', 'bach', 'sequential', 'kernel', 'herding', 'frank', 'wolfe', 'optimization', 'for', 'particle', 'filtering', 'in', 'artificial', 'intelligence', 'and', 'statistics', 'volume', 'pages', 'mathai', 'review', 'of', 'the', 'different', 'techniques', 'used', 'for', 'deriving', 'the', 'exact', 'distributions', 'of', 'multivariate', 'test', 'criteria', 'sankhya', 'the', 'indian', 'journal', 'of', 'statistics', 'series', 'pages', 'mckinley', 'programming', 'the', 'world', 'of', 'uncertain', 'things', 'keynote', 'in', 'acm', 'sigplan', 'sigact', 'symposium', 'on', 'principles', 'of', 'programming', 'languages', 'pages', 'milios', 'probability', 'distributions', 'as', 'program', 'variables', 'phd', 'thesis', 'university', 'of', 'edinburgh', 'poisson', 'recherches', 'sur', 'la', 'probabilitdes', 'jugements', 'en', 'matire', 'criminelle', 'et', 'en', 'matire', 'civile', 'prcdes', 'des', 'rgles', 'gnrales', 'du', 'calcul', 'des', 'probabilits', 'schlkopf', 'and', 'smola', 'learning', 'with', 'kernels', 'support', 'vector', 'machines', 'regularization', 'optimization', 'and', 'beyond', 'mit', 'press', 'schlkopf', 'muandet', 'fukumizu', 'harmeling', 'and', 'peters', 'computing', 'functions', 'of', 'random', 'variables', 'via', 'reproducing', 'kernel', 'hilbert', 'space', 'representations', 'statistics', 'and', 'computing', 'scovel', 'hush', 'steinwart', 'and', 'theiler', 'radial', 'kernels', 'and', 'their', 'reproducing', 'kernel', 'hilbert', 'spaces', 'journal', 'of', 'complexity', 'simon', 'gabriel', 'and', 'schlkopf', 'kernel', 'distribution', 'embeddings', 'universal', 'kernels', 'characteristic', 'kernels', 'and', 'kernel', 'metrics', 'on', 'distributions', 'technical', 'report', 'max', 'planck', 'institute', 'for', 'intelligent', 'systems', 'smola', 'gretton', 'song', 'and', 'schlkopf', 'hilbert', 'space', 'embedding', 'for', 'distributions', 'in', 'alt', 'song', 'huang', 'smola', 'and', 'fukumizu', 'hilbert', 'space', 'embeddings', 'of', 'conditional', 'distributions', 'with', 'applications', 'to', 'dynamical', 'systems', 'in', 'international', 'conference', 'on', 'machine', 'learning', 'pages', 'springer', 'the', 'algebra', 'of', 'random', 'variables', 'wiley', 'sriperumbudur', 'gretton', 'fukumizu', 'schlkopf', 'and', 'lanckriet', 'hilbert', 'space', 'embeddings', 'and', 'metrics', 'on', 'probability', 'measures', 'journal', 'of', 'machine', 'learning', 'research', 'sriperumbudur', 'fukumizu', 'and', 'lanckriet', 'universality', 'characteristic', 'kernels', 'and', 'rkhs', 'embedding', 'of', 'measures', 'journal', 'of', 'machine', 'learning', 'research', 'steinwart', 'and', 'christmann', 'support', 'vector', 'machines', 'information', 'science', 'and', 'statistics', 'springer', 'steinwart', 'and', 'scovel', 'mercers', 'theorem', 'on', 'general', 'domains', 'on', 'the', 'interaction', 'between', 'measures', 'kernels', 'and', 'rkhss', 'constructive', 'approximation', 'tolstikhin', 'sriperumbudur', 'and', 'muandet', 'arxiv', 'math', 'stat', 'minimax', 'estimation', 'of', 'kernel', 'mean', 'embeddings', 'wendland', 'scattered', 'data', 'approximation', 'cambridge', 'university', 'press', 'williamson', 'probabilistic', 'arithmetic', 'phd', 'thesis', 'university', 'of', 'queensland']\n"]}]},{"cell_type":"code","source":["clean_words = remove_all_stop_words(text_as_words)"],"metadata":{"id":"D8bQYoaNxqwh","executionInfo":{"status":"ok","timestamp":1751185346594,"user_tz":-330,"elapsed":4303,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["len(clean_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJ1nSWXxx72Q","executionInfo":{"status":"ok","timestamp":1751185355856,"user_tz":-330,"elapsed":36,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"bfe74926-f14b-4ee1-d21b-cc75184cc2ee"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["len(clean_words[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B7CMmhDhx_Jw","executionInfo":{"status":"ok","timestamp":1751185369506,"user_tz":-330,"elapsed":51,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"cfef14f4-c6f1-45c2-a48b-c706f82973da"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2782"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["print(clean_words[:1][0][:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bl_1fex2yCfZ","executionInfo":{"status":"ok","timestamp":1751185378199,"user_tz":-330,"elapsed":56,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"38fe5791-69f8-4e4b-c97f-ed350e0c16c1"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["['consistent', 'kernel', 'mean', 'estimation', 'functions', 'random', 'variables', 'carl', 'johann', 'simon', 'gabriel', 'adam', 'scibior', 'ilya', 'tolstikhin', 'bernhard', 'schlkopf', 'department', 'empirical', 'inference']\n"]}]},{"cell_type":"code","source":["bigram = gensim.models.Phrases(clean_words, min_count=5, threshold=100)\n","trigram = gensim.models.Phrases(bigram[clean_words], threshold=100)"],"metadata":{"id":"fvF8KHf3yEnI","executionInfo":{"status":"ok","timestamp":1751186996778,"user_tz":-330,"elapsed":4240,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["bigram_mod = gensim.models.phrases.Phraser(bigram)\n","trigram_mod = gensim.models.phrases.Phraser(trigram)"],"metadata":{"id":"OfE0hz_r4OwD","executionInfo":{"status":"ok","timestamp":1751187025694,"user_tz":-330,"elapsed":1456,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["def make_bigrams(texts):\n","    return [bigram_mod[doc] for doc in texts]\n","\n","def make_trigrams(texts):\n","    return [trigram_mod[bigram_mod[doc]] for doc in texts]"],"metadata":{"id":"oFWmuhGj4WfD","executionInfo":{"status":"ok","timestamp":1751187039680,"user_tz":-330,"elapsed":22,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n","    \"\"\"https://spacy.io/api/annotation\"\"\"\n","    texts_out = []\n","    for sent in texts:\n","        doc = nlp(\" \".join(sent))\n","        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n","    return texts_out"],"metadata":{"id":"6swGzu-24aQb","executionInfo":{"status":"ok","timestamp":1751187073330,"user_tz":-330,"elapsed":41,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])"],"metadata":{"id":"lf-re13q4id3","executionInfo":{"status":"ok","timestamp":1751187095822,"user_tz":-330,"elapsed":12020,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["clean_words_bigrams = make_bigrams(clean_words)"],"metadata":{"id":"lcIWbqV_4lCI","executionInfo":{"status":"ok","timestamp":1751187458485,"user_tz":-330,"elapsed":455,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["clean_words_lemmatized = lemmatization(clean_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"],"metadata":{"id":"84mfobuJ6AZb","executionInfo":{"status":"ok","timestamp":1751189151422,"user_tz":-330,"elapsed":21100,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["print(clean_words_lemmatized[:1][0][:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2CearaQAYqb","executionInfo":{"status":"ok","timestamp":1751189166463,"user_tz":-330,"elapsed":58,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"c5d0b793-f23f-49fc-b112-f276e579b943"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["['consistent', 'kernel', 'mean', 'estimation', 'function', 'random', 'variable', 'ilya', 'department', 'empirical', 'inference', 'institute', 'intelligent', 'system', 'joint', 'first', 'author', 'also', 'engineer', 'ilya', 'abstract', 'provide', 'theoretical', 'foundation', 'function', 'random', 'variable', 'use', 'kernel', 'mean', 'embedding', 'show', 'continuous', 'function', 'consistent', 'estimator', 'mean', 'embed', 'random', 'variable', 'lead', 'consistent', 'estimator', 'mean', 'embed', 'matrn_kernel', 'sufficiently', 'smooth', 'function', 'also', 'provide', 'rate', 'convergence', 'result', 'extend', 'function', 'multiple', 'random', 'variable', 'variable', 'dependent', 'estimator', 'mean', 'embed', 'joint', 'distribution', 'starting', 'point', 'independent', 'sufficient', 'separate', 'estimator', 'mean', 'embedding', 'marginal', 'distribution', 'case', 'result', 'cover', 'mean', 'embedding', 'base', 'iid', 'sample', 'well', 'reduced', 'set', 'expansion', 'term', 'dependent', 'expansion', 'point', 'latter', 'serve', 'justification', 'use', 'expansion', 'limit', 'memory', 'resource']\n"]}]},{"cell_type":"code","source":["print(len(clean_words))\n","print(len(clean_words[0]))\n","print(len(clean_words[99]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wg3elxauAheb","executionInfo":{"status":"ok","timestamp":1751189193374,"user_tz":-330,"elapsed":21,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"ebb83788-d4c8-45c1-ba90-1effe1423565"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n","2782\n","3614\n"]}]},{"cell_type":"code","source":["print(len(clean_words_lemmatized))\n","print(len(clean_words_lemmatized[0]))\n","print(len(clean_words_lemmatized[99]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzzIb-ljAoDT","executionInfo":{"status":"ok","timestamp":1751189206857,"user_tz":-330,"elapsed":87,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"2bdacaf2-0d8f-41bf-f801-7d8d6186b395"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n","2043\n","2693\n"]}]},{"cell_type":"code","source":["import gensim.corpora as corpora"],"metadata":{"id":"ZuNW4DoKArVZ","executionInfo":{"status":"ok","timestamp":1751189296920,"user_tz":-330,"elapsed":41,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["id2word = corpora.Dictionary(clean_words_lemmatized)\n","\n","# note: If you do not lematized the clean words you can still use the clean words as below\n","# id2word = corpora.Dictionary(clean_words)\n","\n","\n","# Creating Corpus for the clean words\n","texts = clean_words_lemmatized\n","#texts = clean_words\n","\n","\n","# Creating The Term Document Frequency\n","corpus = [id2word.doc2bow(text) for text in texts]"],"metadata":{"id":"sCwuARibBBVA","executionInfo":{"status":"ok","timestamp":1751189397564,"user_tz":-330,"elapsed":228,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["print(corpus[:1][0][:100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_RLZBglQBZ2d","executionInfo":{"status":"ok","timestamp":1751189416467,"user_tz":-330,"elapsed":64,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"13580acd-0ef4-43ac-989d-ec5f1c55a1db"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 3), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 13), (16, 1), (17, 3), (18, 1), (19, 4), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 5), (26, 21), (27, 9), (28, 8), (29, 5), (30, 1), (31, 4), (32, 4), (33, 1), (34, 1), (35, 1), (36, 5), (37, 11), (38, 1), (39, 1), (40, 1), (41, 2), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 9), (48, 2), (49, 1), (50, 1), (51, 3), (52, 1), (53, 2), (54, 2), (55, 6), (56, 2), (57, 2), (58, 1), (59, 1), (60, 1), (61, 4), (62, 2), (63, 9), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 2), (70, 1), (71, 6), (72, 1), (73, 3), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 3), (81, 1), (82, 2), (83, 1), (84, 2), (85, 4), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 2), (93, 1), (94, 2), (95, 2), (96, 5), (97, 2), (98, 2), (99, 4)]\n"]}]},{"cell_type":"code","source":["print(len(clean_words_lemmatized))\n","print(len(clean_words_lemmatized[0]))\n","print(len(clean_words_lemmatized[99]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jz54l7mABego","executionInfo":{"status":"ok","timestamp":1751189438807,"user_tz":-330,"elapsed":63,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"ecd2acfa-07d1-46bb-c025-d7a5117016fc"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["100\n","2043\n","2693\n"]}]},{"cell_type":"code","source":["num_topics = 10"],"metadata":{"id":"-h8YoKivBj9C","executionInfo":{"status":"ok","timestamp":1751189832457,"user_tz":-330,"elapsed":38,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# Using Gensin to build the LDA model\n","lda_model = gensim.models.LdaMulticore(corpus=corpus,\n","                                       id2word=id2word,\n","                                       num_topics=num_topics,\n","                                       )\n","\n","# Please perform the modelling by adding the following options also to check your modelling performance\n","# random_state=100,\n","# chunksize=100,\n","# passes=10,\n","# per_word_topics=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsZ5NQFnDEE3","executionInfo":{"status":"ok","timestamp":1751189903146,"user_tz":-330,"elapsed":1497,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"ed4bd15a-e226-4a9d-cf00-f94ff0815b7e"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]}]},{"cell_type":"code","source":["from pprint import pprint\n","pprint(lda_model.print_topics())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JItvltg1DU-T","executionInfo":{"status":"ok","timestamp":1751189984753,"user_tz":-330,"elapsed":54,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"7a7c2b3c-66df-44dc-ebe7-bcb260a0e24e"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["[(0,\n","  '0.009*\"learn\" + 0.008*\"use\" + 0.008*\"model\" + 0.008*\"set\" + '\n","  '0.008*\"function\" + 0.006*\"feature\" + 0.006*\"result\" + 0.005*\"image\" + '\n","  '0.005*\"network\" + 0.004*\"datum\"'),\n"," (1,\n","  '0.010*\"use\" + 0.010*\"function\" + 0.009*\"model\" + 0.007*\"learn\" + '\n","  '0.007*\"show\" + 0.007*\"result\" + 0.006*\"network\" + 0.006*\"datum\" + '\n","  '0.006*\"method\" + 0.006*\"feature\"'),\n"," (2,\n","  '0.012*\"model\" + 0.008*\"use\" + 0.006*\"set\" + 0.006*\"feature\" + '\n","  '0.006*\"function\" + 0.006*\"learn\" + 0.006*\"state\" + 0.006*\"network\" + '\n","  '0.005*\"parameter\" + 0.005*\"method\"'),\n"," (3,\n","  '0.013*\"model\" + 0.008*\"learn\" + 0.008*\"datum\" + 0.007*\"network\" + '\n","  '0.006*\"use\" + 0.006*\"set\" + 0.005*\"function\" + 0.005*\"problem\" + '\n","  '0.005*\"method\" + 0.005*\"result\"'),\n"," (4,\n","  '0.014*\"model\" + 0.008*\"function\" + 0.008*\"use\" + 0.008*\"learn\" + '\n","  '0.006*\"network\" + 0.006*\"state\" + 0.005*\"method\" + 0.005*\"datum\" + '\n","  '0.005*\"result\" + 0.005*\"set\"'),\n"," (5,\n","  '0.011*\"model\" + 0.011*\"use\" + 0.011*\"network\" + 0.006*\"set\" + '\n","  '0.005*\"number\" + 0.005*\"datum\" + 0.005*\"method\" + 0.005*\"learn\" + '\n","  '0.004*\"image\" + 0.004*\"show\"'),\n"," (6,\n","  '0.012*\"use\" + 0.009*\"model\" + 0.008*\"learn\" + 0.007*\"function\" + '\n","  '0.006*\"network\" + 0.006*\"state\" + 0.006*\"show\" + 0.005*\"result\" + '\n","  '0.005*\"datum\" + 0.005*\"feature\"'),\n"," (7,\n","  '0.010*\"model\" + 0.007*\"use\" + 0.007*\"network\" + 0.006*\"result\" + '\n","  '0.005*\"function\" + 0.005*\"set\" + 0.005*\"distribution\" + 0.005*\"state\" + '\n","  '0.005*\"method\" + 0.005*\"show\"'),\n"," (8,\n","  '0.016*\"model\" + 0.008*\"use\" + 0.008*\"learn\" + 0.006*\"function\" + '\n","  '0.006*\"network\" + 0.006*\"set\" + 0.006*\"base\" + 0.005*\"datum\" + '\n","  '0.005*\"value\" + 0.005*\"result\"'),\n"," (9,\n","  '0.013*\"model\" + 0.008*\"learn\" + 0.008*\"datum\" + 0.007*\"use\" + '\n","  '0.007*\"network\" + 0.007*\"set\" + 0.006*\"result\" + 0.005*\"show\" + '\n","  '0.005*\"method\" + 0.005*\"distribution\"')]\n"]}]},{"cell_type":"code","source":["doc_lda = lda_model[corpus]"],"metadata":{"id":"ggmpLPU-DpQH","executionInfo":{"status":"ok","timestamp":1751190098396,"user_tz":-330,"elapsed":49,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["doc_lda\n","# to Save the mode;\n","# doc_lda.save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vpitFR53EFAC","executionInfo":{"status":"ok","timestamp":1751190108743,"user_tz":-330,"elapsed":46,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"20088bac-a60e-4aaf-ff28-ca25884490ec"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<gensim.interfaces.TransformedCorpus at 0x7e3407fae090>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["!pip install pyLDAvis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5dHrAtYjEHhF","executionInfo":{"status":"ok","timestamp":1751190148729,"user_tz":-330,"elapsed":10053,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"bdf1c864-fadb-4db8-9ac7-af6efe650922"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyLDAvis\n","  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.5.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.11.0)\n","Collecting funcy (from pyLDAvis)\n","  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n","Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n","Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n","Installing collected packages: funcy, pyLDAvis\n","Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"]}]},{"cell_type":"code","source":["import pyLDAvis.gensim_models as gensimvis\n","import pickle\n","import pyLDAvis\n","import os"],"metadata":{"id":"b-vF64yOEO1t","executionInfo":{"status":"ok","timestamp":1751190179561,"user_tz":-330,"elapsed":404,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"971bed7d","executionInfo":{"status":"ok","timestamp":1751190372957,"user_tz":-330,"elapsed":37,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"source":["import os\n","\n","# Create the directory if it doesn't exist\n","if not os.path.exists('/content/results'):\n","    os.makedirs('/content/results')"],"execution_count":64,"outputs":[]},{"cell_type":"code","source":["pyLDAvis.enable_notebook()"],"metadata":{"id":"f4LnVOcKFNjP","executionInfo":{"status":"ok","timestamp":1751190415351,"user_tz":-330,"elapsed":56,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["LDAvis_data_filepath = os.path.join('/content/results/ldavis_prepared_'+str(num_topics))"],"metadata":{"id":"-igwlu8MFSYI","executionInfo":{"status":"ok","timestamp":1751190425377,"user_tz":-330,"elapsed":5,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["# # this is a bit time consuming - make the if statement True\n","# # if you want to execute visualization prep yourself\n","if 1 == 1:\n","    LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n","    with open(LDAvis_data_filepath, 'wb') as f:\n","        pickle.dump(LDAvis_prepared, f)"],"metadata":{"id":"nP7u8EYKFU1p","executionInfo":{"status":"ok","timestamp":1751190435451,"user_tz":-330,"elapsed":2127,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["# load the pre-prepared pyLDAvis data from disk\n","with open(LDAvis_data_filepath, 'rb') as f:\n","    LDAvis_prepared = pickle.load(f)\n",""],"metadata":{"id":"f6q0QJYsFWx_","executionInfo":{"status":"ok","timestamp":1751190530003,"user_tz":-330,"elapsed":39,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')"],"metadata":{"id":"7oEsTmyiFuXu","executionInfo":{"status":"ok","timestamp":1751190578580,"user_tz":-330,"elapsed":23,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["LDAvis_prepared"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":882},"id":"LA696idCF6PK","executionInfo":{"status":"ok","timestamp":1751190640578,"user_tz":-330,"elapsed":1210,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"5f6f49f7-6d73-4361-b2a4-966f54b64502"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n","topic                                                \n","1     -0.004314 -0.007623       1        1  20.729963\n","5     -0.006556  0.000839       2        1  18.731958\n","9     -0.002396  0.006124       3        1  12.523423\n","4      0.001703 -0.002062       4        1  11.595724\n","2      0.002424  0.001677       5        1  10.822919\n","7     -0.005428  0.001189       6        1   7.509016\n","0      0.007383 -0.005861       7        1   5.615065\n","3     -0.001454  0.001894       8        1   5.013073\n","8      0.007320  0.005694       9        1   4.102381\n","6      0.001318 -0.001870      10        1   3.356479, topic_info=             Term         Freq        Total Category  logprob  loglift\n","881         model  2185.000000  2185.000000  Default  30.0000  30.0000\n","337         learn  1279.000000  1279.000000  Default  29.0000  29.0000\n","659           use  1693.000000  1693.000000  Default  28.0000  28.0000\n","234      function  1226.000000  1226.000000  Default  27.0000  27.0000\n","592         state   810.000000   810.000000  Default  26.0000  26.0000\n","..            ...          ...          ...      ...      ...      ...\n","554           set    26.069159  1081.325039  Topic10  -5.4967  -0.3309\n","678          well    18.924525   589.878242  Topic10  -5.8170  -0.0452\n","638          time    18.323488   556.676180  Topic10  -5.8493  -0.0195\n","163  distribution    19.224954   774.530873  Topic10  -5.8013  -0.3018\n","297         input    18.350348   606.975373  Topic10  -5.8479  -0.1046\n","\n","[833 rows x 6 columns], token_table=      Topic      Freq      Term\n","term                           \n","5468      2  0.285479  ablation\n","5468      5  0.285479  ablation\n","5468      7  0.285479  ablation\n","1063      1  0.196769   achieve\n","1063      2  0.166826   achieve\n","...     ...       ...       ...\n","2756      8  0.080883        wt\n","2756     10  0.080883        wt\n","6114      1  0.503913       xim\n","6114      2  0.167971       xim\n","6114      7  0.167971       xim\n","\n","[3344 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 6, 10, 5, 3, 8, 1, 4, 9, 7])"],"text/html":["\n","<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n","\n","\n","<div id=\"ldavis_el385511387618547071689949802437\" style=\"background-color:white;\"></div>\n","<script type=\"text/javascript\">\n","\n","var ldavis_el385511387618547071689949802437_data = {\"mdsDat\": {\"x\": [-0.004313906642820855, -0.006556204429226963, -0.0023959164120267743, 0.0017033167295665945, 0.002424212226879074, -0.00542775656512287, 0.007382971852534567, -0.0014542527040584915, 0.007319670206512659, 0.001317865737763118], \"y\": [-0.007623369837505712, 0.0008390191300040602, 0.006123561792898235, -0.002061871302110771, 0.0016772288073728903, 0.001188546791314974, -0.005861380065210966, 0.0018941177629441999, 0.005693660830895793, -0.0018695139106026774], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [20.729962787553617, 18.73195797125623, 12.52342274714573, 11.595724304450513, 10.822919130300253, 7.509015946205539, 5.615064894057167, 5.013072819177994, 4.102380817970992, 3.3564785818819582]}, \"tinfo\": {\"Term\": [\"model\", \"learn\", \"use\", \"function\", \"state\", \"set\", \"datum\", \"network\", \"value\", \"result\", \"feature\", \"base\", \"show\", \"problem\", \"image\", \"distribution\", \"parameter\", \"map\", \"class\", \"object\", \"sample\", \"training\", \"method\", \"figure\", \"number\", \"error\", \"give\", \"policy\", \"well\", \"example\", \"std\", \"extra\", \"extra_outputs\", \"xim\", \"noisel\", \"noisescale\", \"brfs\", \"std_std\", \"scrambled_wavelet\", \"supervisor\", \"mother\", \"extra_output\", \"compatibility\", \"unencoded\", \"dictionary\", \"round\", \"continuous_tempere\", \"sign_sign\", \"halt\", \"keyboard\", \"interpolate\", \"multitask\", \"ctld\", \"cutting_plane\", \"gb\", \"unencode\", \"sublinear\", \"contrive\", \"logarithmic\", \"pomerleau\", \"temperature\", \"scene\", \"object_detection\", \"community\", \"random_projection\", \"function\", \"non_decomposable\", \"object\", \"noise\", \"show\", \"surface\", \"texture\", \"feature\", \"edge\", \"loss\", \"marker\", \"local\", \"result\", \"correspond\", \"output\", \"detection\", \"scale\", \"use\", \"method\", \"bound\", \"prove\", \"follow\", \"problem\", \"theorem\", \"positive\", \"bind\", \"datum\", \"sample\", \"learn\", \"input\", \"distribution\", \"figure\", \"test\", \"graph\", \"model\", \"network\", \"probability\", \"number\", \"also\", \"define\", \"performance\", \"set\", \"approach\", \"case\", \"well\", \"estimate\", \"system\", \"image\", \"base\", \"parameter\", \"training\", \"transform_coder\", \"adaptive_transform\", \"piecewise_polynomial\", \"transform_code\", \"moss\", \"bpp\", \"quantization\", \"npm\", \"pea\", \"sakurai\", \"lancaster_interaction\", \"demi_syllable\", \"coder\", \"reproduction\", \"cot\", \"hippocampal\", \"uphill\", \"maass\", \"ventral\", \"flll\", \"centrality\", \"successor\", \"independence_test\", \"dqh\", \"pxy\", \"dropout\", \"allocate\", \"shatter\", \"am\", \"preplay\", \"decoder\", \"turbo\", \"compression\", \"sparsifying_logistic\", \"vocabulary\", \"dot_product\", \"packet\", \"ai\", \"mutant\", \"network\", \"vc_dimension\", \"parent\", \"eye\", \"rate\", \"bit\", \"image\", \"code\", \"neural\", \"use\", \"number\", \"vector\", \"activity\", \"representation\", \"decode\", \"order\", \"log\", \"test\", \"describe\", \"term\", \"cluster\", \"model\", \"weight\", \"column\", \"set\", \"input\", \"give\", \"training\", \"matrix\", \"different\", \"small\", \"figure\", \"method\", \"time\", \"datum\", \"case\", \"graph\", \"parameter\", \"show\", \"problem\", \"learn\", \"result\", \"base\", \"function\", \"state\", \"distribution\", \"also\", \"feature\", \"conditional_entropy\", \"semi_supervise\", \"skewed\", \"mmihmm\", \"written_character\", \"eca\", \"capacitor\", \"blahut\", \"rlmi\", \"target_neuron\", \"impedance\", \"chip\", \"interconnect\", \"reactive_policie\", \"neuronal\", \"ferret\", \"latent_factor\", \"circuit\", \"convergent\", \"exchangeability\", \"spread_stimulus\", \"parasitic\", \"grid_world\", \"rlmince\", \"pole\", \"chapelle\", \"quadrant\", \"bahl\", \"cortico_cortical\", \"conserve\", \"logo_traine\", \"unlabeled\", \"spike\", \"child\", \"vin\", \"population\", \"transient\", \"calcium_image\", \"advice\", \"datum\", \"lds\", \"label\", \"policy\", \"domain\", \"model\", \"matrix\", \"learning\", \"system\", \"learn\", \"rule\", \"set\", \"file\", \"mean\", \"design\", \"train\", \"base\", \"large\", \"distribution\", \"form\", \"prior\", \"task\", \"result\", \"point\", \"graph\", \"network\", \"show\", \"term\", \"parameter\", \"value\", \"follow\", \"state\", \"method\", \"give\", \"use\", \"log\", \"training\", \"number\", \"input\", \"figure\", \"problem\", \"approach\", \"well\", \"function\", \"altitude\", \"wind\", \"glideslope\", \"pitch\", \"landing\", \"aircraft_lande\", \"switch\", \"pid\", \"aircraft\", \"turbulence\", \"oscillatory\", \"aircraft_landing\", \"disturbance\", \"damp\", \"plant\", \"flare\", \"controller\", \"land\", \"neuman\", \"aerodynamic\", \"augmentation\", \"touchdown\", \"dyna_ahc\", \"ejudge\", \"ebs\", \"initiation\", \"airframe\", \"parenthesis\", \"occam_razor\", \"optimizational\", \"kregbaye\", \"evoc\", \"concentrator\", \"pfm\", \"dyna\", \"kernel\", \"topic\", \"control\", \"evocation\", \"apm\", \"state\", \"model\", \"function\", \"action\", \"site\", \"learn\", \"error\", \"select\", \"task\", \"also\", \"sample\", \"weight\", \"estimate\", \"method\", \"propose\", \"well\", \"provide\", \"use\", \"matrix\", \"give\", \"parameter\", \"large\", \"problem\", \"result\", \"figure\", \"value\", \"network\", \"datum\", \"distribution\", \"feature\", \"set\", \"follow\", \"log\", \"show\", \"number\", \"base\", \"io_passe\", \"lp_relaxation\", \"compensation\", \"vkt\", \"factorial_hmms\", \"relaxed\", \"iqrp\", \"scheduler\", \"rec_compensation\", \"rec\", \"equivalence_constraint\", \"frustrate\", \"deshpande\", \"fk\", \"ntkd\", \"lehrer\", \"exactness\", \"synthesizer\", \"subexponential\", \"core\", \"randomize\", \"rnr\", \"belief_propagation\", \"compiler\", \"golub\", \"pnk\", \"rina\", \"ukt\", \"relaxing_equivalence\", \"repulsive\", \"instruction\", \"environment\", \"eigenfeature\", \"map\", \"relaxation\", \"ambiguity\", \"feature\", \"coverage\", \"value\", \"child\", \"first\", \"time\", \"state\", \"transition\", \"error\", \"table\", \"parameter\", \"consider\", \"new\", \"procedure\", \"achieve\", \"model\", \"set\", \"goal\", \"sample\", \"variable\", \"code\", \"algorithm\", \"experiment\", \"problem\", \"present\", \"large\", \"also\", \"task\", \"class\", \"use\", \"base\", \"probability\", \"neural\", \"function\", \"method\", \"learn\", \"give\", \"matrix\", \"case\", \"network\", \"result\", \"distribution\", \"datum\", \"number\", \"show\", \"figure\", \"well\", \"mental_rotation\", \"erd_erd\", \"succession\", \"vjk\", \"agnostic_active\", \"hypothesis_space\", \"label_complexity\", \"clf\", \"refinement\", \"wein\", \"disagreement\", \"fck\", \"self_organize\", \"monomial\", \"watanabe\", \"kth_order\", \"npm\", \"ulually\", \"iayer\", \"disagreement_coefficient\", \"prxdx\", \"demi_syllable\", \"hebbian\", \"large_vocabulary\", \"tsybakovs\", \"cepstral\", \"dqh\", \"mlp_predictor\", \"ws\", \"logd\", \"advice\", \"wt\", \"speech\", \"lower_bound\", \"unit\", \"view\", \"recognition\", \"speech_recognition\", \"riemannian\", \"activation\", \"edelman\", \"input\", \"learning\", \"distribution\", \"bound\", \"boundary\", \"state\", \"probability\", \"condition\", \"log\", \"loss\", \"density\", \"structure\", \"number\", \"give\", \"layer\", \"time\", \"class\", \"let\", \"object\", \"result\", \"model\", \"network\", \"method\", \"large\", \"weight\", \"show\", \"set\", \"base\", \"use\", \"parameter\", \"also\", \"function\", \"sample\", \"problem\", \"error\", \"learn\", \"datum\", \"figure\", \"value\", \"tangent_subspace\", \"tangent_distance\", \"goals_replay\", \"ddpg\", \"fetch\", \"hindsight_experience\", \"curriculum\", \"gripper\", \"prototype\", \"multiagent\", \"googl\", \"replay\", \"lvq\", \"mahalanobis\", \"slide\", \"mjolsness\", \"puck\", \"horgan\", \"naf\", \"stagewise\", \"rangarajan\", \"schaul\", \"actor\", \"helicopter\", \"siickinger\", \"ostrovski\", \"hdqc\", \"physical_robot\", \"ablation\", \"road\", \"compatibility\", \"building\", \"screen\", \"lfw\", \"dqn\", \"tangent\", \"shelf\", \"reward\", \"image\", \"contextual\", \"map\", \"face\", \"compensation\", \"set\", \"learn\", \"subspace\", \"feature\", \"goal\", \"category\", \"function\", \"example\", \"measure\", \"well\", \"compute\", \"matrix\", \"task\", \"policy\", \"case\", \"also\", \"approach\", \"result\", \"use\", \"point\", \"class\", \"system\", \"object\", \"give\", \"value\", \"different\", \"problem\", \"state\", \"model\", \"sample\", \"variable\", \"show\", \"datum\", \"network\", \"number\", \"method\", \"figure\", \"parameter\", \"tracklet\", \"parking\", \"mlp_predictor\", \"barycenter\", \"probit\", \"fsm\", \"sarsa\", \"urban\", \"thread\", \"genevay\", \"flop\", \"crutchfield\", \"pages_curran\", \"fulcrum\", \"schuurman\", \"kolen\", \"ullman\", \"reprojection\", \"watrous\", \"dbm\", \"dbms\", \"metropolis\", \"hdp\", \"sbn_qlim\", \"fitness\", \"evolution\", \"view_tuned\", \"stlwt\", \"rf\", \"synergistic\", \"swap\", \"gibbs_sampl\", \"recognition\", \"measurement\", \"data\", \"object\", \"training\", \"move\", \"transition\", \"datum\", \"file\", \"filter\", \"learn\", \"outperform\", \"view\", \"model\", \"topic\", \"label\", \"machine\", \"define\", \"variable\", \"sample\", \"set\", \"search\", \"problem\", \"follow\", \"number\", \"parameter\", \"network\", \"state\", \"point\", \"class\", \"large\", \"distribution\", \"method\", \"figure\", \"result\", \"example\", \"time\", \"use\", \"small\", \"function\", \"probability\", \"show\", \"learning\", \"also\", \"base\", \"give\", \"fully_disconnecte\", \"compensation\", \"equivalence_constraint\", \"relaxing_equivalence\", \"relaxed\", \"tighten\", \"valid_configuration\", \"adnan\", \"rec\", \"rec_compensation\", \"frustrated\", \"frustrate\", \"compensate\", \"relaxation\", \"bucket\", \"clone\", \"message_passing\", \"pensation\", \"los_angele\", \"yair\", \"exactness\", \"rina\", \"upper_bounde\", \"repulsive\", \"lp_relaxation\", \"informed\", \"idealized\", \"rerun\", \"standley\", \"jointree\", \"ideal\", \"map\", \"calcium\", \"assignment\", \"delete\", \"relax\", \"model\", \"base\", \"approximation\", \"value\", \"belief_propagation\", \"consider\", \"protocol\", \"random\", \"learn\", \"policy\", \"recognition\", \"distribution\", \"use\", \"state\", \"function\", \"cell\", \"performance\", \"training\", \"set\", \"test\", \"datum\", \"case\", \"network\", \"result\", \"sample\", \"problem\", \"approach\", \"well\", \"method\", \"parameter\", \"show\", \"figure\", \"give\", \"also\", \"time\", \"score_space\", \"scheduling\", \"counter\", \"ewn\", \"scheduler\", \"dyna\", \"grbfs\", \"ajj\", \"utgoff\", \"impedance\", \"gale\", \"schedule\", \"instability\", \"pac_bayes\", \"oiod\", \"painstakingly\", \"oio\", \"reordering\", \"euclidean_distance\", \"tarsy\", \"germain\", \"erd\", \"instruction_scheduling\", \"vendor\", \"voting_classifi\", \"modem\", \"partial_schedule\", \"pac_baye\", \"margin_bound\", \"pertain\", \"classifier\", \"execution\", \"instruction\", \"normalisation\", \"likelihood_ratio\", \"dyna_ahc\", \"basic_block\", \"prototype\", \"margin\", \"derivative\", \"use\", \"division\", \"state\", \"first\", \"maze\", \"class\", \"space\", \"cell\", \"learn\", \"value\", \"error\", \"show\", \"image\", \"probability\", \"function\", \"figure\", \"feature\", \"make\", \"model\", \"result\", \"network\", \"datum\", \"parameter\", \"dataset\", \"example\", \"approach\", \"vector\", \"number\", \"base\", \"object\", \"method\", \"problem\", \"give\", \"set\", \"well\", \"time\", \"distribution\", \"input\"], \"Freq\": [2185.0, 1279.0, 1693.0, 1226.0, 810.0, 1081.0, 1066.0, 1354.0, 655.0, 1001.0, 797.0, 672.0, 916.0, 836.0, 600.0, 774.0, 731.0, 283.0, 515.0, 565.0, 655.0, 597.0, 975.0, 732.0, 779.0, 576.0, 684.0, 406.0, 589.0, 478.0, 17.335398485721612, 29.85794277079945, 4.55341126817584, 2.550332534883585, 1.3686746565098706, 3.301235983942713, 1.5836822216894126, 3.1787326469890798, 3.3279041758691816, 2.200132119760553, 4.136471229141088, 2.2053267842281823, 4.322137125939421, 2.196047903753043, 7.6895285804742315, 15.457871143975183, 4.396596173824201, 1.5732628922168288, 3.792435352999483, 2.263268536279871, 3.5699025101812842, 2.0045176162062304, 7.346189288237368, 4.063296204253807, 4.108597015614164, 1.1864206065337182, 2.2365702009563755, 1.1846944327599331, 4.6284694696489055, 0.7648809136882766, 12.51809506253288, 46.00586627396008, 10.008256967210826, 27.167179149295777, 11.800529067707211, 376.18725427470093, 11.741928018132887, 170.89132589261035, 58.70775319972641, 261.0473086316878, 25.831098076553413, 13.248704719548538, 225.01054890944917, 79.61929116447942, 96.27550719998685, 37.776372593867414, 70.01510543438805, 259.14073276966775, 85.17710499343978, 93.71277330013142, 38.04867461379094, 85.77899005921886, 388.3770954580414, 235.22176722608575, 91.28233891268407, 41.26013556124609, 150.85570304450985, 199.62785886410953, 88.63084456594146, 53.12977900968382, 72.84961563046531, 238.49443841270426, 155.29901919796959, 270.1529711472629, 143.29927970516042, 174.6688015491027, 164.8007208068044, 105.65641121670451, 105.61684936527467, 368.855941252905, 253.78204479286603, 119.28423015495116, 154.15509928121605, 136.66834951328815, 100.54312192083108, 118.92875864542017, 179.10916450681205, 121.82423450485174, 120.74009165873568, 119.6339141322531, 103.35606373060767, 114.8961378477212, 119.90036004729083, 125.98342214085513, 121.7820577494448, 115.48122718410889, 5.080287146325817, 5.218135696408058, 3.6892150604496745, 1.556115105616334, 4.7072423595973625, 1.8542463329797254, 9.258169510324905, 4.621099214851239, 2.23381199884301, 1.852584421470405, 5.173817884038804, 4.3333848188792645, 4.796680411082954, 2.7137889277763407, 1.3782620451114695, 2.3675281028139907, 1.3707671779124921, 1.7241825874313954, 1.3157508586109372, 0.6713943707267694, 16.018137735885787, 4.36803891402095, 2.235890098227587, 2.0243165253086595, 0.9580998596456838, 1.367979596963893, 1.6035647833831046, 1.33491938262115, 1.0073394421842798, 2.244252324711256, 18.14121432726933, 1.9873900495316965, 18.920187906492764, 4.785127324828632, 3.960831092534643, 8.31461273183636, 14.954091985699916, 11.852878876832593, 5.309021627300868, 386.58223198661557, 10.771657889541544, 13.688308715682943, 8.938838777610913, 98.90386156759526, 40.90147378084428, 155.4799084442149, 63.91512245792512, 120.48468382621571, 390.30704531035815, 190.46404573459932, 121.56837508992764, 41.6454070260542, 90.75857533753283, 19.1943576074823, 83.94466069499983, 125.424501368297, 101.39788238457011, 67.04824261541259, 106.70292905620879, 57.52481478170507, 400.25949984727526, 101.34956741296716, 54.168051990187834, 215.52604927222924, 131.22602402976744, 143.7492018796173, 128.1178875374864, 133.01889117112196, 102.55256724455155, 91.53013602204513, 144.1915548566291, 179.35769946992957, 113.50224510865587, 187.84383427530858, 116.73744799342208, 90.49226466813312, 132.13327641975286, 153.1006604701792, 137.86255795405225, 176.09645541031855, 147.88239568323914, 116.91401079405932, 150.25359666987038, 122.19082691543001, 116.39888793505729, 109.69107125171121, 106.45252234035486, 1.6992238410960014, 21.774776745437414, 1.3754283396440867, 1.0886886079584648, 2.113840414035556, 2.1384422484356858, 3.160478110988363, 1.2605196369337617, 0.9640440489136046, 2.2804727953779977, 3.006863752284285, 1.8356338832165786, 1.2920405161032316, 2.420256831962995, 5.699836067237837, 1.971736335521041, 3.9210703972630245, 5.135269976770271, 2.348099402592158, 0.9470202816834462, 0.9688071169162876, 1.4865836525949183, 5.189310849278052, 0.6763419770920152, 1.6840506184329402, 0.454771931496772, 1.4681349953916802, 0.6788548667892396, 3.553533707996078, 1.162695201021804, 2.403491806110141, 14.360220317175878, 21.023492589591378, 15.21948196200553, 6.7581866877270755, 14.141064471896623, 5.189835581624287, 3.199276544493991, 21.14996137028136, 181.86516112680107, 8.738255910993773, 57.66172730448748, 72.47647906521888, 35.932392380233935, 316.49683285275637, 105.57314327917575, 80.90090774955061, 90.64803202078375, 190.18852083774973, 39.289930962101316, 158.49613428178773, 14.086134661368083, 56.08322746054615, 26.578323015571215, 59.58193837579483, 100.78820291333973, 82.10114737733613, 110.75788550485508, 52.52327751874276, 51.36150905718377, 70.3610565141157, 132.81558964613433, 71.17218225142595, 65.2170777064912, 164.1670106470118, 118.82575027467318, 67.40196929673738, 97.19811676436737, 88.72442952147021, 83.14862913388535, 102.55217630943048, 116.88868148630577, 90.2728152522361, 171.3881120679628, 75.58538012919622, 81.07088236524177, 93.47991859393655, 79.42782939571688, 85.08418448369626, 87.68882880993942, 74.20151179772068, 75.19954167326112, 98.29407826621024, 6.252537754797901, 6.6540327772666314, 2.1097333401484826, 2.549954737551074, 3.303545432175884, 1.2436219475401178, 6.915016592520356, 1.180250476981106, 4.523891327323777, 2.0421034674858447, 0.8723040517428642, 1.7671124508522504, 1.472782539837343, 4.365120350162282, 4.5823718166155025, 2.2539287855849883, 9.400784203180498, 1.110242039537474, 0.8355309527687486, 0.5404706509559817, 1.3495002446593745, 0.80742161518758, 3.1954683710737934, 1.0600260739553138, 2.372568863888859, 0.5005101632992812, 0.49989840107247446, 0.501835654783318, 3.836997618909283, 1.4884338397155898, 3.0087466006793755, 2.202294311572543, 7.990721455898168, 7.1975950430133775, 6.3690831937589385, 94.27388584107625, 53.336584399277825, 39.22342425144251, 7.534500504449159, 7.185116068506403, 131.09254777585213, 312.89430858354586, 177.8683880430954, 47.16530701587242, 13.465130581721812, 168.61069714641442, 85.1277027645492, 35.071715461976474, 67.18207310110546, 87.15602198364489, 87.67042167869057, 63.75147003645903, 61.94450429918152, 118.19966000461612, 51.997206859643406, 77.88193453275515, 55.20024764122105, 176.14033647657305, 82.43517478431835, 86.51425491928703, 90.12046374978242, 70.86476167946039, 98.4427941351599, 110.70831680605922, 87.00395238200949, 79.82815846546316, 131.85912504261498, 111.40275128003708, 88.55813705617975, 87.90558897614127, 106.09167927253354, 72.33124064304863, 65.30779250216368, 84.06652964141308, 71.49437708667539, 67.88244020230795, 2.8822281294454792, 1.389060250063735, 13.413837812331936, 2.6315401873106214, 0.7955699695038666, 1.5864553597218367, 3.0436951533314685, 3.2614940790417988, 1.3653345356508637, 3.6332235901372254, 3.288696084235416, 0.6747390305888868, 0.9600471234818858, 0.9300812702113016, 0.5407542677025698, 1.5783365559957447, 0.4935788060045469, 4.375499981307234, 1.4364549937497297, 3.1935685744248246, 4.483699084343673, 0.7319390354941815, 7.532398938829193, 2.431136439274694, 0.7130700441863355, 1.0520306218506479, 0.47345610349404144, 0.5350273531167054, 1.1853679434796216, 0.4744832978948401, 14.800617678892184, 19.35173985850896, 3.3877951339424435, 50.04324526048931, 11.963762722043587, 3.347398021586897, 126.30019089977769, 4.061753699659855, 101.32034104072741, 11.631598543463618, 70.681958564976, 82.42417428020056, 116.36141230894441, 27.335669946513406, 83.32410994557972, 35.774767386236505, 103.69000423600264, 61.51730088345169, 39.90892322483921, 21.80881153927533, 34.96888131798421, 249.2870673591275, 131.55567427230136, 34.98817097269756, 84.79395203912665, 66.62289203928303, 34.68036231026734, 56.36714924092174, 45.97789682794092, 99.92670286894337, 38.678827051398756, 68.39992701563682, 79.24716194338188, 59.657527083750615, 65.34449535329199, 168.76907947768214, 79.8825749124136, 64.40035243913772, 59.85859106449319, 123.98510773716576, 102.20066722786791, 121.73136386261778, 75.57591724327305, 71.7627329532357, 66.56229741494965, 114.76493919331493, 93.57876916274331, 78.36466859384598, 89.47275063414006, 75.96590623125262, 81.26269934688179, 71.85744845158318, 66.11243937242548, 2.1259104911451834, 0.8787193500142129, 0.49999000269109267, 1.0315412629955205, 0.989177904127823, 0.653715230160463, 3.8206580479435295, 0.4698443138117717, 7.172137365882887, 0.46350631244439455, 0.6318147698925635, 0.8062705370325534, 1.2182888033747408, 1.1676828032996323, 0.5874679588586794, 1.7914106937062022, 2.1318457889524036, 0.2969110528135403, 1.847032221210963, 1.9188066014633078, 0.7764108597925267, 2.006490411493951, 1.0446046518586913, 1.5702090745340134, 0.4494721295965735, 0.4361789792572915, 0.9757382032253998, 1.1285567008334139, 3.1632222860605506, 0.7449695542291072, 16.029741994852433, 1.969478528592598, 5.713448819564456, 9.238785127607748, 38.04450632020177, 28.935095532953536, 25.560291078350147, 4.383912303852975, 3.257587808207294, 9.746601872185643, 1.9487482476623794, 63.22622500315607, 50.79132195587826, 76.80833248245773, 36.303376338138506, 8.93073501591559, 76.77356439631407, 51.65080706196098, 29.795471533985076, 51.46224533738593, 32.87662343476333, 10.723348955982724, 37.94804127494494, 66.55624459922663, 58.882552420455326, 30.055520126478857, 49.192241695932296, 45.97690578122794, 35.69965094366215, 49.14015580425948, 78.52315622445249, 146.4660175417802, 98.26393768797274, 74.4600989912423, 46.54725407795656, 39.77386589093388, 69.46026406341628, 78.08075567700828, 54.28633595884449, 105.95309633295578, 57.16375442590079, 52.06292711677693, 78.22600798431333, 51.61236279219955, 60.07635165186526, 46.582257307376665, 68.53001739050698, 61.732502178569405, 51.59461113076595, 44.11475318496564, 1.9854732911328155, 1.4473008744952789, 0.6107149820997899, 2.7910707745015935, 0.6133810973215339, 1.659629812472496, 1.603176692635929, 1.4335851571682245, 4.0448401409315125, 0.42730054140441986, 0.5585131975342269, 4.370655448908927, 0.40294288425831604, 0.38482967689469477, 1.2536960762191753, 0.3871226466559346, 0.8050300453274182, 0.26533821117671885, 0.39872289274164247, 0.4106762010674873, 0.36677942791168544, 0.6529776234711792, 0.9004165967775732, 0.387510264417821, 0.364224486277832, 1.0206319677846067, 0.6302198908516755, 0.9055817379232849, 0.5044234354701677, 5.048534640403826, 1.5389209127707337, 3.9299662874062866, 1.4650640379062172, 2.0820959473833796, 1.8125662829848252, 2.73198013578211, 1.9876433624202856, 18.006622501364674, 54.93125162877575, 5.624596935115712, 27.36317863727087, 16.05610918250018, 6.286312036414427, 82.26773560309924, 95.02779935120736, 5.261559796687108, 60.13865003711575, 20.7924405269924, 8.891331238297663, 82.07152896364576, 37.21352907720187, 25.286787562743573, 41.95475283348114, 23.697899133347136, 44.71497454322681, 33.27662970612166, 29.996717714699333, 39.83194885624516, 43.27836134721431, 38.60890039344234, 59.461246032414905, 88.78514630107175, 32.56041331087332, 34.715434643177716, 35.41204176658104, 35.72501495796938, 40.810126598797034, 38.90904013614404, 30.879446992212248, 45.527736512307655, 44.58039916660927, 84.90637388370135, 37.15500092343664, 31.72909212441354, 44.67421558944743, 47.22536749253037, 47.89903191646765, 37.142083272269225, 38.76313952586304, 35.15820843521528, 34.37478360105184, 3.266894789064433, 1.293061230175505, 0.8229529369627893, 6.150807174178046, 0.6900433278152064, 0.811283312648092, 1.4554172371767098, 1.116505900853115, 1.1809874276664105, 0.2839574438906959, 1.5241366921891726, 0.38976685473488026, 0.8403149345503063, 0.19056350094066443, 0.2790613879325481, 0.5837524818326876, 0.2836855732135674, 0.2788913802316587, 0.3711916910379481, 1.9192542119730365, 1.1761408435692002, 0.7248825039849093, 0.8217088854876771, 0.5276013323629725, 2.740874310671182, 3.935165937811786, 1.1591438045982645, 0.4369335756939273, 2.5467892907354432, 0.25480938001411707, 8.775588439112848, 0.9603792717381467, 17.848448039396235, 4.218493772813057, 9.561608420852876, 43.445328183549506, 45.65504772107528, 6.229800746277056, 13.844701941644121, 74.76963255218628, 5.694468226483981, 13.395938545393062, 79.96230520576883, 6.952418807107628, 16.144955537443806, 125.15960278740731, 18.642314976866643, 21.869554061892526, 20.26144772989345, 27.485918104257927, 31.99969531967246, 40.42534911069898, 60.881714867169876, 11.905439263902522, 48.73721430501984, 36.59557260839794, 45.28043684040824, 42.66503256596444, 70.10368099804433, 44.985374501095876, 28.572090223025548, 30.609897531205384, 31.40142519587705, 41.075923428565375, 48.46290914248877, 38.22877195267769, 47.697365536352876, 27.43086338527046, 29.994611298280354, 61.273655823637064, 24.443187502958367, 48.92975547123939, 28.149497717589558, 37.27531266113035, 26.325848844205197, 30.41352685601851, 30.365474478197036, 28.732098251286, 1.5114513663604279, 12.682073196721358, 3.477668650868329, 1.2951004697820605, 1.3927987099106969, 1.0765481364695701, 1.078171932127107, 0.7498991755081429, 3.0474796190118565, 1.143459961819474, 1.0077334202826045, 0.5475706065323536, 3.3673301583950423, 11.153827605881153, 1.3703621941476023, 0.804273260579944, 0.6642357841408555, 0.3884025860692432, 0.921183664240634, 0.37243332080122993, 0.3641816083291992, 0.3664050402061168, 0.23357399807125298, 0.3499578470602802, 0.8047767175245331, 0.231662979209058, 0.22662520096020214, 0.22479277656711982, 0.22375473587560615, 0.22421623807481275, 1.6027080264177076, 33.70990285858782, 2.0125191521740007, 8.209298373074864, 0.9876004575206955, 2.2527185509058807, 122.57285629124574, 42.81013908667795, 23.612239263369865, 40.96947154735529, 3.703614744726893, 25.80288401565617, 4.62870625036593, 23.01925111830589, 58.76585398970283, 23.876103174037638, 13.958023078062634, 37.60876752467706, 64.88251299102019, 37.2305587260659, 49.08210347301545, 9.821541209079953, 26.22689156424554, 28.23205246474153, 43.24697144325743, 21.81703393137782, 40.971780302292565, 26.96901695515948, 48.148744055396904, 38.87084949675759, 29.157924713135607, 34.126738068171434, 26.16233327571747, 26.267110220002326, 35.45394285193085, 28.323834520343407, 31.51920925333654, 27.257546185031696, 26.459060756859884, 24.687038870801423, 23.6057671501954, 5.4854672302337635, 1.352610590153156, 0.9264975727755597, 0.496153657489055, 1.6590872954349698, 2.885533902432885, 0.28223079895453895, 0.47247571063504734, 0.2713652489417858, 1.1751684296716298, 0.26952987057877587, 5.374807610831049, 0.5716646027138127, 1.6681955574643559, 0.3459468353770617, 0.16854729383051542, 0.2514118847360223, 0.34026710185816833, 0.6444763410128347, 0.253221495124233, 0.34454532586800946, 0.514266323193385, 0.8401783731157665, 0.3311337195230085, 0.5119792650782169, 0.24532902351084457, 0.32303480340775026, 0.5847843416386912, 1.1641066128131214, 0.2449936466108322, 14.84981167074684, 2.883343670837025, 7.05251761132791, 1.1431843126142123, 1.022564191268735, 1.0167591337934123, 0.7105260445893231, 2.0841075101182986, 5.888626394727832, 4.127280487343716, 77.3408304291902, 0.8678292142961777, 37.196139905482525, 22.301924046349196, 0.9743063721806742, 23.8932623859952, 22.638356646873085, 7.95234454373104, 50.0226276191035, 28.230517541494144, 25.17677363044128, 35.32318471085606, 24.92322786131461, 21.34924065972885, 41.645985844369854, 27.520796642027634, 29.085701203116237, 14.448507060245143, 58.44661807066174, 32.54510354090833, 38.63270681364226, 32.46023595258291, 24.353635892006462, 12.97179059405141, 17.788455543558342, 19.44262296002752, 17.295420273640726, 23.47770609616039, 21.317473049174232, 19.055287275067244, 26.36918041889492, 24.002144801592014, 21.16765499039478, 26.06915940088659, 18.924524749306993, 18.323487893667206, 19.22495435394625, 18.35034802349166], \"Total\": [2185.0, 1279.0, 1693.0, 1226.0, 810.0, 1081.0, 1066.0, 1354.0, 655.0, 1001.0, 797.0, 672.0, 916.0, 836.0, 600.0, 774.0, 731.0, 283.0, 515.0, 565.0, 655.0, 597.0, 975.0, 732.0, 779.0, 576.0, 684.0, 406.0, 589.0, 478.0, 36.78707408278759, 65.3460795958643, 10.123651661932357, 5.953411517606034, 3.2378236887940743, 7.814677821848846, 3.864746730107505, 7.778344902417281, 8.179011596502052, 5.419818595384283, 10.224709629408945, 5.479580552685618, 10.740350196205522, 5.457190392646887, 19.307442206043035, 38.996637703951045, 11.199784246951959, 4.074467300629481, 9.829929484800823, 5.9145118297786485, 9.357420942263547, 5.256057351326594, 19.411654457161692, 10.771844348838696, 10.92824518029485, 3.1602090637930367, 5.960500314677, 3.166030870395576, 12.40826093682672, 2.0640985832302117, 34.478415579059686, 132.31179052895442, 27.940022426221873, 78.24559576498119, 33.289176048272736, 1226.5438067276264, 33.18963866687708, 565.2466843414603, 183.69921902357834, 916.5551346430217, 77.55606152716136, 37.91699411620806, 797.6108282647003, 262.0802761756691, 324.19184084116, 119.23849052299308, 235.2371795548523, 1001.22352489873, 296.05330675232085, 329.2032674896509, 122.49263577647484, 309.1572008595035, 1693.2169106684926, 975.377746345225, 336.35661564207226, 137.50935294869595, 604.5213620459244, 836.0189279711608, 329.86225805278946, 184.10672743083265, 265.9704944040314, 1066.2384542071527, 655.6165137129959, 1279.088611960653, 606.9753725000938, 774.5308725674558, 732.6977953264409, 425.8107188264446, 426.5287259614625, 2185.3451184704063, 1354.2034531339473, 515.7935552099913, 779.9932902322028, 650.1709893262441, 411.3005555119424, 536.0788643239707, 1081.3250385970853, 570.4064887448344, 583.4645233162769, 589.8782415416645, 435.4418096794005, 546.6582649124314, 600.5687365457496, 672.5658371045942, 731.804959924617, 597.7759941169176, 12.057316093775047, 12.931048234495185, 9.151953924956103, 3.9567268408717897, 12.452512521349659, 4.9509469987875265, 25.026229820620824, 12.528156205242185, 6.081980639065371, 5.085570523592074, 14.534847052427692, 12.180797518342203, 13.498845819676637, 7.639589144387895, 3.8991412811399186, 6.715009084595428, 3.958717959779843, 4.986217836190141, 3.8218068273083374, 1.9616135987306824, 46.91679395544683, 12.802099027974982, 6.597099789418969, 5.991943329455854, 2.8403308875990416, 4.057707382335367, 4.75836699420311, 3.961617771386632, 2.989585610345064, 6.669107226628842, 54.15894295947313, 5.907823615102716, 58.29835871387107, 14.462579173814435, 11.965619123743345, 25.50451423286247, 46.56583787677852, 36.881559559158596, 16.177704014330814, 1354.2034531339473, 33.601916938924994, 43.38383448911791, 27.862999283719883, 363.61137802304273, 143.21392713304434, 600.5687365457496, 236.06480323745205, 470.38478511591705, 1693.2169106684926, 779.9932902322028, 476.90185578567764, 151.4047487031241, 364.37029086315135, 65.09281976774493, 341.87962463309964, 537.4722509660304, 425.8107188264446, 266.42844243916534, 454.8154104587892, 229.0118797040293, 2185.3451184704063, 444.3138297336393, 214.7111746079121, 1081.3250385970853, 606.9753725000938, 684.3373028268419, 597.7759941169176, 641.2992386435013, 473.72948355494793, 412.46296937051505, 732.6977953264409, 975.377746345225, 556.6761798228305, 1066.2384542071527, 583.4645233162769, 426.5287259614625, 731.804959924617, 916.5551346430217, 836.0189279711608, 1279.088611960653, 1001.22352489873, 672.5658371045942, 1226.5438067276264, 810.9384050798103, 774.5308725674558, 650.1709893262441, 797.6108282647003, 5.423708980591165, 72.16711699504181, 4.598798807219799, 3.663633502960205, 7.240100423598508, 7.4416759565901405, 11.184422524365727, 4.50410014031852, 3.5346937145890607, 8.37216592700841, 11.057596396513956, 6.761122452711377, 4.762441659428768, 9.059220104088123, 21.496729521741486, 7.544825083846493, 15.020924620926719, 19.673391731925076, 9.033503245267855, 3.679459166773335, 3.77351666583105, 5.816234509949626, 20.51793564788799, 2.67617153130348, 6.665295589398825, 1.8140237462650441, 5.860112950730662, 2.721978641746637, 14.320151613824763, 4.689058190233279, 9.899402311194796, 62.1728626711559, 93.21127052519283, 66.93939493518546, 29.157385998754958, 64.18057627676204, 22.347271227564992, 13.41844507399183, 101.54097775926492, 1066.2384542071527, 39.56362244951308, 309.0394329384822, 406.47735296198096, 187.5849821776308, 2185.3451184704063, 641.2992386435013, 475.6776822873014, 546.6582649124314, 1279.088611960653, 213.69341833678143, 1081.3250385970853, 67.51523887198935, 332.33736698938986, 141.69905387821308, 363.0402992622305, 672.5658371045942, 538.4599247015162, 774.5308725674558, 320.16398055625064, 313.5316552413295, 460.1354871521697, 1001.22352489873, 472.21911407533014, 426.5287259614625, 1354.2034531339473, 916.5551346430217, 454.8154104587892, 731.804959924617, 655.62183183785, 604.5213620459244, 810.9384050798103, 975.377746345225, 684.3373028268419, 1693.2169106684926, 537.4722509660304, 597.7759941169176, 779.9932902322028, 606.9753725000938, 732.6977953264409, 836.0189279711608, 570.4064887448344, 589.8782415416645, 1226.5438067276264, 15.650430454219068, 17.336432619609013, 5.857884386094727, 7.667044988934697, 10.361017031942572, 3.94014328525534, 22.12923165086036, 3.7883318012204112, 14.539862567426823, 6.624042083413134, 2.8391431093477912, 5.768794118509265, 4.810000787627179, 14.400274327399359, 15.290102330963679, 7.575962702015895, 31.797786524317996, 3.7759860778421435, 2.8573483149564347, 1.8695542337170488, 4.727231353770277, 2.850706450912204, 11.301067089675715, 3.7863833848850943, 8.599859068487701, 1.849791639679844, 1.853407391501547, 1.8643703134811278, 14.33383066703269, 5.608091849130509, 11.438781067112096, 8.412601442820144, 31.823248970157174, 29.519397943431, 26.013113654991923, 463.35869542999154, 257.7321421303022, 196.96123504294002, 32.30103922040538, 30.847777519226973, 810.9384050798103, 2185.3451184704063, 1226.5438067276264, 280.0894724263941, 65.03492162960661, 1279.088611960653, 576.8160409636133, 204.08942875522885, 460.1354871521697, 650.1709893262441, 655.6165137129959, 444.3138297336393, 435.4418096794005, 975.377746345225, 354.6004170522744, 589.8782415416645, 384.0163937088991, 1693.2169106684926, 641.2992386435013, 684.3373028268419, 731.804959924617, 538.4599247015162, 836.0189279711608, 1001.22352489873, 732.6977953264409, 655.62183183785, 1354.2034531339473, 1066.2384542071527, 774.5308725674558, 797.6108282647003, 1081.3250385970853, 604.5213620459244, 537.4722509660304, 916.5551346430217, 779.9932902322028, 672.5658371045942, 11.524299882587162, 5.683958022911338, 55.57189416210945, 11.294754931076982, 3.4746302602390298, 7.01324187647719, 13.520563030109225, 14.526619510832804, 6.339925480805187, 16.871116359592165, 15.296257576668408, 3.177044332921579, 4.578828646452032, 4.484027013193778, 2.613528592059372, 7.716024202713477, 2.4249615234666244, 21.618577702132306, 7.113823049017395, 15.955603823789573, 22.50225443106055, 3.6865664486139975, 38.09342200793604, 12.395629830932048, 3.6433086137224002, 5.4027484101729195, 2.4407511204440975, 2.760021032582967, 6.158411966663921, 2.4708786778378027, 78.13894678174579, 103.95031459770586, 17.845196609421283, 283.1027283597581, 65.74032744395024, 17.84800751787568, 797.6108282647003, 22.031947549407167, 655.62183183785, 66.93939493518546, 468.586845865915, 556.6761798228305, 810.9384050798103, 171.5491659893619, 576.8160409636133, 230.1090426699505, 731.804959924617, 418.49671818794803, 266.65522885154934, 136.86556242781984, 233.77699091969538, 2185.3451184704063, 1081.3250385970853, 236.53324380090294, 655.6165137129959, 497.23256904707614, 236.06480323745205, 420.93533251569346, 331.5708043186641, 836.0189279711608, 271.06099368293104, 538.4599247015162, 650.1709893262441, 460.1354871521697, 515.9728558043973, 1693.2169106684926, 672.5658371045942, 515.7935552099913, 470.38478511591705, 1226.5438067276264, 975.377746345225, 1279.088611960653, 684.3373028268419, 641.2992386435013, 583.4645233162769, 1354.2034531339473, 1001.22352489873, 774.5308725674558, 1066.2384542071527, 779.9932902322028, 916.5551346430217, 732.6977953264409, 589.8782415416645, 10.642789206638577, 4.4977313940830435, 2.6367900519615084, 5.532912622057645, 5.445084257739596, 3.6560484253792835, 21.41068420482594, 2.6540613492840612, 40.56547977502116, 2.6445768436905643, 3.606836343566332, 4.604795155740434, 7.008596550538746, 6.759048227700081, 3.4267920963645606, 10.477719836246377, 12.528156205242185, 1.7528833582402399, 10.910502636827669, 11.444281701308224, 4.6932000697644005, 12.180797518342203, 6.377017653291226, 9.588678742927192, 2.7540929146915683, 2.6770516268429967, 5.991943329455854, 6.933471406407291, 19.46081181127207, 4.5883820097860735, 101.54097775926492, 12.363558987267691, 37.69039928951341, 63.4064320375351, 285.33016500415977, 218.25799282192523, 211.7037140480711, 30.577523697090356, 22.251333921642896, 74.67936110958199, 12.671430264635, 606.9753725000938, 475.6776822873014, 774.5308725674558, 336.35661564207226, 69.46647068235755, 810.9384050798103, 515.7935552099913, 279.8165989464765, 537.4722509660304, 324.19184084116, 88.80686696883805, 393.1758577179397, 779.9932902322028, 684.3373028268419, 304.55152925748416, 556.6761798228305, 515.9728558043973, 380.9377619946593, 565.2466843414603, 1001.22352489873, 2185.3451184704063, 1354.2034531339473, 975.377746345225, 538.4599247015162, 444.3138297336393, 916.5551346430217, 1081.3250385970853, 672.5658371045942, 1693.2169106684926, 731.804959924617, 650.1709893262441, 1226.5438067276264, 655.6165137129959, 836.0189279711608, 576.8160409636133, 1279.088611960653, 1066.2384542071527, 732.6977953264409, 655.62183183785, 10.002737063500323, 8.231464815222918, 3.5098700291012084, 16.070141753441824, 3.5628345456485517, 9.67705519749268, 9.647427371858585, 8.742570137078921, 24.83894425075626, 2.653566384640308, 3.501573089429796, 27.458234317408632, 2.5322340717064242, 2.4799535677474447, 8.092380162644767, 2.4998344444420932, 5.2777902454643675, 1.74923947767122, 2.653747839473917, 2.7745796622399643, 2.4792721592999456, 4.430649306445054, 6.134740538258501, 2.6487469429712593, 2.4897390103177415, 7.036774119186887, 4.354240630501743, 6.258295874672797, 3.502880248947681, 35.12586718083873, 10.740350196205522, 28.322087644442924, 10.41310153861075, 15.066133256062981, 13.069650799924382, 20.402866070824018, 15.144019443907867, 170.08797731256834, 600.5687365457496, 48.29335973280121, 283.1027283597581, 155.77155202296794, 55.57189416210945, 1081.3250385970853, 1279.088611960653, 46.77606100378468, 797.6108282647003, 236.53324380090294, 87.69584071871658, 1226.5438067276264, 478.4078948953468, 316.47622917660607, 589.8782415416645, 294.49289307165697, 641.2992386435013, 460.1354871521697, 406.47735296198096, 583.4645233162769, 650.1709893262441, 570.4064887448344, 1001.22352489873, 1693.2169106684926, 472.21911407533014, 515.9728558043973, 546.6582649124314, 565.2466843414603, 684.3373028268419, 655.62183183785, 473.72948355494793, 836.0189279711608, 810.9384050798103, 2185.3451184704063, 655.6165137129959, 497.23256904707614, 916.5551346430217, 1066.2384542071527, 1354.2034531339473, 779.9932902322028, 975.377746345225, 732.6977953264409, 731.804959924617, 24.557843564102363, 10.508432392264657, 6.933471406407291, 51.82789114605767, 6.050452749084075, 7.26742441931094, 13.118776179178933, 10.212647065863488, 10.81860917269953, 2.6383920530597225, 14.16264547550313, 3.622715092387847, 7.8776487550010454, 1.7877834529587306, 2.6255296899954157, 5.54302885387169, 2.697093095507064, 2.676979783131211, 3.563270326456576, 18.582818008687777, 11.390451307359047, 7.042737484206863, 7.9934921806184684, 5.145549679054899, 26.731179922104275, 38.837959434228, 11.492365682785572, 4.361412233216745, 25.490159406097394, 2.552361507038588, 88.50174417973014, 9.785254753317936, 211.7037140480711, 46.86429058136716, 112.60040006534743, 565.2466843414603, 597.7759941169176, 72.62169206991729, 171.5491659893619, 1066.2384542071527, 67.51523887198935, 174.50567667735785, 1279.088611960653, 85.23390047379517, 218.25799282192523, 2185.3451184704063, 257.7321421303022, 309.0394329384822, 285.2672564027283, 411.3005555119424, 497.23256904707614, 655.6165137129959, 1081.3250385970853, 158.97900320572091, 836.0189279711608, 604.5213620459244, 779.9932902322028, 731.804959924617, 1354.2034531339473, 810.9384050798103, 472.21911407533014, 515.9728558043973, 538.4599247015162, 774.5308725674558, 975.377746345225, 732.6977953264409, 1001.22352489873, 478.4078948953468, 556.6761798228305, 1693.2169106684926, 412.46296937051505, 1226.5438067276264, 515.7935552099913, 916.5551346430217, 475.6776822873014, 650.1709893262441, 672.5658371045942, 684.3373028268419, 6.024372646635141, 55.57189416210945, 15.296257576668408, 6.158411966663921, 7.01324187647719, 5.538653679875705, 5.565870625196063, 3.977380849624618, 16.871116359592165, 6.339925480805187, 5.63752295948771, 3.177044332921579, 19.788557745133662, 65.74032744395024, 8.316395891332565, 4.898108578925074, 4.090999213473499, 2.446992571018861, 5.8784522288767755, 2.4621290319782894, 2.4249615234666244, 2.4407511204440975, 1.6348921445262905, 2.4708786778378027, 5.683958022911338, 1.6376798012560434, 1.6576027412299992, 1.653276532456316, 1.647052200489911, 1.6576446905742488, 11.96197430365764, 283.1027283597581, 15.975093937523162, 70.15228230735366, 7.688692582927179, 20.621484297784928, 2185.3451184704063, 672.5658371045942, 334.11804814358635, 655.62183183785, 38.09342200793604, 418.49671818794803, 50.27178569869654, 373.8213037365999, 1279.088611960653, 406.47735296198096, 211.7037140480711, 774.5308725674558, 1693.2169106684926, 810.9384050798103, 1226.5438067276264, 139.15142404172258, 536.0788643239707, 597.7759941169176, 1081.3250385970853, 425.8107188264446, 1066.2384542071527, 583.4645233162769, 1354.2034531339473, 1001.22352489873, 655.6165137129959, 836.0189279711608, 570.4064887448344, 589.8782415416645, 975.377746345225, 731.804959924617, 916.5551346430217, 732.6977953264409, 684.3373028268419, 650.1709893262441, 556.6761798228305, 38.9836024477807, 9.900984864324133, 7.739320950451272, 4.253440571546659, 14.526619510832804, 26.013113654991923, 2.5453820793056225, 4.323521241139231, 2.5203241711202296, 11.057596396513956, 2.555839916108104, 51.17415616563864, 5.460467584524218, 16.070535988012843, 3.4245416811377876, 1.7135539734282976, 2.55824464411136, 3.4634737578439263, 6.587938767654415, 2.5895963413881793, 3.5552423449842245, 5.340006598657266, 8.736295615567318, 3.456180669405651, 5.357251226152517, 2.577063230793677, 3.429094424425086, 6.2139685570905305, 12.404396054929142, 2.619472511419092, 161.55682157086454, 30.896275408094418, 78.13894678174579, 12.279329281746643, 11.359133553030409, 11.301067089675715, 7.745967440510266, 24.83894425075626, 81.68767027086001, 57.82241870796652, 1693.2169106684926, 9.84666543615608, 810.9384050798103, 468.586845865915, 11.375215812873858, 515.9728558043973, 490.0913361328416, 139.15142404172258, 1279.088611960653, 655.62183183785, 576.8160409636133, 916.5551346430217, 600.5687365457496, 515.7935552099913, 1226.5438067276264, 732.6977953264409, 797.6108282647003, 333.7017767931071, 2185.3451184704063, 1001.22352489873, 1354.2034531339473, 1066.2384542071527, 731.804959924617, 298.8393190535596, 478.4078948953468, 570.4064887448344, 476.90185578567764, 779.9932902322028, 672.5658371045942, 565.2466843414603, 975.377746345225, 836.0189279711608, 684.3373028268419, 1081.3250385970853, 589.8782415416645, 556.6761798228305, 774.5308725674558, 606.9753725000938], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -7.7254, -7.1817, -9.0623, -9.642, -10.2643, -9.3839, -10.1184, -9.4217, -9.3758, -9.7897, -9.1583, -9.7873, -9.1144, -9.7915, -8.5383, -7.8401, -9.0974, -10.125, -9.2452, -9.7614, -9.3057, -9.8828, -8.584, -9.1762, -9.1651, -10.4072, -9.7732, -10.4087, -9.046, -10.8462, -8.051, -6.7494, -8.2748, -7.2762, -8.11, -4.6481, -8.115, -5.4372, -6.5056, -5.0135, -7.3266, -7.9943, -5.162, -6.2009, -6.011, -6.9465, -6.3295, -5.0208, -6.1335, -6.038, -6.9393, -6.1264, -4.6162, -5.1177, -6.0642, -6.8583, -5.5619, -5.2817, -6.0937, -6.6055, -6.2898, -5.1038, -5.5328, -4.9792, -5.6133, -5.4153, -5.4735, -5.918, -5.9184, -4.6678, -5.0417, -5.7967, -5.5402, -5.6606, -5.9676, -5.7997, -5.3902, -5.7756, -5.7845, -5.7938, -5.94, -5.8342, -5.7915, -5.742, -5.776, -5.8291, -8.8515, -8.8247, -9.1714, -10.0346, -8.9277, -9.8594, -8.2513, -8.9462, -9.6731, -9.8603, -8.8332, -9.0105, -8.9089, -9.4785, -10.156, -9.615, -10.1615, -9.9321, -10.2024, -10.8752, -7.7031, -9.0025, -9.6722, -9.7716, -10.5196, -10.1635, -10.0046, -10.188, -10.4695, -9.6685, -7.5787, -9.79, -7.5366, -8.9113, -9.1004, -8.3588, -7.7719, -8.0043, -8.8074, -4.5195, -8.0999, -7.8603, -8.2864, -5.8827, -6.7657, -5.4303, -6.3193, -5.6853, -4.5099, -5.2274, -5.6764, -6.7476, -5.9686, -7.5222, -6.0467, -5.6451, -5.8578, -6.2714, -5.8068, -6.4246, -4.4847, -5.8583, -6.4847, -5.1038, -5.5999, -5.5088, -5.6239, -5.5863, -5.8465, -5.9602, -5.5057, -5.2875, -5.745, -5.2412, -5.7169, -5.9716, -5.593, -5.4457, -5.5506, -5.3058, -5.4804, -5.7154, -5.4645, -5.6713, -5.7198, -5.7792, -5.8091, -9.544, -6.9935, -9.7554, -9.9892, -9.3257, -9.3141, -8.9235, -9.8427, -10.1108, -9.2498, -8.9733, -9.4668, -9.818, -9.1903, -8.3338, -9.3953, -8.7078, -8.4381, -9.2206, -10.1286, -10.1059, -9.6777, -8.4276, -10.4653, -9.553, -10.8622, -9.6902, -10.4616, -8.8063, -9.9235, -9.1973, -7.4097, -7.0286, -7.3516, -8.1635, -7.4251, -8.4275, -8.9113, -7.0226, -4.8709, -7.9065, -6.0196, -5.7909, -6.4926, -4.3169, -5.4148, -5.681, -5.5672, -4.8262, -6.4032, -5.0085, -7.429, -6.0474, -6.7941, -5.9869, -5.4612, -5.6663, -5.3669, -6.113, -6.1353, -5.8206, -5.1852, -5.8091, -5.8965, -4.9733, -5.2966, -5.8635, -5.4975, -5.5887, -5.6536, -5.4438, -5.313, -5.5714, -4.9303, -5.7489, -5.6789, -5.5365, -5.6994, -5.6306, -5.6004, -5.7674, -5.7541, -5.4862, -8.1643, -8.102, -9.2507, -9.0612, -8.8023, -9.7792, -8.0636, -9.8315, -8.4879, -9.2833, -10.1339, -9.4279, -9.6101, -8.5236, -8.475, -9.1846, -7.7565, -9.8927, -10.1769, -10.6126, -9.6975, -10.2112, -8.8355, -9.939, -9.1333, -10.6894, -10.6906, -10.6867, -8.6526, -9.5995, -8.8957, -9.2077, -7.919, -8.0235, -8.1458, -5.451, -6.0206, -6.328, -7.9778, -8.0252, -5.1213, -4.2514, -4.8162, -6.1436, -7.3971, -4.8697, -5.5531, -6.4399, -5.7898, -5.5295, -5.5237, -5.8423, -5.871, -5.2249, -6.0461, -5.6421, -5.9863, -4.826, -5.5852, -5.5369, -5.4961, -5.7365, -5.4078, -5.2903, -5.5313, -5.6174, -5.1155, -5.2841, -5.5136, -5.521, -5.3329, -5.716, -5.8181, -5.5656, -5.7276, -5.7795, -8.8697, -9.5996, -7.332, -8.9607, -10.157, -9.4668, -8.8152, -8.7461, -9.6169, -8.6382, -8.7378, -10.3217, -9.969, -10.0008, -10.5431, -9.4719, -10.6343, -8.4523, -9.5661, -8.7671, -8.4278, -10.2403, -7.9091, -9.0399, -10.2665, -9.8776, -10.676, -10.5537, -9.7582, -10.6738, -7.2336, -6.9655, -8.7081, -6.0154, -7.4464, -8.7201, -5.0896, -8.5267, -5.31, -7.4746, -5.6701, -5.5164, -5.1716, -6.6201, -5.5055, -6.351, -5.2869, -5.809, -6.2417, -6.846, -6.3738, -4.4097, -5.0488, -6.3733, -5.4881, -5.7292, -6.3821, -5.8964, -6.1001, -5.3238, -6.273, -5.7029, -5.5557, -5.8397, -5.7486, -4.7997, -5.5477, -5.7632, -5.8363, -5.1081, -5.3013, -5.1265, -5.6031, -5.6549, -5.7301, -5.1854, -5.3895, -5.5669, -5.4343, -5.598, -5.5306, -5.6536, -5.7369, -8.8085, -9.692, -10.2559, -9.5317, -9.5736, -9.9878, -8.2223, -10.3181, -7.5925, -10.3316, -10.0219, -9.7781, -9.3653, -9.4077, -10.0946, -8.9797, -8.8057, -10.777, -8.9491, -8.911, -9.8158, -8.8663, -9.5191, -9.1115, -10.3624, -10.3924, -9.5873, -9.4418, -8.4111, -9.8571, -6.7883, -8.8849, -7.8199, -7.3393, -5.924, -6.1977, -6.3217, -8.0848, -8.3817, -7.2858, -8.8955, -5.416, -5.635, -5.2214, -5.9708, -7.3732, -5.2219, -5.6182, -6.1684, -5.6219, -6.07, -7.1903, -5.9265, -5.3647, -5.4872, -6.1597, -5.667, -5.7346, -5.9876, -5.668, -5.1993, -4.5759, -4.9751, -5.2525, -5.7222, -5.8795, -5.322, -5.205, -5.5684, -4.8997, -5.5168, -5.6103, -5.2031, -5.619, -5.4671, -5.7215, -5.3354, -5.4399, -5.6193, -5.7759, -8.5862, -8.9024, -9.7652, -8.2456, -9.7608, -8.7655, -8.8001, -8.9119, -7.8746, -10.1223, -9.8545, -7.7972, -10.181, -10.227, -9.046, -10.2211, -9.4889, -10.5988, -10.1916, -10.162, -10.2751, -9.6983, -9.377, -10.2201, -10.282, -9.2516, -9.7337, -9.3712, -9.9564, -7.653, -8.841, -7.9034, -8.8902, -8.5387, -8.6773, -8.267, -8.5851, -6.3813, -5.266, -7.5449, -5.9629, -6.496, -7.4337, -4.8621, -4.7179, -7.6116, -5.1754, -6.2375, -7.087, -4.8645, -5.6554, -6.0418, -5.5355, -6.1067, -5.4718, -5.7672, -5.871, -5.5874, -5.5044, -5.6186, -5.1867, -4.7858, -5.789, -5.7249, -5.705, -5.6962, -5.5631, -5.6108, -5.842, -5.4537, -5.4748, -4.8305, -5.657, -5.8148, -5.4727, -5.4171, -5.403, -5.6573, -5.6146, -5.7122, -5.7347, -7.9748, -8.9016, -9.3535, -7.3421, -9.5297, -9.3678, -8.7834, -9.0485, -8.9923, -10.4176, -8.7372, -10.1009, -9.3326, -10.8164, -10.435, -9.6969, -10.4185, -10.4356, -10.1497, -8.5067, -8.9964, -9.4804, -9.355, -9.7981, -8.1504, -7.7887, -9.011, -9.9866, -8.2238, -10.5259, -6.9867, -9.1991, -6.2767, -7.7192, -6.9009, -5.3872, -5.3375, -7.3293, -6.5308, -4.8442, -7.4192, -6.5637, -4.7771, -7.2196, -6.3771, -4.3291, -6.2332, -6.0736, -6.1499, -5.845, -5.6929, -5.4592, -5.0497, -6.6817, -5.2722, -5.5587, -5.3458, -5.4053, -4.9087, -5.3523, -5.8062, -5.7373, -5.7118, -5.4432, -5.2779, -5.5151, -5.2938, -5.847, -5.7576, -5.0433, -5.9623, -5.2683, -5.8211, -5.5403, -5.8881, -5.7438, -5.7454, -5.8006, -8.5451, -6.418, -7.7118, -8.6996, -8.6269, -8.8844, -8.8829, -9.246, -7.8439, -8.8241, -8.9505, -9.5604, -7.7441, -6.5464, -8.6431, -9.176, -9.3673, -9.9039, -9.0403, -9.9459, -9.9683, -9.9622, -10.4124, -10.0081, -9.1754, -10.4206, -10.4426, -10.4508, -10.4554, -10.4533, -8.4865, -5.4404, -8.2588, -6.8529, -8.9707, -8.146, -4.1495, -5.2014, -5.7964, -5.2454, -7.6489, -5.7077, -7.4259, -5.8218, -4.8846, -5.7853, -6.3221, -5.3309, -4.7856, -5.341, -5.0647, -6.6736, -5.6914, -5.6177, -5.1913, -5.8755, -5.2453, -5.6635, -5.0839, -5.2979, -5.5855, -5.4281, -5.6939, -5.6899, -5.3899, -5.6145, -5.5076, -5.6528, -5.6826, -5.7519, -5.7967, -7.0554, -8.4555, -8.8338, -9.4584, -8.2512, -7.6978, -10.0225, -9.5073, -10.0618, -8.5961, -10.0686, -7.0758, -9.3167, -8.2458, -9.819, -10.538, -10.1382, -9.8355, -9.1968, -10.131, -9.823, -9.4225, -8.9316, -9.8627, -9.427, -10.1627, -9.8875, -9.294, -8.6055, -10.164, -6.0595, -7.6986, -6.8041, -8.6237, -8.7352, -8.7409, -9.0993, -8.0232, -6.9845, -7.3399, -4.4093, -8.8993, -5.1413, -5.6528, -8.7835, -5.5839, -5.6379, -6.684, -4.845, -5.4171, -5.5316, -5.193, -5.5417, -5.6965, -5.0283, -5.4426, -5.3873, -6.0869, -4.6894, -5.2749, -5.1034, -5.2775, -5.5648, -6.1947, -5.879, -5.79, -5.9071, -5.6015, -5.698, -5.8102, -5.4853, -5.5794, -5.705, -5.4967, -5.817, -5.8493, -5.8013, -5.8479], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8212, 0.7903, 0.7746, 0.7258, 0.7125, 0.7119, 0.6814, 0.6787, 0.6744, 0.672, 0.6686, 0.6634, 0.6633, 0.6633, 0.653, 0.6482, 0.6385, 0.622, 0.6212, 0.613, 0.61, 0.6096, 0.6019, 0.5986, 0.5953, 0.5939, 0.5934, 0.5906, 0.5875, 0.5809, 0.5604, 0.5172, 0.5469, 0.5157, 0.5365, 0.3917, 0.5345, 0.3774, 0.4329, 0.3177, 0.4742, 0.5221, 0.3081, 0.3822, 0.3595, 0.4241, 0.3617, 0.222, 0.3278, 0.3171, 0.4044, 0.2915, 0.1012, 0.1513, 0.2694, 0.3698, 0.1855, 0.1414, 0.2594, 0.3308, 0.2786, 0.076, 0.1334, 0.0187, 0.13, 0.0842, 0.0816, 0.1798, 0.1777, -0.2055, -0.1009, 0.1094, -0.0477, 0.0139, 0.1649, 0.0678, -0.2244, 0.0298, -0.0018, -0.0219, 0.1354, 0.0138, -0.0376, -0.1014, -0.2197, -0.0705, 0.8106, 0.7674, 0.7664, 0.7417, 0.7021, 0.6928, 0.6805, 0.6776, 0.6733, 0.6651, 0.642, 0.6414, 0.6403, 0.6399, 0.635, 0.6324, 0.6144, 0.613, 0.6086, 0.6028, 0.6003, 0.5996, 0.5929, 0.5898, 0.5882, 0.5877, 0.5873, 0.5872, 0.5871, 0.5858, 0.5812, 0.5855, 0.5496, 0.5689, 0.5694, 0.5541, 0.5391, 0.5398, 0.5607, 0.4213, 0.5373, 0.5214, 0.538, 0.373, 0.4218, 0.3236, 0.3684, 0.3129, 0.2075, 0.2651, 0.3081, 0.3842, 0.285, 0.4537, 0.2706, 0.2198, 0.24, 0.2952, 0.2251, 0.2934, -0.0225, 0.197, 0.2977, 0.0621, 0.1434, 0.1146, 0.1347, 0.1019, 0.1447, 0.1695, 0.0493, -0.0185, 0.0848, -0.0613, 0.0659, 0.1245, -0.0368, -0.1146, -0.1275, -0.3079, -0.2376, -0.0747, -0.4247, -0.2177, -0.2203, -0.1046, -0.339, 0.917, 0.8793, 0.8705, 0.8641, 0.8464, 0.8306, 0.8138, 0.8041, 0.7783, 0.777, 0.7753, 0.7738, 0.773, 0.7577, 0.7501, 0.7356, 0.7345, 0.7344, 0.7302, 0.7204, 0.7179, 0.7134, 0.7029, 0.7021, 0.7019, 0.6941, 0.6934, 0.6889, 0.6838, 0.6831, 0.662, 0.6121, 0.5883, 0.5964, 0.6156, 0.565, 0.6176, 0.6439, 0.5087, 0.3089, 0.5674, 0.3987, 0.3533, 0.425, 0.1454, 0.2735, 0.3061, 0.2807, 0.1717, 0.384, 0.1574, 0.5104, 0.2983, 0.404, 0.2704, 0.1795, 0.1968, 0.1327, 0.27, 0.2686, 0.1997, 0.0576, 0.1852, 0.1996, -0.0325, 0.0346, 0.1684, 0.0588, 0.0775, 0.0938, 0.0097, -0.044, 0.052, -0.2129, 0.116, 0.0797, -0.044, 0.0439, -0.0755, -0.1773, 0.038, 0.0178, -0.4464, 1.237, 1.1969, 1.1333, 1.0537, 1.0115, 1.0013, 0.9913, 0.9883, 0.987, 0.9778, 0.9744, 0.9714, 0.971, 0.9609, 0.9495, 0.9422, 0.9359, 0.9305, 0.925, 0.9135, 0.9009, 0.8931, 0.8914, 0.8814, 0.8668, 0.8473, 0.8442, 0.8421, 0.8366, 0.828, 0.819, 0.8143, 0.7726, 0.7432, 0.7474, 0.5622, 0.5792, 0.5408, 0.6989, 0.6975, 0.3322, 0.2109, 0.2236, 0.3731, 0.5797, 0.1282, 0.2412, 0.3934, 0.2304, 0.145, 0.1425, 0.213, 0.2044, 0.0441, 0.2347, 0.1298, 0.2148, -0.1086, 0.103, 0.0864, 0.0602, 0.1266, 0.0154, -0.0475, 0.0238, 0.0488, -0.1747, -0.1042, -0.0141, -0.0508, -0.1671, 0.0314, 0.0468, -0.2345, -0.2351, -0.1388, 0.8376, 0.8145, 0.8021, 0.7667, 0.7493, 0.7372, 0.7324, 0.7297, 0.688, 0.688, 0.6864, 0.6741, 0.6613, 0.6505, 0.648, 0.6366, 0.6316, 0.626, 0.6236, 0.6148, 0.6103, 0.6068, 0.6027, 0.5945, 0.5924, 0.5873, 0.5835, 0.5828, 0.5757, 0.5734, 0.5597, 0.5424, 0.5619, 0.4906, 0.5197, 0.5498, 0.3805, 0.5326, 0.3562, 0.4734, 0.332, 0.3134, 0.282, 0.3868, 0.2887, 0.3622, 0.2694, 0.3062, 0.3241, 0.3868, 0.3236, 0.0526, 0.117, 0.3124, 0.1782, 0.2135, 0.3056, 0.2129, 0.2478, 0.0993, 0.2765, 0.1602, 0.1188, 0.1806, 0.1571, -0.0823, 0.093, 0.1429, 0.1619, -0.0683, -0.0324, -0.1286, 0.0202, 0.0334, 0.0527, -0.2446, -0.1467, -0.0674, -0.2545, -0.1055, -0.1994, -0.0985, 0.0349, 0.9784, 0.9562, 0.9263, 0.9094, 0.8835, 0.8676, 0.8656, 0.8576, 0.8564, 0.8476, 0.8471, 0.8466, 0.8394, 0.8332, 0.8255, 0.8228, 0.8181, 0.8135, 0.8129, 0.8033, 0.7899, 0.7856, 0.78, 0.7797, 0.7763, 0.7746, 0.7741, 0.7736, 0.7723, 0.7711, 0.743, 0.7521, 0.7025, 0.6629, 0.5742, 0.5684, 0.4749, 0.6467, 0.6677, 0.5528, 0.7169, 0.3273, 0.3521, 0.2781, 0.3628, 0.5377, 0.2317, 0.2879, 0.3493, 0.243, 0.3005, 0.475, 0.251, 0.1278, 0.1362, 0.2733, 0.1628, 0.1712, 0.2216, 0.1465, 0.0435, -0.1137, -0.0342, 0.0165, 0.1408, 0.1757, 0.0092, -0.0391, 0.0722, -0.1823, 0.0395, 0.0643, -0.1633, 0.0473, -0.044, 0.0728, -0.3376, -0.26, -0.0643, -0.1097, 1.2627, 1.1415, 1.131, 1.1292, 1.1204, 1.1166, 1.085, 1.0717, 1.0647, 1.0535, 1.044, 1.042, 1.0417, 1.0165, 1.0149, 1.0145, 0.9993, 0.9938, 0.9843, 0.9693, 0.9688, 0.965, 0.9609, 0.9576, 0.9576, 0.949, 0.9469, 0.9466, 0.9418, 0.9399, 0.9368, 0.9047, 0.9186, 0.9006, 0.9042, 0.8691, 0.8491, 0.6341, 0.4879, 0.7296, 0.5431, 0.6074, 0.7004, 0.3038, 0.28, 0.6948, 0.2947, 0.4482, 0.5909, 0.1754, 0.3259, 0.3528, 0.2364, 0.3598, 0.2165, 0.2531, 0.2733, 0.1954, 0.1701, 0.1869, 0.0561, -0.0684, 0.2054, 0.1808, 0.1429, 0.1183, 0.0602, 0.0554, 0.1492, -0.0306, -0.0212, -0.3683, 0.0092, 0.1279, -0.1415, -0.2372, -0.4622, -0.1648, -0.3456, -0.1572, -0.1785, 0.9759, 0.898, 0.8619, 0.8618, 0.822, 0.8006, 0.7944, 0.7797, 0.7782, 0.764, 0.7639, 0.7637, 0.7551, 0.7544, 0.7515, 0.7423, 0.7411, 0.7315, 0.7314, 0.7228, 0.7226, 0.7194, 0.7181, 0.7156, 0.7156, 0.7037, 0.6991, 0.6924, 0.6897, 0.6889, 0.6821, 0.6718, 0.5198, 0.5853, 0.527, 0.4274, 0.421, 0.5372, 0.4762, 0.3356, 0.5203, 0.4261, 0.2208, 0.4868, 0.3891, 0.1332, 0.3666, 0.3447, 0.3484, 0.2875, 0.2498, 0.207, 0.1161, 0.4013, 0.1509, 0.1886, 0.1467, 0.151, 0.0321, 0.1013, 0.1881, 0.1684, 0.1513, 0.0563, -0.0089, 0.04, -0.051, 0.1343, 0.0722, -0.3259, 0.1673, -0.2284, 0.0849, -0.2092, 0.0989, -0.0692, -0.1047, -0.1773, 1.8109, 1.7161, 1.7124, 1.6344, 1.5771, 1.5556, 1.5522, 1.5252, 1.4823, 1.4808, 1.4719, 1.4354, 1.4226, 1.4197, 1.3904, 1.3869, 1.3757, 1.353, 1.3402, 1.3049, 1.2977, 1.2973, 1.2478, 1.2391, 1.2388, 1.2379, 1.2038, 1.1983, 1.1974, 1.1931, 1.1836, 1.0656, 1.122, 1.0482, 1.1414, 0.9794, 0.3128, 0.4393, 0.5439, 0.4208, 0.8629, 0.4074, 0.8084, 0.4062, 0.1133, 0.359, 0.4745, 0.1686, -0.0682, 0.1125, -0.0249, 0.5426, 0.1761, 0.1408, -0.0254, 0.2223, -0.0654, 0.1193, -0.1431, -0.0551, 0.0808, -0.005, 0.1116, 0.082, -0.121, -0.0582, -0.1764, -0.0978, -0.0592, -0.0774, 0.0331, 1.4332, 1.4037, 1.2716, 1.2457, 1.2246, 1.1954, 1.195, 1.1804, 1.1656, 1.1526, 1.1448, 1.1408, 1.1375, 1.129, 1.1018, 1.0752, 1.0743, 1.074, 1.0697, 1.0693, 1.0603, 1.054, 1.0527, 1.0489, 1.0464, 1.0425, 1.032, 1.031, 1.0282, 1.0248, 1.0074, 1.0226, 0.9892, 1.0202, 0.9866, 0.986, 1.0054, 0.9162, 0.7644, 0.7545, 0.3081, 0.9654, 0.3123, 0.3492, 0.9368, 0.3218, 0.3193, 0.5322, 0.1529, 0.2491, 0.2627, 0.1382, 0.2122, 0.2096, 0.0115, 0.1125, 0.0829, 0.2546, -0.2271, -0.0321, -0.1626, -0.0976, -0.0086, 0.2571, 0.1024, 0.0154, 0.0774, -0.109, -0.0573, 0.0044, -0.2164, -0.1562, -0.0817, -0.3309, -0.0452, -0.0195, -0.3018, -0.1046]}, \"token.table\": {\"Topic\": [2, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 10, 2, 3, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 10, 1, 2, 4, 1, 2, 3, 4, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 2, 3, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 1, 2, 1, 2, 3, 4, 5, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 9, 1, 2, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 9, 1, 3, 4, 10, 1, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 7, 10, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 2, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 5, 9, 2, 3, 5, 7, 9, 1, 2, 3, 4, 5, 6, 8, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 10, 1, 4, 1, 2, 3, 4, 5, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 7, 1, 2, 3, 5, 2, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 8, 1, 3, 4, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 5, 6, 1, 3, 6, 1, 2, 3, 4, 6, 8, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 10, 1, 2, 7, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 1, 2, 4, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 9, 1, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 1, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 7, 9, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 8, 2, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 1, 2, 4, 6, 8, 9, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 4, 5, 6, 8, 9, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 7, 1, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 6, 1, 2, 3, 4, 5, 7, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 9, 10, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 7, 9, 2, 3, 4, 5, 7, 9, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 8, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 3, 3, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 7, 1, 2, 3, 4, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 1, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 1, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 7, 9, 1, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 7, 10, 1, 2, 3, 4, 5, 7, 8, 10, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 2, 3, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 5, 2, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 5, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 4, 10, 2, 6, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 10, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 7], \"Freq\": [0.28547935668095287, 0.28547935668095287, 0.28547935668095287, 0.19676872312810903, 0.16682565656513593, 0.1368825900021628, 0.08982919968891934, 0.14971533281486557, 0.05988613312594623, 0.0684412950010814, 0.04277580937567588, 0.05560855218837864, 0.03849822843810829, 0.14281150824228772, 0.18565496071497406, 0.1570926590665165, 0.16780352218468808, 0.09282748035748703, 0.06783546641508667, 0.053554315590857896, 0.03927316476662913, 0.05712460329691509, 0.03570287706057193, 0.16068696654208922, 0.21424928872278562, 0.13390580545174102, 0.10712464436139281, 0.06695290272587051, 0.13390580545174102, 0.08034348327104461, 0.053562322180696405, 0.026781161090348202, 0.040171741635522305, 0.1849347542916416, 0.2774021314374624, 0.10567700245236662, 0.05944331387945623, 0.12549144041218538, 0.10567700245236662, 0.019814437959818743, 0.05283850122618331, 0.039628875919637485, 0.03302406326636457, 0.16300607886570456, 0.16300607886570456, 0.16300607886570456, 0.16300607886570456, 0.16300607886570456, 0.16300607886570456, 0.07733325109192427, 0.3866662554596213, 0.15466650218384853, 0.07733325109192427, 0.07733325109192427, 0.07733325109192427, 0.07733325109192427, 0.07733325109192427, 0.2514217365164765, 0.2514217365164765, 0.2514217365164765, 0.2514217365164765, 0.08863416719639389, 0.19696481599198642, 0.20681305679158574, 0.06893768559719525, 0.12802713039479116, 0.15757185279358912, 0.049241203997996606, 0.029544722398797962, 0.029544722398797962, 0.03939296319839728, 0.5348868633844334, 0.1836518872189367, 0.1836518872189367, 0.1836518872189367, 0.1836518872189367, 0.16268292533497414, 0.3253658506699483, 0.10845528355664943, 0.10845528355664943, 0.10845528355664943, 0.02711382088916236, 0.02711382088916236, 0.05422764177832472, 0.05422764177832472, 0.05422764177832472, 0.20632932299654616, 0.13755288199769744, 0.06877644099884872, 0.3438822049942436, 0.06877644099884872, 0.06877644099884872, 0.06877644099884872, 0.2537978767782795, 0.2537978767782795, 0.2537978767782795, 0.17334645325467318, 0.17334645325467318, 0.17334645325467318, 0.34669290650934637, 0.23129295410527553, 0.23129295410527553, 0.23129295410527553, 0.1829259604790464, 0.1876772841278528, 0.1330370621665792, 0.10452912027374081, 0.1330370621665792, 0.0807725020297088, 0.0641428692588864, 0.057015883785676805, 0.030883603717241602, 0.026132280068435203, 0.21015613155064586, 0.4203122631012917, 0.21015613155064586, 0.21071380029116596, 0.16918626300750553, 0.10766398555023078, 0.13381095346957256, 0.12150649797811759, 0.07997896069445715, 0.06613644826657034, 0.04614170809295605, 0.03845142341079671, 0.026146967919341763, 0.1277920122293401, 0.1277920122293401, 0.06389600611467006, 0.38337603668802034, 0.06389600611467006, 0.06389600611467006, 0.06389600611467006, 0.33449451875190755, 0.11205732617475084, 0.22411465234950168, 0.11205732617475084, 0.11205732617475084, 0.16808598926212626, 0.05602866308737542, 0.05602866308737542, 0.05602866308737542, 0.05602866308737542, 0.05602866308737542, 0.12966898498625576, 0.22692072372594757, 0.06483449249312788, 0.22692072372594757, 0.09725173873969181, 0.06483449249312788, 0.06483449249312788, 0.06483449249312788, 0.03241724624656394, 0.03241724624656394, 0.21388255990645905, 0.17706670943075709, 0.129732044533426, 0.1104475514271059, 0.10343500847935315, 0.07538483668834212, 0.06837229374058937, 0.04382839342345472, 0.04558152916039291, 0.03330957900182559, 0.24242928644546152, 0.10475339537766856, 0.10176044122402089, 0.12570407445320228, 0.12570407445320228, 0.08380271630213484, 0.053873174765658116, 0.053873174765658116, 0.07183089968754415, 0.035915449843772075, 0.17105644471301984, 0.17105644471301984, 0.0997829260825949, 0.14254703726084986, 0.14254703726084986, 0.028509407452169972, 0.08552822235650992, 0.028509407452169972, 0.11403762980867989, 0.028509407452169972, 0.21154031295769657, 0.21154031295769657, 0.21154031295769657, 0.3673798113854122, 0.11576778192829085, 0.2315355638565817, 0.09647315160690904, 0.07717852128552723, 0.13506241224967266, 0.09647315160690904, 0.07717852128552723, 0.11576778192829085, 0.019294630321381807, 0.019294630321381807, 0.1873422541686504, 0.17396066458517537, 0.15017117199233088, 0.10110534351958911, 0.11894746296422247, 0.08028953750085017, 0.04757898518568899, 0.04460529861158343, 0.06393426134326959, 0.0312237090281084, 0.12909943240532457, 0.12909943240532457, 0.12909943240532457, 0.12909943240532457, 0.12909943240532457, 0.12909943240532457, 0.12909943240532457, 0.12909943240532457, 0.02625125145731641, 0.2362612631158477, 0.13125625728658205, 0.18375876020121487, 0.21001001165853128, 0.05250250291463282, 0.05250250291463282, 0.02625125145731641, 0.10500500582926564, 0.02625125145731641, 0.27446653495747125, 0.16167206853659266, 0.1127944664208786, 0.10903465087351598, 0.09023557313670288, 0.0939953886840655, 0.04511778656835144, 0.04135797102098882, 0.03383833992626358, 0.04135797102098882, 0.20947683371694914, 0.2862850060798305, 0.11172097798237288, 0.10473841685847457, 0.11870353910627118, 0.04887792786728813, 0.04189536674338983, 0.020947683371694916, 0.02793024449559322, 0.020947683371694916, 0.22201993047367777, 0.22201993047367777, 0.22201993047367777, 0.27054618749296727, 0.1664899615341337, 0.11000229601362405, 0.08919105082185734, 0.10405622595883356, 0.1070292609862288, 0.04459552541092867, 0.03864945535613818, 0.0267573152465572, 0.041622490383533425, 0.215931511312688, 0.17274520905015042, 0.14395434087512535, 0.10076803861258773, 0.07197717043756267, 0.1295589067876128, 0.057581736350050136, 0.07197717043756267, 0.028790868175025068, 0.028790868175025068, 0.2019815603448991, 0.4039631206897982, 0.2019815603448991, 0.5174983355104272, 0.12024439589777232, 0.12024439589777232, 0.12024439589777232, 0.12024439589777232, 0.12024439589777232, 0.12024439589777232, 0.12024439589777232, 0.31777318511920816, 0.10592439503973607, 0.07061626335982404, 0.07061626335982404, 0.07061626335982404, 0.07061626335982404, 0.1412325267196481, 0.03530813167991202, 0.03530813167991202, 0.03530813167991202, 0.12519488197201095, 0.2503897639440219, 0.18779232295801643, 0.06259744098600548, 0.12519488197201095, 0.06259744098600548, 0.06259744098600548, 0.12519488197201095, 0.14904856628108726, 0.14904856628108726, 0.2235728494216309, 0.07452428314054363, 0.14904856628108726, 0.07452428314054363, 0.07452428314054363, 0.07452428314054363, 0.2682302097818976, 0.1788201398545984, 0.2682302097818976, 0.0894100699272992, 0.0894100699272992, 0.0894100699272992, 0.2073819318306863, 0.20052633077843218, 0.11654521788831956, 0.11140351709912899, 0.11483131762525604, 0.07369771131173149, 0.06855601052254091, 0.0377058057873975, 0.04627530710271512, 0.025708503945952844, 0.1368365922676979, 0.1254335429120564, 0.1368365922676979, 0.1710457403346224, 0.07982134548949044, 0.09122439484513194, 0.10262744420077342, 0.057015246778207455, 0.034209148066924475, 0.04561219742256597, 0.2227788915096197, 0.17247398052357654, 0.14372831710298045, 0.07186415855149023, 0.10779623782723534, 0.07186415855149023, 0.043118495130894136, 0.043118495130894136, 0.07186415855149023, 0.05749132684119218, 0.2131432938383686, 0.3410292701413898, 0.12788597630302118, 0.12788597630302118, 0.04262865876767372, 0.02131432938383686, 0.06394298815151059, 0.04262865876767372, 0.02131432938383686, 0.37354528017798583, 0.13444997536524364, 0.2539610645787935, 0.22408329227540605, 0.07469443075846868, 0.17926663382032484, 0.029877772303387475, 0.014938886151693738, 0.029877772303387475, 0.029877772303387475, 0.014938886151693738, 0.14790443554220428, 0.14790443554220428, 0.29580887108440856, 0.14790443554220428, 0.14790443554220428, 0.25415038078493757, 0.15249022847096252, 0.25415038078493757, 0.10166015231397502, 0.05083007615698751, 0.05083007615698751, 0.05083007615698751, 0.05083007615698751, 0.05083007615698751, 0.1686135210821657, 0.15892308883606424, 0.13566605144542068, 0.11047092760555685, 0.1259756191993192, 0.08915197666413359, 0.06783302572271034, 0.06008067992582916, 0.03876172898440591, 0.04651407478128709, 0.2166420437074999, 0.14855454425657136, 0.1237954535471428, 0.11141590819242853, 0.09284659016035711, 0.09284659016035711, 0.049518181418857124, 0.049518181418857124, 0.024759090709428562, 0.09284659016035711, 0.3767810417305358, 0.20416043946078824, 0.20416043946078824, 0.20416043946078824, 0.20416043946078824, 0.11353122830833892, 0.2532619708416791, 0.1659302567583415, 0.10916464260417205, 0.10916464260417205, 0.08733171408333763, 0.061132199858336345, 0.0480324427458357, 0.026199514225001292, 0.026199514225001292, 0.15673662270941158, 0.2711119960379011, 0.15250049777131935, 0.08048637382375189, 0.14826437283322716, 0.05506962419519866, 0.05083349925710645, 0.03812512444282984, 0.02965287456664543, 0.021180624690461024, 0.14816081513314963, 0.3704020378328741, 0.14816081513314963, 0.07408040756657482, 0.07408040756657482, 0.07408040756657482, 0.07408040756657482, 0.07408040756657482, 0.07408040756657482, 0.14438000284153654, 0.25150065011106365, 0.12575032505553183, 0.10246322782302593, 0.13972258339503538, 0.051231613911512965, 0.06520387225101651, 0.055889033358014144, 0.04191677501851061, 0.018629677786004717, 0.3450673451461385, 0.17892380859429405, 0.11502244838204619, 0.08946190429714702, 0.0511210881697983, 0.06390136021224788, 0.03834081612734873, 0.03834081612734873, 0.03834081612734873, 0.02556054408489915, 0.3724273349497642, 0.09310683373744105, 0.09310683373744105, 0.09310683373744105, 0.09310683373744105, 0.09310683373744105, 0.1862136674748821, 0.10106850765775659, 0.15160276148663487, 0.15160276148663487, 0.10106850765775659, 0.15160276148663487, 0.050534253828878294, 0.10106850765775659, 0.050534253828878294, 0.15160276148663487, 0.050534253828878294, 0.017994707847871584, 0.1079682470872295, 0.14395766278297267, 0.08997353923935791, 0.2339312020223306, 0.017994707847871584, 0.1079682470872295, 0.2339312020223306, 0.017994707847871584, 0.16134718665196027, 0.16134718665196027, 0.08067359332598013, 0.08067359332598013, 0.16134718665196027, 0.08067359332598013, 0.08067359332598013, 0.08067359332598013, 0.1543782740809581, 0.3259096897264671, 0.18868455721005992, 0.0857657078227545, 0.0514594246936527, 0.0686125662582036, 0.0343062831291018, 0.0343062831291018, 0.0343062831291018, 0.0171531415645509, 0.24448807320616978, 0.16638771648753223, 0.135826707336761, 0.11205703355282783, 0.09168302745231367, 0.050935015251285375, 0.0814960244020566, 0.04753934756786635, 0.0407480122010283, 0.030561009150771222, 0.2513885369624624, 0.1256942684812312, 0.0628471342406156, 0.2513885369624624, 0.1256942684812312, 0.0314235671203078, 0.0314235671203078, 0.0628471342406156, 0.0314235671203078, 0.1751147007878998, 0.19298354780707327, 0.150098314961057, 0.11436062092271009, 0.10006554330737133, 0.10721308211504071, 0.05718031046135504, 0.04288523284601628, 0.03216392463451221, 0.03216392463451221, 0.1843756742071739, 0.1843756742071739, 0.3687513484143478, 0.21326244192978341, 0.21326244192978341, 0.21326244192978341, 0.21326244192978341, 0.21505544987232314, 0.16965485489927715, 0.11469623993190567, 0.08602217994892926, 0.14814930991204484, 0.07407465495602242, 0.06451663496169693, 0.04301108997446463, 0.06212712996311557, 0.02628455498439505, 0.3106017076259014, 0.2277745855923277, 0.04141356101678685, 0.04141356101678685, 0.0828271220335737, 0.0828271220335737, 0.12424068305036055, 0.06212034152518028, 0.020706780508393426, 0.020706780508393426, 0.3571497371557499, 0.08928743428893747, 0.17857486857787494, 0.08928743428893747, 0.08928743428893747, 0.08928743428893747, 0.08928743428893747, 0.31585288992303984, 0.31585288992303984, 0.1827770829734671, 0.1370828122301003, 0.13200567103639288, 0.19800850655458935, 0.1066199650678558, 0.07615711790561129, 0.04569427074336677, 0.035539988355951936, 0.04569427074336677, 0.035539988355951936, 0.1886923794337502, 0.12579491962250014, 0.0943461897168751, 0.2830385691506253, 0.0943461897168751, 0.0943461897168751, 0.031448729905625035, 0.031448729905625035, 0.031448729905625035, 0.031448729905625035, 0.11069902482448808, 0.11069902482448808, 0.22139804964897616, 0.11069902482448808, 0.11069902482448808, 0.11069902482448808, 0.11069902482448808, 0.11069902482448808, 0.18802171532531056, 0.12534781021687372, 0.12534781021687372, 0.12534781021687372, 0.18802171532531056, 0.06267390510843686, 0.06267390510843686, 0.06267390510843686, 0.06267390510843686, 0.06267390510843686, 0.2871104563311339, 0.14524411320280892, 0.1080886423834857, 0.09795533216003391, 0.11484418253245356, 0.07431094163864642, 0.05742209126622678, 0.047288781042774994, 0.03715547081932321, 0.03377770074483928, 0.20949498866365224, 0.13966332577576815, 0.2793266515515363, 0.06983166288788407, 0.13966332577576815, 0.13966332577576815, 0.2564667263627977, 0.2564667263627977, 0.1292103023510985, 0.1292103023510985, 0.1292103023510985, 0.1292103023510985, 0.1292103023510985, 0.1292103023510985, 0.1292103023510985, 0.13616590150609376, 0.18155453534145835, 0.09077726767072918, 0.13616590150609376, 0.18155453534145835, 0.09077726767072918, 0.04538863383536459, 0.04538863383536459, 0.04538863383536459, 0.04538863383536459, 0.2760360598329216, 0.2760360598329216, 0.3606081086724391, 0.15454633228818818, 0.15454633228818818, 0.05151544409606273, 0.05151544409606273, 0.05151544409606273, 0.05151544409606273, 0.05151544409606273, 0.05151544409606273, 0.10365457665086823, 0.20730915330173647, 0.10365457665086823, 0.10365457665086823, 0.10365457665086823, 0.20730915330173647, 0.10365457665086823, 0.3713384514724479, 0.09283461286811197, 0.09283461286811197, 0.09283461286811197, 0.09283461286811197, 0.09283461286811197, 0.09283461286811197, 0.09283461286811197, 0.13888624303459315, 0.13888624303459315, 0.13888624303459315, 0.2777724860691863, 0.06944312151729658, 0.06944312151729658, 0.06944312151729658, 0.17761926235069359, 0.17761926235069359, 0.09769059429288147, 0.11545252052795082, 0.1243334836454855, 0.07104770494027743, 0.06216674182274275, 0.08880963117534679, 0.05328577870520808, 0.02664288935260404, 0.20412307253674086, 0.1940842329037864, 0.11042723596249916, 0.11711979571780214, 0.09034955669659023, 0.07696443718598427, 0.06692559755302979, 0.05354047804242384, 0.04350163840946937, 0.04350163840946937, 0.22321460932205367, 0.17632078383422728, 0.1706935247756881, 0.10410429258297461, 0.08347100936833099, 0.058148343604904736, 0.04408019595855682, 0.0703407382317396, 0.03845293690001765, 0.030012048312208897, 0.10762630291406645, 0.1614394543710997, 0.10762630291406645, 0.2152526058281329, 0.10762630291406645, 0.05381315145703323, 0.10762630291406645, 0.10762630291406645, 0.05381315145703323, 0.05381315145703323, 0.08779283392870732, 0.08779283392870732, 0.08779283392870732, 0.17558566785741464, 0.08779283392870732, 0.08779283392870732, 0.08779283392870732, 0.08779283392870732, 0.12445440934406504, 0.18668161401609756, 0.12445440934406504, 0.18668161401609756, 0.12445440934406504, 0.06222720467203252, 0.18668161401609756, 0.06222720467203252, 0.12290142028789777, 0.2918908731837572, 0.15362677535987224, 0.10753874275191055, 0.16898945289585945, 0.07681338767993612, 0.015362677535987222, 0.015362677535987222, 0.030725355071974443, 0.030725355071974443, 0.09232085647870704, 0.33235508332334535, 0.11078502777444844, 0.11078502777444844, 0.14771337036593127, 0.07385668518296563, 0.03692834259148282, 0.01846417129574141, 0.03692834259148282, 0.01846417129574141, 0.24556251783877642, 0.16289790787324773, 0.10697773054362537, 0.10697773054362537, 0.1118403546592447, 0.07050804967648036, 0.05592017732962235, 0.06564542556086102, 0.03890099292495468, 0.03403836880933535, 0.13006112407465872, 0.13006112407465872, 0.13006112407465872, 0.13006112407465872, 0.13006112407465872, 0.13006112407465872, 0.13006112407465872, 0.08209643075456846, 0.32838572301827385, 0.08209643075456846, 0.08209643075456846, 0.16419286150913692, 0.08209643075456846, 0.08209643075456846, 0.15764546681860245, 0.20268702876677455, 0.1801662477926885, 0.09008312389634425, 0.07882273340930122, 0.12386429535747334, 0.045041561948172125, 0.05630195243521516, 0.045041561948172125, 0.03378117146112909, 0.19023763180083764, 0.1556489714734126, 0.1556489714734126, 0.10376598098227507, 0.10376598098227507, 0.08647165081856256, 0.05188299049113754, 0.05188299049113754, 0.034588660327425025, 0.06917732065485005, 0.19892771025038627, 0.25147465258067697, 0.10134053163698924, 0.14638076792009555, 0.08632711954262046, 0.05630029535388291, 0.04879358930669852, 0.04879358930669852, 0.033780177212329746, 0.026273471165145355, 0.21839646713463795, 0.21839646713463795, 0.21839646713463795, 0.21877351437112455, 0.19054467380710846, 0.19054467380710846, 0.08468652169204821, 0.1199725723970683, 0.05645768112803214, 0.04940047098702812, 0.03528605070502009, 0.03528605070502009, 0.03528605070502009, 0.31022273101660236, 0.26940395061968103, 0.06531004863507418, 0.06531004863507418, 0.05714629255568991, 0.04898253647630564, 0.07347380471445845, 0.06531004863507418, 0.02449126823815282, 0.02449126823815282, 0.41434799672719363, 0.10358699918179841, 0.051793499590899204, 0.051793499590899204, 0.10358699918179841, 0.051793499590899204, 0.10358699918179841, 0.051793499590899204, 0.051793499590899204, 0.21742366387472908, 0.21742366387472908, 0.12032183340640347, 0.09499092111031854, 0.11398910533238224, 0.059105462024198197, 0.06543819009821944, 0.04855091523416281, 0.040107277802134494, 0.025330912296084942, 0.2772512819395708, 0.2772512819395708, 0.2772512819395708, 0.2621396500277569, 0.08737988334258563, 0.17475976668517126, 0.08737988334258563, 0.08737988334258563, 0.17475976668517126, 0.08737988334258563, 0.08737988334258563, 0.22594322085561389, 0.14976807782429263, 0.14331255722841793, 0.11490826660656935, 0.10070612129564505, 0.09941501717647011, 0.04002422769442303, 0.05293526888617239, 0.04906195652864758, 0.02453097826432379, 0.20790017385700052, 0.20790017385700052, 0.20790017385700052, 0.10155722325327404, 0.20311444650654809, 0.20311444650654809, 0.10155722325327404, 0.10155722325327404, 0.10155722325327404, 0.10155722325327404, 0.10155722325327404, 0.20790576914664488, 0.12794201178255069, 0.19191301767382604, 0.13327292894015697, 0.08529467452170046, 0.06930192304888162, 0.05864008873366906, 0.04797825441845651, 0.04797825441845651, 0.03198550294563767, 0.23525247119857012, 0.3136699615980935, 0.07841749039952338, 0.11762623559928506, 0.07841749039952338, 0.03920874519976169, 0.07841749039952338, 0.03920874519976169, 0.03920874519976169, 0.03920874519976169, 0.16689076398371294, 0.3337815279674259, 0.16689076398371294, 0.16689076398371294, 0.16689076398371294, 0.15302627672436142, 0.15302627672436142, 0.07651313836218071, 0.15302627672436142, 0.15302627672436142, 0.07651313836218071, 0.15302627672436142, 0.07651313836218071, 0.07651313836218071, 0.07651313836218071, 0.2464445820695088, 0.2464445820695088, 0.2464445820695088, 0.11532644802881178, 0.07688429868587451, 0.15376859737174903, 0.23065289605762357, 0.11532644802881178, 0.07688429868587451, 0.07688429868587451, 0.03844214934293726, 0.11532644802881178, 0.08848721913292305, 0.08848721913292305, 0.1769744382658461, 0.26546165739876915, 0.08848721913292305, 0.08848721913292305, 0.08848721913292305, 0.08848721913292305, 0.08848721913292305, 0.23256195061713997, 0.11628097530856998, 0.11628097530856998, 0.23256195061713997, 0.11628097530856998, 0.11628097530856998, 0.11628097530856998, 0.13437833168675234, 0.13437833168675234, 0.2687566633735047, 0.13437833168675234, 0.13437833168675234, 0.13437833168675234, 0.1578353791348912, 0.1578353791348912, 0.1578353791348912, 0.0789176895674456, 0.0789176895674456, 0.1578353791348912, 0.0789176895674456, 0.0789176895674456, 0.0789176895674456, 0.0789176895674456, 0.30524998358280503, 0.14880936699661745, 0.11065311904876682, 0.11065311904876682, 0.06104999671656101, 0.08394374548527138, 0.04578749753742076, 0.04578749753742076, 0.05341874712699088, 0.03434062315306557, 0.11207497702457982, 0.16811246553686973, 0.11207497702457982, 0.11207497702457982, 0.16811246553686973, 0.05603748851228991, 0.05603748851228991, 0.05603748851228991, 0.2641042647693604, 0.2641042647693604, 0.2641042647693604, 0.14429970758675362, 0.19239961011567147, 0.10581978556361932, 0.09619980505783574, 0.18277962960988792, 0.09619980505783574, 0.05771988303470144, 0.02885994151735072, 0.04809990252891787, 0.03847992202313429, 0.06537546814884405, 0.1307509362976881, 0.1307509362976881, 0.1307509362976881, 0.19612640444653215, 0.1307509362976881, 0.19612640444653215, 0.1872656861981122, 0.1872656861981122, 0.1872656861981122, 0.1872656861981122, 0.22233430865069942, 0.22233430865069942, 0.22233430865069942, 0.18550108249633399, 0.17856646258992898, 0.09361736873646762, 0.14736067301110645, 0.14389336305790393, 0.08148178390025886, 0.052009649298037565, 0.0398740644618288, 0.032939444555423796, 0.0433413744150313, 0.23654136490897612, 0.176831894155254, 0.08497116991875842, 0.14238412256656816, 0.12630849582518142, 0.06200598885963452, 0.05970947075372213, 0.04822688022416018, 0.0436338440123354, 0.018372144847299116, 0.15179254623765157, 0.15179254623765157, 0.15179254623765157, 0.15179254623765157, 0.15179254623765157, 0.15179254623765157, 0.1188692946880854, 0.2377385893761708, 0.1188692946880854, 0.2377385893761708, 0.1188692946880854, 0.1188692946880854, 0.1188692946880854, 0.12383502501904334, 0.21671129378332582, 0.06191751250952167, 0.24767005003808668, 0.0928762687642825, 0.06191751250952167, 0.06191751250952167, 0.0928762687642825, 0.030958756254760834, 0.030958756254760834, 0.1287400283855667, 0.23173205109402004, 0.18023603973979338, 0.07724401703134001, 0.07724401703134001, 0.07724401703134001, 0.07724401703134001, 0.10299202270845335, 0.02574800567711334, 0.02574800567711334, 0.23510379025617245, 0.23510379025617245, 0.17558238669613774, 0.17558238669613774, 0.13168679002210332, 0.11914519097237919, 0.11078412493922977, 0.07106906128177004, 0.0773398608066321, 0.05643719572375856, 0.043895596674034434, 0.03762479714917238, 0.271779072595862, 0.271779072595862, 0.1941981653370451, 0.12946544355803005, 0.12946544355803005, 0.12946544355803005, 0.16183180444753759, 0.03236636088950751, 0.06473272177901503, 0.03236636088950751, 0.03236636088950751, 0.09709908266852255, 0.20508440162496022, 0.17190898371504018, 0.09047841248160009, 0.13270167163968014, 0.13873356580512014, 0.07238272998528007, 0.06031894165440006, 0.048255153323520046, 0.048255153323520046, 0.033175417909920034, 0.45909410611220014, 0.12242509496325338, 0.13772823183366004, 0.04590941061122002, 0.15303136870406672, 0.030606273740813345, 0.030606273740813345, 0.015303136870406672, 0.015303136870406672, 0.3649914406349538, 0.1824957203174769, 0.1824957203174769, 0.1824957203174769, 0.49389293181642546, 0.0987785863632851, 0.0987785863632851, 0.0987785863632851, 0.0987785863632851, 0.25122923518467166, 0.3230090166660064, 0.07177978148133475, 0.07177978148133475, 0.07177978148133475, 0.07177978148133475, 0.07177978148133475, 0.035889890740667375, 0.035889890740667375, 0.035889890740667375, 0.2375273245948303, 0.2246880097518665, 0.1027145187437104, 0.0898752039007466, 0.1027145187437104, 0.0449376019503733, 0.1027145187437104, 0.0385179445288914, 0.0320982871074095, 0.0256786296859276, 0.2878004061160761, 0.2878004061160761, 0.2171649261647131, 0.2171649261647131, 0.2171649261647131, 0.2171649261647131, 0.2820924591627159, 0.13289689187221285, 0.08901584266912368, 0.11032949513919556, 0.15797177713112093, 0.05516474756959778, 0.07522465577672424, 0.0313436065736351, 0.028836118047744295, 0.03635858362541672, 0.13254117741457053, 0.13254117741457053, 0.26508235482914105, 0.13254117741457053, 0.13254117741457053, 0.13254117741457053, 0.2806753968469696, 0.2806753968469696, 0.2806753968469696, 0.22519516375300008, 0.19653396109352736, 0.11600962981215156, 0.11873926816067278, 0.09826698054676368, 0.07097059706155154, 0.04776867109912123, 0.05186312862190305, 0.03685011770503638, 0.03821493687929699, 0.13330323865200616, 0.20736059345867625, 0.20736059345867625, 0.029622941922668036, 0.1629261805746742, 0.05924588384533607, 0.07405735480667008, 0.0888688257680041, 0.029622941922668036, 0.014811470961334018, 0.15472276039432278, 0.22348843168068847, 0.10314850692954852, 0.13180086996553422, 0.06876567128636568, 0.06303519867916854, 0.07449614389356282, 0.07449614389356282, 0.05157425346477426, 0.05157425346477426, 0.15792163321028205, 0.20273723182401074, 0.11310603459655337, 0.11950826296994317, 0.15151940483689225, 0.06615635985836141, 0.04694967473819196, 0.051217826987118506, 0.04054744636480215, 0.04694967473819196, 0.11222849154964801, 0.29927597746572804, 0.18704748591608, 0.037409497183216005, 0.07481899436643201, 0.07481899436643201, 0.07481899436643201, 0.11222849154964801, 0.037409497183216005, 0.037409497183216005, 0.2230138215174898, 0.2230138215174898, 0.2230138215174898, 0.2230138215174898, 0.2230138215174898, 0.1319964259768477, 0.1319964259768477, 0.1319964259768477, 0.2639928519536954, 0.1319964259768477, 0.1319964259768477, 0.5097843941574826, 0.07060827736807236, 0.21182483210421707, 0.07060827736807236, 0.14121655473614472, 0.21182483210421707, 0.07060827736807236, 0.07060827736807236, 0.14121655473614472, 0.24978439056141874, 0.1703827299856035, 0.13729870474568048, 0.11910249086372283, 0.08436426436180368, 0.05789704416986527, 0.054588641645872966, 0.061205446693857565, 0.03804662902591146, 0.02977562271593071, 0.19052736630154032, 0.19365076574910656, 0.16554017072101046, 0.10307218176968574, 0.11556577955995069, 0.05934458950375846, 0.053097790608625996, 0.049974391161059756, 0.034357393923228584, 0.034357393923228584, 0.31475796218443375, 0.31475796218443375, 0.17738286960180671, 0.17738286960180671, 0.17738286960180671, 0.17738286960180671, 0.17738286960180671, 0.13760033022741983, 0.27520066045483965, 0.13760033022741983, 0.13760033022741983, 0.13760033022741983, 0.13760033022741983, 0.13760033022741983, 0.1659923876984172, 0.1659923876984172, 0.1659923876984172, 0.1659923876984172, 0.1659923876984172, 0.3319847753968344, 0.30655244267479864, 0.12229485745005265, 0.07989930686736774, 0.14512323084072914, 0.10109708215871019, 0.06359332587402738, 0.06685452207269545, 0.03994965343368387, 0.03994965343368387, 0.03424256008601474, 0.39126081164063925, 0.36602399873060665, 0.09150599968265166, 0.09150599968265166, 0.18301199936530332, 0.09150599968265166, 0.09150599968265166, 0.09150599968265166, 0.09150599968265166, 0.2812747776282568, 0.2812747776282568, 0.20438916005961416, 0.10219458002980708, 0.10219458002980708, 0.20438916005961416, 0.10219458002980708, 0.10219458002980708, 0.10219458002980708, 0.10219458002980708, 0.16366198296856455, 0.21042254953101155, 0.13151409345688223, 0.12713029034165282, 0.11105634558581166, 0.08621479459951169, 0.05991197590813524, 0.04237676344721761, 0.0379929603319882, 0.030686621806605852, 0.17071009499159295, 0.17071009499159295, 0.3414201899831859, 0.17071009499159295, 0.14374300818627767, 0.1987035701398544, 0.12260433051182507, 0.09301018176759143, 0.14797074372116817, 0.07609923962802935, 0.0887824462327009, 0.038049619814014675, 0.05918829748846727, 0.038049619814014675, 0.28491083479124596, 0.28491083479124596, 0.28491083479124596, 0.2744757872647772, 0.2744757872647772, 0.2744757872647772, 0.2744757872647772, 0.285585927941559, 0.285585927941559, 0.2485178454535727, 0.2110057178379391, 0.15239301843851155, 0.09378031903908404, 0.06564622332735882, 0.07033523927931302, 0.04923466749551912, 0.03751212761563361, 0.04454565154356492, 0.02344507975977101, 0.14621353977727308, 0.14621353977727308, 0.24368923296212178, 0.048737846592424354, 0.09747569318484871, 0.048737846592424354, 0.09747569318484871, 0.048737846592424354, 0.048737846592424354, 0.048737846592424354, 0.1143828398652254, 0.1143828398652254, 0.1143828398652254, 0.1143828398652254, 0.1143828398652254, 0.1143828398652254, 0.1143828398652254, 0.4069205182178424, 0.2034602591089212, 0.1017301295544606, 0.1017301295544606, 0.1017301295544606, 0.12510176746337023, 0.12510176746337023, 0.12510176746337023, 0.25020353492674047, 0.12510176746337023, 0.12510176746337023, 0.12510176746337023, 0.22966117053681737, 0.22966117053681737, 0.22966117053681737, 0.22966117053681737, 0.15681311458874395, 0.3136262291774879, 0.15681311458874395, 0.15681311458874395, 0.15681311458874395, 0.10333722187087448, 0.20667444374174895, 0.10333722187087448, 0.10333722187087448, 0.10333722187087448, 0.20667444374174895, 0.10333722187087448, 0.14892012615352238, 0.29784025230704475, 0.14892012615352238, 0.14892012615352238, 0.14892012615352238, 0.27351935304200975, 0.27351935304200975, 0.27351935304200975, 0.1833096115342234, 0.2749644173013351, 0.0916548057671117, 0.0916548057671117, 0.1833096115342234, 0.0916548057671117, 0.16719648021551556, 0.16719648021551556, 0.16719648021551556, 0.08359824010775778, 0.16719648021551556, 0.08359824010775778, 0.16719648021551556, 0.19981060068193998, 0.2580886925475058, 0.08824968196785683, 0.09657512366293766, 0.08658459362884066, 0.05827809186556583, 0.09157985864588916, 0.04329229681442033, 0.0349668551193395, 0.041627208475404166, 0.18087113404053387, 0.18087113404053387, 0.2713067010608008, 0.09043556702026694, 0.09043556702026694, 0.15158176045842012, 0.30316352091684023, 0.15158176045842012, 0.5406014269656213, 0.23559440214352007, 0.21582424252308482, 0.13015355083453206, 0.0873182049902557, 0.09885079810217626, 0.10379333800728506, 0.03295026603405875, 0.029655239430652874, 0.03130275273235581, 0.029655239430652874, 0.18313449984286137, 0.18313449984286137, 0.18313449984286137, 0.18313449984286137, 0.19196573050693055, 0.15357258440554444, 0.12797715367128704, 0.10238172293702963, 0.19196573050693055, 0.051190861468514814, 0.051190861468514814, 0.025595430734257407, 0.025595430734257407, 0.08958400756990093, 0.2289299822268118, 0.1144649911134059, 0.1144649911134059, 0.1144649911134059, 0.1144649911134059, 0.1144649911134059, 0.1144649911134059, 0.1144649911134059, 0.20997632548845652, 0.20997632548845652, 0.20997632548845652, 0.42746821209396246, 0.10686705302349062, 0.10686705302349062, 0.10686705302349062, 0.10686705302349062, 0.08677316715013353, 0.2603195014504006, 0.08677316715013353, 0.08677316715013353, 0.2603195014504006, 0.08677316715013353, 0.08677316715013353, 0.08677316715013353, 0.0739614169745061, 0.2958456678980244, 0.0739614169745061, 0.0739614169745061, 0.2218842509235183, 0.0739614169745061, 0.0739614169745061, 0.0739614169745061, 0.21581552474633317, 0.19639212751916318, 0.08416805465106994, 0.20286659326155318, 0.08416805465106994, 0.06258650217643662, 0.05395388118658329, 0.03668863920687664, 0.03237232871194998, 0.030214173464486644, 0.33815132297653216, 0.16907566148826608, 0.16907566148826608, 0.18040678234996393, 0.18040678234996393, 0.18040678234996393, 0.18040678234996393, 0.1748438044461089, 0.08742190222305445, 0.08742190222305445, 0.2622657066691633, 0.08742190222305445, 0.08742190222305445, 0.08742190222305445, 0.2863218378508147, 0.09544061261693823, 0.19088122523387646, 0.09544061261693823, 0.09544061261693823, 0.19088122523387646, 0.09544061261693823, 0.09544061261693823, 0.19414998089238558, 0.13266915360979684, 0.18767831486263942, 0.08736749140157352, 0.10678248949081208, 0.08413165838670042, 0.05824499426771568, 0.07118832632720805, 0.03882999617847712, 0.03882999617847712, 0.2335282680444657, 0.09341130721778627, 0.2335282680444657, 0.09341130721778627, 0.04670565360889314, 0.18682261443557255, 0.04670565360889314, 0.09341130721778627, 0.13760034713718908, 0.34400086784297274, 0.06880017356859454, 0.06880017356859454, 0.06880017356859454, 0.06880017356859454, 0.13760034713718908, 0.06880017356859454, 0.2648314849114773, 0.2648314849114773, 0.19303124334552155, 0.09651562167276077, 0.09651562167276077, 0.2895468650182823, 0.09651562167276077, 0.09651562167276077, 0.2080006233743111, 0.13000038960894444, 0.1522861706847635, 0.13185753803192937, 0.12628609276297462, 0.08728597588029127, 0.050143007420592856, 0.05757160111253254, 0.031571523190743654, 0.026000077921788888, 0.10428965520798376, 0.3128689656239513, 0.10428965520798376, 0.10428965520798376, 0.10428965520798376, 0.20857931041596753, 0.10428965520798376, 0.10428965520798376, 0.1331475958020359, 0.19972139370305383, 0.2662951916040718, 0.06657379790101794, 0.06657379790101794, 0.06657379790101794, 0.06657379790101794, 0.06657379790101794, 0.06657379790101794, 0.19372747903727727, 0.17074286288031218, 0.15104176331719923, 0.11163956419097334, 0.08865494803400824, 0.09850549781556471, 0.07223736506474746, 0.05581978209548667, 0.03611868253237373, 0.02626813275081726, 0.1769302092833552, 0.07582723255000937, 0.22748169765002813, 0.12637872091668229, 0.10110297673334583, 0.12637872091668229, 0.07582723255000937, 0.05055148836667291, 0.025275744183336456, 0.025275744183336456, 0.21108779913701997, 0.13759797277079822, 0.14854326605938442, 0.1321253261265051, 0.09538041294339421, 0.05394465977946066, 0.07427163302969221, 0.06254453307763555, 0.046126593144756214, 0.039090333173522215, 0.19130601116795198, 0.1744879002960441, 0.17028337257806714, 0.09880640137245872, 0.10721545680841264, 0.10721545680841264, 0.04414754103875815, 0.054658860333700564, 0.0252271663078618, 0.0252271663078618, 0.12960042292873217, 0.12960042292873217, 0.12960042292873217, 0.12960042292873217, 0.25920084585746433, 0.21000805900970665, 0.17850685015825066, 0.110254230980096, 0.12862993614344534, 0.09712872729198933, 0.09450362655436799, 0.063002417702912, 0.044626712539562664, 0.044626712539562664, 0.02625100737621333, 0.19912209383869126, 0.265496125118255, 0.06637403127956375, 0.06637403127956375, 0.1327480625591275, 0.1327480625591275, 0.06637403127956375, 0.08803488358786118, 0.2641046507635835, 0.17606976717572237, 0.08803488358786118, 0.08803488358786118, 0.08803488358786118, 0.08803488358786118, 0.08803488358786118, 0.2975720085254529, 0.20404937727459627, 0.10202468863729813, 0.08076954517119435, 0.08502057386441511, 0.06801645909153209, 0.06376543039831133, 0.034008229545766044, 0.034008229545766044, 0.02975720085254529, 0.19908004517011366, 0.2325701462267683, 0.14140264890587512, 0.12093647603791952, 0.07814356913219415, 0.09488861966052146, 0.037211223396282925, 0.03907178456609708, 0.026047856377398048, 0.027908417547212197, 0.4029573544154284, 0.16118294176617134, 0.08059147088308567, 0.08059147088308567, 0.08059147088308567, 0.08059147088308567, 0.08059147088308567, 0.21794174893616225, 0.21794174893616225, 0.21794174893616225, 0.21794174893616225, 0.10101619962137959, 0.20203239924275918, 0.20203239924275918, 0.10101619962137959, 0.20203239924275918, 0.17011280538909387, 0.17011280538909387, 0.17011280538909387, 0.17011280538909387, 0.17011280538909387, 0.296120962671099, 0.17273722822480772, 0.09253780083471842, 0.09870698755703299, 0.09870698755703299, 0.10179158091819027, 0.040099713695044656, 0.04318430705620193, 0.027761340250415528, 0.024676746889258246, 0.18925524768364643, 0.2207977889642542, 0.07885635320151935, 0.1103988944821271, 0.09462762384182322, 0.14194143576273482, 0.04731381192091161, 0.03154254128060774, 0.04731381192091161, 0.03154254128060774, 0.1759337412361461, 0.1759337412361461, 0.1759337412361461, 0.1759337412361461, 0.1759337412361461, 0.1759337412361461, 0.20055281033691819, 0.40110562067383637, 0.20055281033691819, 0.20055281033691819, 0.21383456611607315, 0.16475778045008915, 0.10867002540325028, 0.1367139029266697, 0.10516454071282286, 0.07712066318940343, 0.05959323973726629, 0.07010969380854858, 0.038560331594701715, 0.024538392832992, 0.20077807389542177, 0.17081119719461255, 0.14384100816388426, 0.11087744379299411, 0.09889069311267042, 0.07791387942210397, 0.06592712874178028, 0.04794700272129475, 0.038956939711051984, 0.0419536273811329, 0.10596860077546458, 0.1766143346257743, 0.13422689431558846, 0.09183945400540264, 0.1766143346257743, 0.04591972700270132, 0.09537174069791812, 0.021193720155092917, 0.12009774754552653, 0.028258293540123887, 0.19586799264744842, 0.12241749540465527, 0.1346592449451208, 0.1346592449451208, 0.08569224678325868, 0.11017574586418974, 0.061208747702327634, 0.048966998161862105, 0.03672524862139658, 0.07345049724279316, 0.16123316210991656, 0.08061658105495828, 0.08061658105495828, 0.16123316210991656, 0.08061658105495828, 0.08061658105495828, 0.08061658105495828, 0.08061658105495828, 0.31868903936411674, 0.21805039535439566, 0.0754789830072908, 0.08386553667476757, 0.15934451968205837, 0.04193276833738378, 0.04193276833738378, 0.008386553667476756, 0.025159661002430268, 0.016773107334953512, 0.16840812134510777, 0.20739148276758643, 0.1652894524313095, 0.12786542546573, 0.11227208089673851, 0.05925470936216755, 0.07017005056046158, 0.029627354681083774, 0.032746023594882066, 0.02806802022418463, 0.08791042002633952, 0.08791042002633952, 0.17582084005267903, 0.17582084005267903, 0.08791042002633952, 0.08791042002633952, 0.08791042002633952, 0.08791042002633952, 0.18053943359885724, 0.18655741471881915, 0.16850347135893343, 0.1173506318392572, 0.09026971679942862, 0.06920678287956195, 0.06920678287956195, 0.04513485839971431, 0.04513485839971431, 0.027080915039828585, 0.1927474937334381, 0.17694851883725465, 0.11375261925252085, 0.11691241423175754, 0.10111343933557408, 0.07899487448091726, 0.07899487448091726, 0.06003610460549712, 0.04423712970931366, 0.037917539750840286, 0.1920438758029194, 0.1920438758029194, 0.1280292505352796, 0.106691042112733, 0.106691042112733, 0.0640146252676398, 0.0426764168450932, 0.0853528336901864, 0.0426764168450932, 0.0213382084225466, 0.187920662635362, 0.187920662635362, 0.093960331317681, 0.093960331317681, 0.187920662635362, 0.093960331317681, 0.24443905946169592, 0.24443905946169592, 0.24443905946169592, 0.2409322961084086, 0.18351864256768144, 0.11995352614759067, 0.12097876996081794, 0.10457486894918161, 0.07586804217881803, 0.03998450871586356, 0.04921170303490899, 0.035883533462954476, 0.026656339143909035, 0.1419902420390468, 0.1419902420390468, 0.1419902420390468, 0.1419902420390468, 0.1419902420390468, 0.1419902420390468, 0.14422789702080402, 0.28845579404160804, 0.14422789702080402, 0.14422789702080402, 0.14422789702080402, 0.14422789702080402, 0.2729530667278818, 0.2729530667278818, 0.16885204853056573, 0.1830374509816431, 0.14459958627549804, 0.1432268053931357, 0.11394081323607282, 0.06680866960829973, 0.038895458333599156, 0.05719920343176346, 0.05628401617685525, 0.02654043039233825, 0.14794982463681466, 0.29589964927362933, 0.14794982463681466, 0.14794982463681466, 0.14794982463681466, 0.1606101577148409, 0.40152539428710227, 0.1606101577148409, 0.08030507885742046, 0.08030507885742046, 0.08030507885742046, 0.3912091536071549, 0.09780228840178873, 0.19560457680357746, 0.09780228840178873, 0.09780228840178873, 0.09780228840178873, 0.16523988436467268, 0.16523988436467268, 0.09638993254605907, 0.12392991327350451, 0.12392991327350451, 0.09638993254605907, 0.05507996145489089, 0.08261994218233634, 0.04130997109116817, 0.027539980727445446, 0.380513351798799, 0.1902566758993995, 0.1902566758993995, 0.1902566758993995, 0.12362693731003642, 0.30906734327509106, 0.12362693731003642, 0.06181346865501821, 0.06181346865501821, 0.06181346865501821, 0.06181346865501821, 0.06181346865501821, 0.06181346865501821, 0.06181346865501821, 0.18756413551611015, 0.2857768521446245, 0.12110440245922072, 0.09747427515010448, 0.08492077001713648, 0.07236726488416848, 0.03544519096367436, 0.05169090348869177, 0.03544519096367436, 0.028799217657985415, 0.34997483322758527, 0.1998363955943761, 0.2551102922481397, 0.09566635959305239, 0.11479963151166288, 0.12755514612406985, 0.05952573485789927, 0.03614062473515313, 0.04677022024549228, 0.03188878653101746, 0.029762867428949635, 0.1395561123363367, 0.1395561123363367, 0.2791122246726734, 0.09303740822422446, 0.1395561123363367, 0.1395561123363367, 0.04651870411211223, 0.04651870411211223, 0.19125820340988853, 0.1500064340469714, 0.10875466468405426, 0.11625498638640283, 0.1500064340469714, 0.07125305617231141, 0.06375273446996284, 0.06375273446996284, 0.04875209106526571, 0.041251769362917134, 0.3211771956005277, 0.16875411972231116, 0.14153571331548678, 0.08709890050183802, 0.08165521922047314, 0.07621153793910827, 0.03810576896955414, 0.032662087688189255, 0.032662087688189255, 0.021774725125459506, 0.308849429776224, 0.38389298553196666, 0.12796432851065556, 0.12796432851065556, 0.12796432851065556, 0.36155862136504296, 0.12051954045501433, 0.09038965534126074, 0.09038965534126074, 0.09038965534126074, 0.06025977022750716, 0.06025977022750716, 0.06025977022750716, 0.03012988511375358, 0.03012988511375358, 0.08143767277961272, 0.24431301833883817, 0.08143767277961272, 0.08143767277961272, 0.16287534555922545, 0.08143767277961272, 0.08143767277961272, 0.08143767277961272, 0.07982020527342784, 0.39910102636713923, 0.07982020527342784, 0.07982020527342784, 0.15964041054685568, 0.07982020527342784, 0.07982020527342784, 0.3826244729207397, 0.19743759584669562, 0.24359183903163745, 0.11923179489443307, 0.09102642405919084, 0.09743673561265498, 0.08589817481641952, 0.04743630549563466, 0.057692803981177286, 0.02820537083524223, 0.02948743314593506, 0.3025227829495776, 0.15037682193400057, 0.0937643713235533, 0.08845695407882385, 0.07430384142621205, 0.08668781499724738, 0.06368900693675318, 0.07607298050778852, 0.030075364386800113, 0.03361364254995307, 0.35790951945031163, 0.17895475972515582, 0.07158190389006232, 0.07158190389006232, 0.07158190389006232, 0.07158190389006232, 0.07158190389006232, 0.07158190389006232, 0.03579095194503116, 0.03579095194503116, 0.20929506352407912, 0.13953004234938607, 0.06976502117469303, 0.27906008469877214, 0.06976502117469303, 0.06976502117469303, 0.06976502117469303, 0.06976502117469303, 0.2920098784336463, 0.17831376997775852, 0.17831376997775852, 0.17831376997775852, 0.17831376997775852, 0.19597541114625783, 0.24570051546695013, 0.07312515341278278, 0.10530022091440719, 0.11700024546045244, 0.08190017182231671, 0.06142512886673753, 0.046800098184180974, 0.035100073638135734, 0.035100073638135734, 0.3522189482832094, 0.14211057269457328, 0.14211057269457328, 0.14211057269457328, 0.14211057269457328, 0.14211057269457328, 0.14211057269457328, 0.19945115623596954, 0.19945115623596954, 0.11732420955057032, 0.10559178859551328, 0.11732420955057032, 0.04692968382022813, 0.05866210477528516, 0.08212694668539923, 0.035197262865171094, 0.035197262865171094, 0.2855378706195711, 0.17314530452463356, 0.10935492917345277, 0.11239256609493757, 0.11846783993790716, 0.07897855995860478, 0.03948927997930239, 0.03037636921484799, 0.024301095371878394, 0.024301095371878394, 0.32185550693169723, 0.16092775346584862, 0.16092775346584862, 0.16092775346584862, 0.16092775346584862, 0.16092775346584862, 0.16092775346584862, 0.311128390722596, 0.0622256781445192, 0.0622256781445192, 0.1866770344335576, 0.0622256781445192, 0.1244513562890384, 0.0622256781445192, 0.0622256781445192, 0.1244513562890384, 0.2576996473628185, 0.3221245592035231, 0.04294994122713641, 0.10737485306784103, 0.10737485306784103, 0.06442491184070462, 0.021474970613568206, 0.04294994122713641, 0.021474970613568206, 0.12694143025419358, 0.12694143025419358, 0.12694143025419358, 0.12694143025419358, 0.12694143025419358, 0.12694143025419358, 0.12694143025419358, 0.16671108653399558, 0.1803759296925198, 0.132548978637685, 0.12298358842671805, 0.14211436884865197, 0.0778896060035881, 0.046460466738982374, 0.058758825581654184, 0.03826156084386784, 0.03279562358045815, 0.34386508944552885, 0.17193254472276442, 0.17193254472276442, 0.13830036165901835, 0.3227008438710428, 0.06915018082950918, 0.13830036165901835, 0.09220024110601223, 0.06915018082950918, 0.06915018082950918, 0.06915018082950918, 0.046100120553006114, 0.023050060276503057, 0.5363741273764508, 0.2854850169858184, 0.09516167232860613, 0.09516167232860613, 0.09516167232860613, 0.09516167232860613, 0.09516167232860613, 0.09516167232860613, 0.09516167232860613, 0.29162218248558663, 0.29162218248558663, 0.16442012221756624, 0.3288402444351325, 0.16442012221756624, 0.16442012221756624, 0.22198226402763802, 0.16788574590325564, 0.1249816108390903, 0.10819303624876474, 0.1156546249555761, 0.07834668142151929, 0.05596191530108521, 0.05036572377097669, 0.04850032659427385, 0.026115560473839766, 0.16938014825307976, 0.2032561779036957, 0.10162808895184786, 0.23713220755431164, 0.03387602965061595, 0.10162808895184786, 0.0677520593012319, 0.03387602965061595, 0.03387602965061595, 0.1597879071277184, 0.1597879071277184, 0.1597879071277184, 0.1597879071277184, 0.1597879071277184, 0.1597879071277184, 0.26396843055770614, 0.26396843055770614, 0.10926628435848429, 0.43706513743393716, 0.10926628435848429, 0.10926628435848429, 0.10926628435848429, 0.1304283464415859, 0.1304283464415859, 0.1304283464415859, 0.3912850393247578, 0.1304283464415859, 0.1304283464415859, 0.13080357192573133, 0.13080357192573133, 0.06540178596286567, 0.32700892981432833, 0.13080357192573133, 0.06540178596286567, 0.06540178596286567, 0.06540178596286567, 0.06540178596286567, 0.1850909803827038, 0.1850909803827038, 0.1850909803827038, 0.20541311672641485, 0.1842365067546195, 0.15035393079974696, 0.09529474487307905, 0.11223603285051532, 0.06564749091256557, 0.06988281290692464, 0.0614121689182065, 0.02752959296333395, 0.02752959296333395, 0.3000617111686699, 0.15003085558433496, 0.3000617111686699, 0.18943244793075112, 0.10086662811897137, 0.1771316396235595, 0.13776905304054626, 0.09840646645753305, 0.07134468818171145, 0.07380484984314979, 0.05412355655164318, 0.059043879874519825, 0.036902424921574896, 0.48447298405440004, 0.14022934230427975, 0.18697245640570634, 0.21813453247332404, 0.10906726623666202, 0.09348622820285317, 0.0779051901690443, 0.03116207606761772, 0.046743114101426585, 0.046743114101426585, 0.03116207606761772, 0.28787649826599443, 0.17381222536814755, 0.1412224331116199, 0.097769376769583, 0.08147448064131917, 0.05431632042754612, 0.0488846883847915, 0.04345305634203689, 0.03802142429928228, 0.02715816021377306, 0.14994510749611814, 0.2998902149922363, 0.14994510749611814, 0.14994510749611814, 0.14994510749611814, 0.21028477474953394, 0.21028477474953394, 0.10698699066204359, 0.11805461038570328, 0.14387905640757587, 0.07378413149106454, 0.02582444602187259, 0.05164889204374518, 0.033202859170979045, 0.02582444602187259, 0.17542088360317484, 0.17542088360317484, 0.16266300115930757, 0.1467156481044735, 0.09249464771803764, 0.0637894122193363, 0.05741047099740267, 0.06059994160836949, 0.03508417672063497, 0.03189470610966815, 0.23071246004916132, 0.1512232931414671, 0.1143868499403405, 0.09887676859249771, 0.12408065078274223, 0.10081552876097806, 0.04459148387504799, 0.05428528471744973, 0.0368364432011266, 0.040713963538087296, 0.16527688777527952, 0.16527688777527952, 0.16527688777527952, 0.16527688777527952, 0.16527688777527952, 0.23922903334899037, 0.16506803301080336, 0.10526077467355575, 0.11722222634100528, 0.11961451667449519, 0.0717687100046971, 0.055022677670267785, 0.05861111317050264, 0.04066893566932836, 0.028707484001878843, 0.15343523693971578, 0.18266099635680452, 0.15343523693971578, 0.11690303766835489, 0.16074167679398796, 0.051145078979905265, 0.05845151883417744, 0.043838639125633086, 0.051145078979905265, 0.0365321992713609, 0.22842612728247064, 0.18048484130960643, 0.09024242065480322, 0.14664393356405522, 0.12126325275489182, 0.07332196678202761, 0.03384090774555121, 0.050761361618326804, 0.042301134681939, 0.03384090774555121, 0.29837810198154396, 0.09945936732718133, 0.0596756203963088, 0.07956749386174505, 0.13924311425805386, 0.07956749386174505, 0.07956749386174505, 0.03978374693087253, 0.09945936732718133, 0.019891873465436263, 0.16103744022366062, 0.12077808016774547, 0.08051872011183031, 0.08051872011183031, 0.16103744022366062, 0.08051872011183031, 0.16103744022366062, 0.040259360055915155, 0.040259360055915155, 0.08051872011183031, 0.2981615368032231, 0.16726134991400318, 0.1090834890743499, 0.09453902386443659, 0.08726679125947993, 0.07999455865452326, 0.050905628234696625, 0.050905628234696625, 0.02908893041982664, 0.0363611630247833, 0.2239487725234764, 0.18228388461213196, 0.10416221977836111, 0.14322305219524653, 0.12239060823957432, 0.07030949835039375, 0.04426894340580347, 0.054685165383639586, 0.031248665933508335, 0.026040554944590278, 0.21307423189614846, 0.21307423189614846, 0.21307423189614846, 0.18947323661818144, 0.18947323661818144, 0.18947323661818144, 0.18947323661818144, 0.18947323661818144, 0.18947323661818144, 0.35207165628695797, 0.17064517500047777, 0.17064517500047777, 0.17064517500047777, 0.17064517500047777, 0.15983230509232063, 0.3596226864577214, 0.15983230509232063, 0.07991615254616032, 0.07991615254616032, 0.07991615254616032, 0.03995807627308016, 0.03995807627308016, 0.03995807627308016, 0.03995807627308016, 0.21668106977946291, 0.18725524548842476, 0.06955194832427204, 0.1284035969063484, 0.12572852197079948, 0.0642017984531742, 0.06687687338872313, 0.045476273904331725, 0.061526723517625274, 0.03477597416213602, 0.3604775312731911, 0.15019897136382962, 0.06007958854553185, 0.15019897136382962, 0.1201591770910637, 0.06007958854553185, 0.030039794272765926, 0.030039794272765926, 0.030039794272765926, 0.06007958854553185, 0.13331997508031943, 0.13331997508031943, 0.08887998338687962, 0.17775996677375924, 0.17775996677375924, 0.04443999169343981, 0.04443999169343981, 0.04443999169343981, 0.04443999169343981, 0.04443999169343981, 0.2062641725013542, 0.27226870770178757, 0.10450718073401946, 0.07975548003385696, 0.11825812556744308, 0.05500377933369446, 0.04125283450027084, 0.05500377933369446, 0.03850264553358612, 0.03025207863353195, 0.11038477799526401, 0.11038477799526401, 0.22076955599052803, 0.11038477799526401, 0.11038477799526401, 0.11038477799526401, 0.11038477799526401, 0.0592729004225879, 0.1778187012677637, 0.1185458008451758, 0.0592729004225879, 0.2370916016903516, 0.0592729004225879, 0.0592729004225879, 0.1778187012677637, 0.0592729004225879, 0.15773056056062626, 0.15773056056062626, 0.15773056056062626, 0.15773056056062626, 0.15773056056062626, 0.15773056056062626, 0.15115464621812835, 0.1983904731612935, 0.10864240196927977, 0.10864240196927977, 0.07085374041474767, 0.1228131500522293, 0.05668299233179814, 0.08502448849769721, 0.06613015772043115, 0.03306507886021558, 0.09860600742760262, 0.17256051299830458, 0.19721201485520523, 0.07395450557070196, 0.09860600742760262, 0.17256051299830458, 0.04930300371380131, 0.04930300371380131, 0.04930300371380131, 0.04930300371380131, 0.09698622907638281, 0.1454793436145742, 0.19397245815276562, 0.1454793436145742, 0.19397245815276562, 0.048493114538191405, 0.09698622907638281, 0.048493114538191405, 0.09698622907638281, 0.048493114538191405, 0.06084545294378665, 0.13690226912351997, 0.16732499559541328, 0.10647954265162664, 0.18253635883135994, 0.030422726471893324, 0.09126817941567997, 0.015211363235946662, 0.16732499559541328, 0.030422726471893324, 0.14258741073141318, 0.14258741073141318, 0.14258741073141318, 0.28517482146282636, 0.14258741073141318, 0.14258741073141318, 0.16237952339224732, 0.16237952339224732, 0.16237952339224732, 0.16237952339224732, 0.16237952339224732, 0.16237952339224732, 0.28872746552077755, 0.28872746552077755, 0.28872746552077755, 0.10925684315025266, 0.18209473858375444, 0.10925684315025266, 0.14567579086700355, 0.10925684315025266, 0.03641894771675089, 0.14567579086700355, 0.03641894771675089, 0.07283789543350178, 0.03641894771675089, 0.18387887728520538, 0.24974593780527896, 0.10703397334511955, 0.10977843420012262, 0.10977843420012262, 0.07684490394008583, 0.057633677955064376, 0.03567799111503985, 0.03567799111503985, 0.03567799111503985, 0.13089709159747265, 0.39269127479241794, 0.13089709159747265, 0.13089709159747265, 0.13089709159747265, 0.3735553052366796, 0.25868349430382875, 0.14781913960218787, 0.13283747004791208, 0.11086435470164091, 0.093885129206795, 0.0789034596525192, 0.05892790024681814, 0.04794134257368255, 0.038952340841117074, 0.032959673019406756, 0.13522413731649718, 0.16462068890704007, 0.14698275795271434, 0.14698275795271434, 0.10582758572595433, 0.06467241349919431, 0.10582758572595433, 0.03527586190865144, 0.05291379286297716, 0.04115517222676002, 0.19615412835762694, 0.11769247701457616, 0.15692330268610155, 0.03923082567152539, 0.07846165134305078, 0.11769247701457616, 0.03923082567152539, 0.11769247701457616, 0.07846165134305078, 0.03923082567152539, 0.13482337780576972, 0.22470562967628288, 0.13482337780576972, 0.08988225187051316, 0.08988225187051316, 0.13482337780576972, 0.04494112593525658, 0.04494112593525658, 0.04494112593525658, 0.28290994375908995, 0.28290994375908995, 0.3736681256425036, 0.27125511337954056, 0.27125511337954056, 0.27125511337954056, 0.28469048033794964, 0.11387619213517985, 0.05693809606758993, 0.08540714410138489, 0.05693809606758993, 0.08540714410138489, 0.14234524016897482, 0.08540714410138489, 0.028469048033794964, 0.028469048033794964, 0.38464854621249145, 0.15385941848499657, 0.07692970924249828, 0.07692970924249828, 0.07692970924249828, 0.10257294565666439, 0.07692970924249828, 0.025643236414166097, 0.025643236414166097, 0.025643236414166097, 0.14506764055383264, 0.21994126148484305, 0.18250445101933785, 0.0842328235473867, 0.12634923532108006, 0.0748736209310104, 0.06083481700644595, 0.0467960130818815, 0.02339800654094075, 0.03275720915731705, 0.1966347719220445, 0.393269543844089, 0.1966347719220445, 0.1966347719220445, 0.23641869409630692, 0.15862931732913496, 0.07626409486977642, 0.13422480697080652, 0.12964896127861994, 0.07931465866456748, 0.056435430203634555, 0.06101127589582114, 0.04423317502447033, 0.024404510358328458, 0.30490649016090987, 0.07622662254022747, 0.15245324508045494, 0.07622662254022747, 0.07622662254022747, 0.07622662254022747, 0.07622662254022747, 0.07622662254022747, 0.07622662254022747, 0.194342696577302, 0.194342696577302, 0.194342696577302, 0.194342696577302, 0.194342696577302, 0.27817563285250047, 0.17466842062831425, 0.11968021413421533, 0.1164456137522095, 0.0840996099321513, 0.05498820649409893, 0.04851900573008729, 0.0646920076401164, 0.0323460038200582, 0.022642202674040737, 0.347663649748082, 0.1511581085861226, 0.06046324343444904, 0.0755790542930613, 0.10581067601028582, 0.0755790542930613, 0.08313695972236743, 0.05290533800514291, 0.02267371628791839, 0.03023162171722452, 0.22570055331288524, 0.22570055331288524, 0.22570055331288524, 0.22570055331288524, 0.22570055331288524, 0.1954111361921116, 0.13678779533447813, 0.11724668171526696, 0.11724668171526696, 0.13678779533447813, 0.05862334085763348, 0.05862334085763348, 0.03908222723842232, 0.03908222723842232, 0.0977055680960558, 0.1376782807939974, 0.1376782807939974, 0.0688391403969987, 0.0688391403969987, 0.20651742119099611, 0.0688391403969987, 0.0688391403969987, 0.1376782807939974, 0.2020001067981155, 0.2020001067981155, 0.10100005339905775, 0.10100005339905775, 0.2020001067981155, 0.10100005339905775, 0.10100005339905775, 0.10100005339905775, 0.07695543283919333, 0.25651810946397774, 0.1026072437855911, 0.1026072437855911, 0.15391086567838666, 0.07695543283919333, 0.05130362189279555, 0.05130362189279555, 0.025651810946397777, 0.12825905473198887, 0.36679248642745793, 0.12226416214248598, 0.12226416214248598, 0.12226416214248598, 0.12226416214248598, 0.3841314698765201, 0.09603286746913002, 0.09603286746913002, 0.09603286746913002, 0.09603286746913002, 0.09603286746913002, 0.09603286746913002, 0.17612388702530504, 0.18241402584763738, 0.10693235997964949, 0.11322249880198182, 0.12580277644664647, 0.06919152704565555, 0.06290138822332324, 0.07548166586798788, 0.05661124940099091, 0.03145069411166162, 0.19599251290949182, 0.15189419750485617, 0.09799625645474591, 0.17149344879580533, 0.11759550774569509, 0.06369756669558484, 0.06369756669558484, 0.06369756669558484, 0.03919850258189836, 0.029398876936423773, 0.14268191823984086, 0.2853638364796817, 0.14268191823984086, 0.14268191823984086, 0.14268191823984086, 0.14268191823984086, 0.13856726465444147, 0.13856726465444147, 0.3048479822397713, 0.05542690586177659, 0.08314035879266489, 0.06928363232722073, 0.05542690586177659, 0.05542690586177659, 0.05542690586177659, 0.041570179396332445, 0.16553764465884854, 0.1997549231637502, 0.1461170271290395, 0.09802787895998853, 0.12207245304451401, 0.07213372225357646, 0.07583288749734962, 0.05641226996754057, 0.03976602637056138, 0.02404457408452549, 0.2524221309846314, 0.2524221309846314, 0.2524221309846314, 0.19809800239043138, 0.06603266746347713, 0.13206533492695427, 0.13206533492695427, 0.06603266746347713, 0.13206533492695427, 0.13206533492695427, 0.06603266746347713, 0.2847619200798584, 0.1669294014261239, 0.12983397888698525, 0.09164751450846018, 0.08837438899030088, 0.07528188691766372, 0.04909688277238938, 0.040368548057297934, 0.03491333886036578, 0.038186464378525076, 0.49086171330691797, 0.24543085665345898, 0.19989260652974872, 0.21526896087819095, 0.06150541739376884, 0.19989260652974872, 0.09225812609065326, 0.06150541739376884, 0.04612906304532663, 0.04612906304532663, 0.01537635434844221, 0.01537635434844221, 0.21744808631985998, 0.21744808631985998, 0.24714607566661279, 0.12357303783330639, 0.12357303783330639, 0.12357303783330639, 0.12357303783330639, 0.12357303783330639, 0.12357303783330639, 0.18425896539509534, 0.22305032653090487, 0.10425178305248815, 0.11394962333644054, 0.10910070319446434, 0.08728056255557147, 0.04848920141976193, 0.05818704170371432, 0.03636690106482145, 0.03394244099383335, 0.22036708678058753, 0.1999627268934961, 0.09181961949191147, 0.12446659531125777, 0.10610267141287548, 0.0795770035596566, 0.05509177169514688, 0.04488959175160116, 0.03060653983063716, 0.046930027740310305, 0.138287920568217, 0.3457198014205425, 0.138287920568217, 0.0691439602841085, 0.138287920568217, 0.0691439602841085, 0.0691439602841085, 0.0691439602841085, 0.0691439602841085, 0.10612782234739868, 0.318383467042196, 0.079595866760549, 0.079595866760549, 0.10612782234739868, 0.159191733521098, 0.02653195558684967, 0.05306391117369934, 0.02653195558684967, 0.02653195558684967, 0.09811128035477473, 0.2943338410643242, 0.06540752023651648, 0.06540752023651648, 0.09811128035477473, 0.13081504047303297, 0.03270376011825824, 0.09811128035477473, 0.06540752023651648, 0.03270376011825824, 0.13946811288755476, 0.21456632751931504, 0.22529464389528078, 0.05364158187982876, 0.11801148013562326, 0.09655484738369176, 0.021456632751931503, 0.042913265503863006, 0.0643698982557945, 0.021456632751931503, 0.265004792228675, 0.265004792228675, 0.265004792228675, 0.360414953518647, 0.12084764932344659, 0.1504429920149029, 0.1270133457175, 0.16154124552419902, 0.14304415634203882, 0.09495172446842233, 0.05549126754648058, 0.05549126754648058, 0.04562615331599514, 0.04562615331599514, 0.4621188399420485, 0.1359173058653084, 0.10873384469224671, 0.02718346117306168, 0.16310076703837006, 0.02718346117306168, 0.05436692234612336, 0.38568616301235087, 0.1285620543374503, 0.1285620543374503, 0.1285620543374503, 0.22928353169277313, 0.22928353169277313, 0.2009279014701706, 0.16277703410241667, 0.11953938441896224, 0.1347997313660638, 0.1220827755768125, 0.0966488639983099, 0.04578104084130469, 0.050867823157005214, 0.030520693894203126, 0.03560747620990365, 0.28114278162657597, 0.14057139081328798, 0.14057139081328798, 0.14057139081328798, 0.14057139081328798, 0.14057139081328798, 0.33554230256061657, 0.16777115128030828, 0.16777115128030828, 0.17102765449516397, 0.17102765449516397, 0.128270740871373, 0.10689228405947748, 0.128270740871373, 0.04275691362379099, 0.10689228405947748, 0.04275691362379099, 0.021378456811895496, 0.0641353704356865, 0.3792490036345897, 0.1562243813010371, 0.3124487626020742, 0.07811219065051855, 0.07811219065051855, 0.1562243813010371, 0.07811219065051855, 0.36901604081422096, 0.18450802040711048, 0.18450802040711048, 0.18450802040711048, 0.33524136589755, 0.14183288557204038, 0.09025729081857115, 0.10315118950693845, 0.12893898688367306, 0.06446949344183653, 0.07736339213020384, 0.025787797376734613, 0.025787797376734613, 0.03868169606510192, 0.18078739744955824, 0.203385822130753, 0.1016929110653765, 0.09039369872477912, 0.1242913357465713, 0.1016929110653765, 0.06779527404358433, 0.1016929110653765, 0.03389763702179217, 0.01129921234059739, 0.18075638879420763, 0.09037819439710382, 0.09037819439710382, 0.31632368038986336, 0.09037819439710382, 0.09037819439710382, 0.04518909719855191, 0.04518909719855191, 0.04518909719855191, 0.04518909719855191, 0.3917940296632445, 0.27753907230484465, 0.23128256025403718, 0.04625651205080744, 0.09251302410161488, 0.18502604820322976, 0.04625651205080744, 0.04625651205080744, 0.04625651205080744, 0.04625651205080744, 0.2103690868342066, 0.17744175150363514, 0.16646597306011132, 0.11341637724974618, 0.09878200599171441, 0.07317185629015882, 0.06402537425388898, 0.038415224552333385, 0.03292733533057147, 0.027439446108809558, 0.23467135134473252, 0.1694848648600846, 0.12168144143800945, 0.0869153153128639, 0.156447567563155, 0.06518648648464792, 0.05214918918771834, 0.034766126125145555, 0.03911189189078875, 0.030420360359502362, 0.1470381655982138, 0.1960508874642851, 0.09802544373214254, 0.04901272186607127, 0.1470381655982138, 0.04901272186607127, 0.1470381655982138, 0.04901272186607127, 0.04901272186607127, 0.09802544373214254, 0.12148506036867739, 0.24297012073735477, 0.12148506036867739, 0.12148506036867739, 0.12148506036867739, 0.12148506036867739, 0.09997263685446346, 0.19994527370892692, 0.09997263685446346, 0.09997263685446346, 0.09997263685446346, 0.19994527370892692, 0.09997263685446346, 0.09997263685446346, 0.11944340433746345, 0.11944340433746345, 0.2388868086749269, 0.11944340433746345, 0.11944340433746345, 0.11944340433746345, 0.20428765575499638, 0.1238765572131361, 0.1521291053494654, 0.14560928654877403, 0.13039637601382748, 0.056505096272658574, 0.07171800680760511, 0.04129218573771203, 0.03911891280414825, 0.036945639870584454, 0.37704748845522623, 0.14501826479047164, 0.14501826479047164, 0.058007305916188655, 0.08701095887428298, 0.058007305916188655, 0.029003652958094327, 0.058007305916188655, 0.029003652958094327, 0.029003652958094327, 0.18908770024579555, 0.23526027821279213, 0.14731251065660816, 0.12972295714537138, 0.07915299080056558, 0.07035821404494719, 0.03957649540028279, 0.04397388377809199, 0.035179107022473594, 0.030781718644664394, 0.24893689922165707, 0.23719459265459777, 0.1033322977901218, 0.08924152990965065, 0.08219614596941507, 0.06575691677553205, 0.05871153283529648, 0.03287845838776603, 0.0516661488950609, 0.02818153576094231, 0.34285418195750383, 0.18461379028480976, 0.05274679722423136, 0.10549359444846272, 0.1318669930605784, 0.05274679722423136, 0.05274679722423136, 0.02637339861211568, 0.02637339861211568, 0.02637339861211568, 0.2698095881759134, 0.17886253598178528, 0.1061048942264828, 0.12732587307177937, 0.10004175741354093, 0.06669450494236062, 0.048505094503535, 0.04244195769059312, 0.030315684064709372, 0.030315684064709372, 0.18486664672635983, 0.18486664672635983, 0.09243332336317991, 0.09243332336317991, 0.09243332336317991, 0.09243332336317991, 0.09243332336317991, 0.09243332336317991, 0.18054929190345068, 0.18054929190345068, 0.18054929190345068, 0.18054929190345068, 0.18054929190345068, 0.16526663675331, 0.20478691945518848, 0.12933910702432957, 0.09341157729534913, 0.14730287188881977, 0.08802244783600206, 0.04311303567477652, 0.053891294593470654, 0.04311303567477652, 0.032334776756082394, 0.12415991166449737, 0.16683988129916835, 0.1435598978620751, 0.20563985369432378, 0.12415991166449737, 0.046559966874186516, 0.05043996411370206, 0.07371994755079532, 0.03879997239515543, 0.023279983437093258, 0.35079023997016867, 0.24432112633743425, 0.08144037544581141, 0.08144037544581141, 0.16288075089162282, 0.08144037544581141, 0.040720187722905705, 0.12216056316871712, 0.12216056316871712, 0.040720187722905705, 0.040720187722905705, 0.1652709082763865, 0.19006154451784446, 0.1652709082763865, 0.09640802982789212, 0.12119866606935009, 0.07161739358643414, 0.060599333034675046, 0.05233578762085572, 0.049581272482915946, 0.027545151379397746, 0.19237975618255995, 0.21412703296841457, 0.13550226305032484, 0.08698910714341841, 0.09702631181381285, 0.0685875652476953, 0.05353175824210364, 0.07695190247302398, 0.046840288461840685, 0.02509301167598608, 0.5054683025728756, 0.16587439397334539, 0.4146859849333635, 0.08293719698667269, 0.08293719698667269, 0.08293719698667269, 0.08293719698667269, 0.08293719698667269, 0.08293719698667269, 0.13424457820602048, 0.22374096367670082, 0.22374096367670082, 0.08949638547068033, 0.04474819273534016, 0.08949638547068033, 0.08949638547068033, 0.04474819273534016, 0.04474819273534016, 0.14573081632789925, 0.14573081632789925, 0.15156004898101522, 0.1165846530623194, 0.15738928163413118, 0.06995079183739164, 0.03497539591869582, 0.08160925714362358, 0.0582923265311597, 0.03497539591869582, 0.3630959560825094, 0.3385341422325499, 0.16926707111627495, 0.16926707111627495, 0.16926707111627495, 0.150965224466801, 0.150965224466801, 0.150965224466801, 0.301930448933602, 0.150965224466801, 0.150965224466801, 0.36231607954963646, 0.37076955247330684, 0.3164347610596849, 0.366488954223557, 0.1832444771117785, 0.1832444771117785, 0.1832444771117785, 0.147197896161409, 0.20677799698864596, 0.1436931843480421, 0.1086460662143733, 0.06308481264060385, 0.13317904890794147, 0.06308481264060385, 0.05257067720050321, 0.05257067720050321, 0.031542406320301926, 0.19301025374157668, 0.11258931468258639, 0.22517862936517277, 0.09650512687078834, 0.08042093905899028, 0.08042093905899028, 0.06433675124719222, 0.08042093905899028, 0.04825256343539417, 0.03216837562359611, 0.2526070334284722, 0.2526070334284722, 0.2526070334284722, 0.2937534197208985, 0.09791780657363285, 0.09791780657363285, 0.1958356131472657, 0.09791780657363285, 0.09791780657363285, 0.09791780657363285, 0.09791780657363285, 0.22914961311531856, 0.23033079668807793, 0.10099119547092648, 0.10394415440282492, 0.09981001189816711, 0.06260272935624682, 0.05256266898779215, 0.03602609896916091, 0.03838846611467966, 0.0454755675512359, 0.17966641112229842, 0.17966641112229842, 0.17966641112229842, 0.17966641112229842, 0.17966641112229842, 0.17966641112229842, 0.16472910869556098, 0.1571027610707665, 0.13574898772134192, 0.12202156199671185, 0.1540522220208487, 0.06711185909819152, 0.05948551147339703, 0.03355592954909576, 0.06253605052331482, 0.042707546698849144, 0.16692390073937788, 0.19910200208672785, 0.10658996071309672, 0.11865674871835295, 0.13474579939202794, 0.07441185936574676, 0.06435620269469991, 0.06435620269469991, 0.04424488935260619, 0.02815583867893121, 0.17856124133946372, 0.32736227578901683, 0.08928062066973186, 0.11904082755964249, 0.059520413779821243, 0.11904082755964249, 0.029760206889910622, 0.029760206889910622, 0.029760206889910622, 0.029760206889910622, 0.1971055445887049, 0.2558178344661915, 0.1132308447637241, 0.08806843481622985, 0.11113397726809958, 0.06500289236436013, 0.04613108490373945, 0.05242168739061301, 0.0314530124343678, 0.03564674742561685, 0.28933672618797646, 0.28933672618797646, 0.261656343500828, 0.18326934781552603, 0.15577894564319714, 0.1420337445570327, 0.12370680977548007, 0.06872600543082226, 0.13287027716625638, 0.05498080434465781, 0.07330773912621041, 0.03207213586771706, 0.03207213586771706, 0.261042859477897, 0.08701428649263233, 0.17402857298526467, 0.08701428649263233, 0.08701428649263233, 0.08701428649263233, 0.08701428649263233, 0.08701428649263233, 0.08701428649263233, 0.13718650911198976, 0.10288988183399234, 0.2400763909459821, 0.06859325455599488, 0.13718650911198976, 0.06859325455599488, 0.10288988183399234, 0.03429662727799744, 0.10288988183399234, 0.03429662727799744, 0.1807366333625757, 0.1807366333625757, 0.1807366333625757, 0.1807366333625757, 0.1807366333625757, 0.17707334175946526, 0.17707334175946526, 0.17707334175946526, 0.08853667087973263, 0.2656100126391979, 0.08853667087973263, 0.167145550875124, 0.334291101750248, 0.083572775437562, 0.083572775437562, 0.083572775437562, 0.083572775437562, 0.083572775437562, 0.083572775437562, 0.18666289068511396, 0.18666289068511396, 0.18666289068511396, 0.18666289068511396, 0.2918181120648921, 0.2918181120648921, 0.28064107080936246, 0.28064107080936246, 0.19355688309669755, 0.22731680456705178, 0.11703439443056131, 0.14404233160684468, 0.08777579582292099, 0.09002645725427792, 0.04276256719578202, 0.040511905764425066, 0.02250661431356948, 0.033759921470354226, 0.3781323285749104, 0.2034318127862733, 0.17291704086833232, 0.12714488299142082, 0.13223067831107765, 0.11188749703245032, 0.05933427872932972, 0.07120113447519566, 0.045772157876911496, 0.04407689277035922, 0.03221003702449328, 0.17304598159408754, 0.11536398772939169, 0.057681993864695844, 0.4037739570528709, 0.11536398772939169, 0.057681993864695844, 0.057681993864695844, 0.057681993864695844, 0.13811963115049933, 0.13811963115049933, 0.27623926230099866, 0.13811963115049933, 0.13811963115049933, 0.13811963115049933, 0.15415595346656316, 0.20554127128875088, 0.15415595346656316, 0.15415595346656316, 0.05138531782218772, 0.15415595346656316, 0.05138531782218772, 0.05138531782218772, 0.05138531782218772, 0.05138531782218772, 0.16176571827413538, 0.16176571827413538, 0.16176571827413538, 0.08088285913706769, 0.08088285913706769, 0.16176571827413538, 0.08088285913706769, 0.08088285913706769, 0.08088285913706769, 0.5039127550864063, 0.16797091836213546, 0.16797091836213546], \"Term\": [\"ablation\", \"ablation\", \"ablation\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"actor\", \"adaptive_transform\", \"adaptive_transform\", \"adaptive_transform\", \"adaptive_transform\", \"adaptive_transform\", \"adaptive_transform\", \"adaptive_transform\", \"adaptive_transform\", \"adnan\", \"adnan\", \"adnan\", \"adnan\", \"advice\", \"advice\", \"advice\", \"advice\", \"advice\", \"advice\", \"advice\", \"advice\", \"advice\", \"advice\", \"aerodynamic\", \"agnostic_active\", \"agnostic_active\", \"agnostic_active\", \"agnostic_active\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"aircraft\", \"aircraft\", \"aircraft\", \"aircraft\", \"aircraft\", \"aircraft\", \"aircraft\", \"aircraft_lande\", \"aircraft_lande\", \"aircraft_lande\", \"aircraft_landing\", \"aircraft_landing\", \"aircraft_landing\", \"aircraft_landing\", \"ajj\", \"ajj\", \"ajj\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"allocate\", \"allocate\", \"allocate\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"altitude\", \"altitude\", \"altitude\", \"altitude\", \"altitude\", \"altitude\", \"altitude\", \"am\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"ambiguity\", \"apm\", \"apm\", \"apm\", \"apm\", \"apm\", \"apm\", \"apm\", \"apm\", \"apm\", \"apm\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"augmentation\", \"augmentation\", \"augmentation\", \"bahl\", \"barycenter\", \"barycenter\", \"barycenter\", \"barycenter\", \"barycenter\", \"barycenter\", \"barycenter\", \"barycenter\", \"barycenter\", \"barycenter\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"basic_block\", \"basic_block\", \"basic_block\", \"basic_block\", \"basic_block\", \"basic_block\", \"basic_block\", \"basic_block\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"blahut\", \"blahut\", \"blahut\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"boundary\", \"boundary\", \"boundary\", \"boundary\", \"boundary\", \"boundary\", \"boundary\", \"boundary\", \"boundary\", \"boundary\", \"bpp\", \"bpp\", \"bpp\", \"brfs\", \"bucket\", \"bucket\", \"bucket\", \"bucket\", \"bucket\", \"bucket\", \"bucket\", \"building\", \"building\", \"building\", \"building\", \"building\", \"building\", \"building\", \"building\", \"building\", \"building\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium\", \"calcium_image\", \"calcium_image\", \"calcium_image\", \"calcium_image\", \"calcium_image\", \"calcium_image\", \"calcium_image\", \"calcium_image\", \"capacitor\", \"capacitor\", \"capacitor\", \"capacitor\", \"capacitor\", \"capacitor\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"category\", \"category\", \"category\", \"category\", \"category\", \"category\", \"category\", \"category\", \"category\", \"category\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"centrality\", \"centrality\", \"centrality\", \"centrality\", \"centrality\", \"centrality\", \"centrality\", \"centrality\", \"centrality\", \"cepstral\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"clf\", \"clone\", \"clone\", \"clone\", \"clone\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"coder\", \"coder\", \"coder\", \"coder\", \"coder\", \"coder\", \"coder\", \"coder\", \"coder\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"compatibility\", \"compatibility\", \"compatibility\", \"compatibility\", \"compatibility\", \"compatibility\", \"compatibility\", \"compensate\", \"compensate\", \"compensate\", \"compensate\", \"compensate\", \"compensate\", \"compensate\", \"compensate\", \"compensate\", \"compensate\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compensation\", \"compiler\", \"compiler\", \"compiler\", \"compiler\", \"compiler\", \"compiler\", \"compiler\", \"compiler\", \"compression\", \"compression\", \"compression\", \"compression\", \"compression\", \"compression\", \"compression\", \"compression\", \"compression\", \"compression\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"concentrator\", \"concentrator\", \"concentrator\", \"concentrator\", \"concentrator\", \"concentrator\", \"concentrator\", \"concentrator\", \"concentrator\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"conditional_entropy\", \"conditional_entropy\", \"conditional_entropy\", \"conserve\", \"conserve\", \"conserve\", \"conserve\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"contextual\", \"continuous_tempere\", \"continuous_tempere\", \"continuous_tempere\", \"continuous_tempere\", \"continuous_tempere\", \"continuous_tempere\", \"continuous_tempere\", \"contrive\", \"contrive\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"convergent\", \"convergent\", \"convergent\", \"convergent\", \"convergent\", \"convergent\", \"convergent\", \"convergent\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"correspond\", \"correspond\", \"correspond\", \"correspond\", \"correspond\", \"correspond\", \"correspond\", \"correspond\", \"correspond\", \"correspond\", \"cortico_cortical\", \"cortico_cortical\", \"cortico_cortical\", \"cortico_cortical\", \"cortico_cortical\", \"cortico_cortical\", \"cot\", \"cot\", \"counter\", \"counter\", \"counter\", \"counter\", \"counter\", \"counter\", \"counter\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"coverage\", \"crutchfield\", \"crutchfield\", \"ctld\", \"ctld\", \"ctld\", \"ctld\", \"ctld\", \"ctld\", \"ctld\", \"ctld\", \"ctld\", \"curriculum\", \"curriculum\", \"curriculum\", \"curriculum\", \"curriculum\", \"curriculum\", \"curriculum\", \"cutting_plane\", \"cutting_plane\", \"cutting_plane\", \"cutting_plane\", \"cutting_plane\", \"cutting_plane\", \"cutting_plane\", \"cutting_plane\", \"damp\", \"damp\", \"damp\", \"damp\", \"damp\", \"damp\", \"damp\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"dbm\", \"dbm\", \"dbm\", \"dbm\", \"dbm\", \"dbm\", \"dbm\", \"dbm\", \"dbm\", \"dbm\", \"dbms\", \"dbms\", \"dbms\", \"dbms\", \"dbms\", \"dbms\", \"dbms\", \"dbms\", \"ddpg\", \"ddpg\", \"ddpg\", \"ddpg\", \"ddpg\", \"ddpg\", \"ddpg\", \"ddpg\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decode\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"define\", \"delete\", \"delete\", \"delete\", \"delete\", \"delete\", \"delete\", \"delete\", \"demi_syllable\", \"demi_syllable\", \"demi_syllable\", \"demi_syllable\", \"demi_syllable\", \"demi_syllable\", \"demi_syllable\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"derivative\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"describe\", \"deshpande\", \"deshpande\", \"deshpande\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"dictionary\", \"dictionary\", \"dictionary\", \"dictionary\", \"dictionary\", \"dictionary\", \"dictionary\", \"dictionary\", \"dictionary\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"disagreement\", \"disagreement\", \"disagreement\", \"disagreement_coefficient\", \"disagreement_coefficient\", \"disagreement_coefficient\", \"disagreement_coefficient\", \"disagreement_coefficient\", \"disagreement_coefficient\", \"disagreement_coefficient\", \"disagreement_coefficient\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"disturbance\", \"disturbance\", \"disturbance\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"division\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dqh\", \"dqh\", \"dqh\", \"dqh\", \"dqh\", \"dqn\", \"dqn\", \"dqn\", \"dqn\", \"dqn\", \"dqn\", \"dqn\", \"dqn\", \"dqn\", \"dqn\", \"dropout\", \"dropout\", \"dropout\", \"dyna\", \"dyna\", \"dyna\", \"dyna\", \"dyna\", \"dyna\", \"dyna\", \"dyna\", \"dyna\", \"dyna_ahc\", \"dyna_ahc\", \"dyna_ahc\", \"dyna_ahc\", \"dyna_ahc\", \"dyna_ahc\", \"dyna_ahc\", \"dyna_ahc\", \"dyna_ahc\", \"ebs\", \"ebs\", \"ebs\", \"ebs\", \"ebs\", \"ebs\", \"ebs\", \"eca\", \"eca\", \"eca\", \"eca\", \"eca\", \"eca\", \"edelman\", \"edelman\", \"edelman\", \"edelman\", \"edelman\", \"edelman\", \"edelman\", \"edelman\", \"edelman\", \"edelman\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"eigenfeature\", \"eigenfeature\", \"eigenfeature\", \"eigenfeature\", \"eigenfeature\", \"eigenfeature\", \"eigenfeature\", \"eigenfeature\", \"ejudge\", \"ejudge\", \"ejudge\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"equivalence_constraint\", \"equivalence_constraint\", \"equivalence_constraint\", \"equivalence_constraint\", \"equivalence_constraint\", \"equivalence_constraint\", \"equivalence_constraint\", \"erd\", \"erd\", \"erd\", \"erd\", \"erd_erd\", \"erd_erd\", \"erd_erd\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"euclidean_distance\", \"euclidean_distance\", \"euclidean_distance\", \"euclidean_distance\", \"euclidean_distance\", \"euclidean_distance\", \"evoc\", \"evoc\", \"evoc\", \"evoc\", \"evoc\", \"evoc\", \"evoc\", \"evocation\", \"evocation\", \"evocation\", \"evocation\", \"evocation\", \"evocation\", \"evocation\", \"evocation\", \"evocation\", \"evocation\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"evolution\", \"ewn\", \"ewn\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"exchangeability\", \"exchangeability\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"execution\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra\", \"extra_output\", \"extra_output\", \"extra_output\", \"extra_output\", \"extra_outputs\", \"extra_outputs\", \"extra_outputs\", \"extra_outputs\", \"extra_outputs\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"factorial_hmms\", \"factorial_hmms\", \"fck\", \"fck\", \"fck\", \"fck\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"ferret\", \"ferret\", \"ferret\", \"ferret\", \"ferret\", \"ferret\", \"fetch\", \"fetch\", \"fetch\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fk\", \"fk\", \"fk\", \"fk\", \"fk\", \"flare\", \"flare\", \"flare\", \"flare\", \"flare\", \"flare\", \"flll\", \"flop\", \"flop\", \"flop\", \"flop\", \"flop\", \"flop\", \"flop\", \"flop\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"frustrate\", \"frustrate\", \"frustrated\", \"frustrated\", \"frustrated\", \"frustrated\", \"frustrated\", \"fsm\", \"fsm\", \"fsm\", \"fsm\", \"fsm\", \"fsm\", \"fsm\", \"fully_disconnecte\", \"fully_disconnecte\", \"fully_disconnecte\", \"fully_disconnecte\", \"fully_disconnecte\", \"fully_disconnecte\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"gale\", \"gb\", \"gb\", \"gb\", \"gb\", \"gb\", \"gb\", \"gb\", \"gb\", \"germain\", \"germain\", \"gibbs_sampl\", \"gibbs_sampl\", \"gibbs_sampl\", \"gibbs_sampl\", \"gibbs_sampl\", \"gibbs_sampl\", \"gibbs_sampl\", \"gibbs_sampl\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"glideslope\", \"glideslope\", \"glideslope\", \"glideslope\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goals_replay\", \"goals_replay\", \"goals_replay\", \"golub\", \"golub\", \"golub\", \"golub\", \"googl\", \"googl\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"grid_world\", \"grid_world\", \"grid_world\", \"grid_world\", \"grid_world\", \"grid_world\", \"grid_world\", \"grid_world\", \"grid_world\", \"grid_world\", \"gripper\", \"gripper\", \"gripper\", \"gripper\", \"gripper\", \"gripper\", \"gripper\", \"halt\", \"halt\", \"halt\", \"halt\", \"halt\", \"hdp\", \"hdp\", \"hdp\", \"hdp\", \"hdp\", \"hdp\", \"hdp\", \"hdqc\", \"hdqc\", \"hdqc\", \"hdqc\", \"hebbian\", \"hebbian\", \"hebbian\", \"hebbian\", \"hebbian\", \"hindsight_experience\", \"hindsight_experience\", \"hindsight_experience\", \"hindsight_experience\", \"hindsight_experience\", \"hindsight_experience\", \"hindsight_experience\", \"hippocampal\", \"hippocampal\", \"hippocampal\", \"hippocampal\", \"hippocampal\", \"hypothesis_space\", \"hypothesis_space\", \"hypothesis_space\", \"iayer\", \"iayer\", \"iayer\", \"iayer\", \"iayer\", \"iayer\", \"ideal\", \"ideal\", \"ideal\", \"ideal\", \"ideal\", \"ideal\", \"ideal\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"impedance\", \"impedance\", \"impedance\", \"impedance\", \"impedance\", \"independence_test\", \"independence_test\", \"independence_test\", \"initiation\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instability\", \"instability\", \"instability\", \"instability\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction\", \"instruction_scheduling\", \"instruction_scheduling\", \"instruction_scheduling\", \"instruction_scheduling\", \"instruction_scheduling\", \"instruction_scheduling\", \"instruction_scheduling\", \"instruction_scheduling\", \"interconnect\", \"interconnect\", \"interconnect\", \"interpolate\", \"interpolate\", \"interpolate\", \"interpolate\", \"interpolate\", \"io_passe\", \"io_passe\", \"io_passe\", \"io_passe\", \"io_passe\", \"io_passe\", \"io_passe\", \"io_passe\", \"iqrp\", \"iqrp\", \"iqrp\", \"iqrp\", \"iqrp\", \"iqrp\", \"iqrp\", \"iqrp\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"keyboard\", \"keyboard\", \"keyboard\", \"kolen\", \"kolen\", \"kolen\", \"kolen\", \"kregbaye\", \"kregbaye\", \"kregbaye\", \"kregbaye\", \"kregbaye\", \"kregbaye\", \"kregbaye\", \"kth_order\", \"kth_order\", \"kth_order\", \"kth_order\", \"kth_order\", \"kth_order\", \"kth_order\", \"kth_order\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label_complexity\", \"label_complexity\", \"label_complexity\", \"label_complexity\", \"label_complexity\", \"label_complexity\", \"label_complexity\", \"label_complexity\", \"lancaster_interaction\", \"lancaster_interaction\", \"lancaster_interaction\", \"lancaster_interaction\", \"lancaster_interaction\", \"lancaster_interaction\", \"lancaster_interaction\", \"lancaster_interaction\", \"land\", \"land\", \"landing\", \"landing\", \"landing\", \"landing\", \"landing\", \"landing\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large_vocabulary\", \"large_vocabulary\", \"large_vocabulary\", \"large_vocabulary\", \"large_vocabulary\", \"large_vocabulary\", \"large_vocabulary\", \"large_vocabulary\", \"latent_factor\", \"latent_factor\", \"latent_factor\", \"latent_factor\", \"latent_factor\", \"latent_factor\", \"latent_factor\", \"latent_factor\", \"latent_factor\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"lds\", \"lds\", \"lds\", \"lds\", \"lds\", \"lds\", \"lds\", \"lds\", \"lds\", \"lds\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"lehrer\", \"lehrer\", \"lehrer\", \"lehrer\", \"lehrer\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"lfw\", \"lfw\", \"lfw\", \"lfw\", \"lfw\", \"lfw\", \"lfw\", \"likelihood_ratio\", \"likelihood_ratio\", \"likelihood_ratio\", \"likelihood_ratio\", \"likelihood_ratio\", \"likelihood_ratio\", \"likelihood_ratio\", \"likelihood_ratio\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"logarithmic\", \"logarithmic\", \"logarithmic\", \"logarithmic\", \"logarithmic\", \"logarithmic\", \"logarithmic\", \"logd\", \"logd\", \"logd\", \"logd\", \"logo_traine\", \"logo_traine\", \"logo_traine\", \"logo_traine\", \"logo_traine\", \"los_angele\", \"los_angele\", \"los_angele\", \"los_angele\", \"los_angele\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lp_relaxation\", \"lp_relaxation\", \"lp_relaxation\", \"lp_relaxation\", \"lp_relaxation\", \"lp_relaxation\", \"maass\", \"maass\", \"maass\", \"maass\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin\", \"margin_bound\", \"margin_bound\", \"margin_bound\", \"margin_bound\", \"margin_bound\", \"margin_bound\", \"margin_bound\", \"margin_bound\", \"marker\", \"marker\", \"marker\", \"marker\", \"marker\", \"marker\", \"marker\", \"marker\", \"marker\", \"marker\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"maze\", \"maze\", \"maze\", \"maze\", \"maze\", \"maze\", \"maze\", \"maze\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"mental_rotation\", \"mental_rotation\", \"mental_rotation\", \"mental_rotation\", \"mental_rotation\", \"mental_rotation\", \"message_passing\", \"message_passing\", \"message_passing\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"metropolis\", \"metropolis\", \"metropolis\", \"metropolis\", \"metropolis\", \"metropolis\", \"mlp_predictor\", \"mlp_predictor\", \"mlp_predictor\", \"mlp_predictor\", \"mlp_predictor\", \"mlp_predictor\", \"mmihmm\", \"mmihmm\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"monomial\", \"monomial\", \"monomial\", \"monomial\", \"monomial\", \"moss\", \"moss\", \"moss\", \"moss\", \"moss\", \"moss\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"mother\", \"move\", \"move\", \"move\", \"move\", \"move\", \"move\", \"move\", \"move\", \"move\", \"move\", \"multitask\", \"multitask\", \"multitask\", \"multitask\", \"mutant\", \"mutant\", \"mutant\", \"mutant\", \"mutant\", \"mutant\", \"mutant\", \"mutant\", \"mutant\", \"mutant\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"neuman\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noisel\", \"noisescale\", \"noisescale\", \"noisescale\", \"noisescale\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"non_decomposable\", \"normalisation\", \"normalisation\", \"normalisation\", \"normalisation\", \"normalisation\", \"normalisation\", \"normalisation\", \"normalisation\", \"npm\", \"npm\", \"npm\", \"npm\", \"npm\", \"npm\", \"npm\", \"ntkd\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_detection\", \"occam_razor\", \"occam_razor\", \"occam_razor\", \"occam_razor\", \"occam_razor\", \"occam_razor\", \"occam_razor\", \"occam_razor\", \"oiod\", \"optimizational\", \"optimizational\", \"optimizational\", \"optimizational\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"oscillatory\", \"ostrovski\", \"ostrovski\", \"ostrovski\", \"ostrovski\", \"ostrovski\", \"ostrovski\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"outperform\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"pac_baye\", \"pac_baye\", \"pac_baye\", \"pac_baye\", \"pac_baye\", \"pac_baye\", \"pac_baye\", \"pac_bayes\", \"pac_bayes\", \"pac_bayes\", \"pac_bayes\", \"pac_bayes\", \"pac_bayes\", \"pac_bayes\", \"pac_bayes\", \"pac_bayes\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"packet\", \"pages_curran\", \"pages_curran\", \"pages_curran\", \"pages_curran\", \"pages_curran\", \"pages_curran\", \"pages_curran\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parasitic\", \"parasitic\", \"parasitic\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parenthesis\", \"parking\", \"parking\", \"parking\", \"parking\", \"parking\", \"parking\", \"parking\", \"parking\", \"partial_schedule\", \"partial_schedule\", \"pea\", \"pea\", \"pea\", \"pea\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"pfm\", \"pfm\", \"pfm\", \"pfm\", \"pfm\", \"pfm\", \"pfm\", \"pfm\", \"pfm\", \"physical_robot\", \"physical_robot\", \"physical_robot\", \"physical_robot\", \"physical_robot\", \"physical_robot\", \"pid\", \"pid\", \"piecewise_polynomial\", \"piecewise_polynomial\", \"piecewise_polynomial\", \"piecewise_polynomial\", \"piecewise_polynomial\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"pnk\", \"pnk\", \"pnk\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pole\", \"pole\", \"pole\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"pomerleau\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"preplay\", \"preplay\", \"preplay\", \"preplay\", \"preplay\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probit\", \"probit\", \"probit\", \"probit\", \"probit\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"protocol\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prototype\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"prxdx\", \"prxdx\", \"prxdx\", \"puck\", \"puck\", \"puck\", \"puck\", \"puck\", \"puck\", \"pxy\", \"quadrant\", \"quadrant\", \"quadrant\", \"quadrant\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random_projection\", \"random_projection\", \"random_projection\", \"random_projection\", \"random_projection\", \"random_projection\", \"random_projection\", \"random_projection\", \"random_projection\", \"random_projection\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"randomize\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"reactive_policie\", \"reactive_policie\", \"reactive_policie\", \"reactive_policie\", \"reactive_policie\", \"reactive_policie\", \"reactive_policie\", \"rec\", \"rec\", \"rec\", \"rec\", \"rec\", \"rec\", \"rec\", \"rec\", \"rec\", \"rec_compensation\", \"rec_compensation\", \"rec_compensation\", \"rec_compensation\", \"rec_compensation\", \"rec_compensation\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"refinement\", \"refinement\", \"refinement\", \"refinement\", \"refinement\", \"refinement\", \"refinement\", \"refinement\", \"refinement\", \"refinement\", \"relax\", \"relax\", \"relax\", \"relax\", \"relax\", \"relax\", \"relax\", \"relax\", \"relax\", \"relax\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxed\", \"relaxed\", \"relaxed\", \"relaxed\", \"relaxed\", \"relaxed\", \"relaxing_equivalence\", \"relaxing_equivalence\", \"relaxing_equivalence\", \"relaxing_equivalence\", \"relaxing_equivalence\", \"relaxing_equivalence\", \"reordering\", \"reordering\", \"reordering\", \"replay\", \"replay\", \"replay\", \"replay\", \"replay\", \"replay\", \"replay\", \"replay\", \"replay\", \"replay\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"reproduction\", \"reproduction\", \"reproduction\", \"reproduction\", \"reproduction\", \"reprojection\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"rf\", \"riemannian\", \"riemannian\", \"riemannian\", \"riemannian\", \"riemannian\", \"riemannian\", \"riemannian\", \"riemannian\", \"riemannian\", \"rlmi\", \"rlmi\", \"rlmince\", \"rnr\", \"rnr\", \"rnr\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"sakurai\", \"sakurai\", \"sakurai\", \"sakurai\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sarsa\", \"sarsa\", \"sarsa\", \"sarsa\", \"sarsa\", \"sarsa\", \"sarsa\", \"sarsa\", \"sarsa\", \"sbn_qlim\", \"sbn_qlim\", \"sbn_qlim\", \"sbn_qlim\", \"sbn_qlim\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"scene\", \"schaul\", \"schaul\", \"schaul\", \"schaul\", \"schaul\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduler\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"scheduling\", \"score_space\", \"score_space\", \"score_space\", \"score_space\", \"score_space\", \"score_space\", \"score_space\", \"score_space\", \"score_space\", \"score_space\", \"scrambled_wavelet\", \"scrambled_wavelet\", \"scrambled_wavelet\", \"scrambled_wavelet\", \"scrambled_wavelet\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"screen\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"self_organize\", \"self_organize\", \"self_organize\", \"self_organize\", \"self_organize\", \"self_organize\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"semi_supervise\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shatter\", \"shatter\", \"shatter\", \"shelf\", \"shelf\", \"shelf\", \"shelf\", \"shelf\", \"shelf\", \"shelf\", \"shelf\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"sign_sign\", \"sign_sign\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"skewed\", \"skewed\", \"slide\", \"slide\", \"slide\", \"slide\", \"slide\", \"slide\", \"slide\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"sparsifying_logistic\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spread_stimulus\", \"spread_stimulus\", \"spread_stimulus\", \"stagewise\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std\", \"std_std\", \"std_std\", \"std_std\", \"std_std\", \"stlwt\", \"stlwt\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"subexponential\", \"subexponential\", \"subexponential\", \"subexponential\", \"subexponential\", \"subexponential\", \"sublinear\", \"sublinear\", \"sublinear\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"succession\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"successor\", \"supervisor\", \"supervisor\", \"supervisor\", \"supervisor\", \"surface\", \"surface\", \"surface\", \"surface\", \"surface\", \"surface\", \"surface\", \"surface\", \"surface\", \"surface\", \"swap\", \"swap\", \"swap\", \"swap\", \"swap\", \"swap\", \"swap\", \"swap\", \"swap\", \"swap\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"switch\", \"synergistic\", \"synthesizer\", \"synthesizer\", \"synthesizer\", \"synthesizer\", \"synthesizer\", \"synthesizer\", \"synthesizer\", \"synthesizer\", \"synthesizer\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"tangent\", \"tangent\", \"tangent\", \"tangent\", \"tangent\", \"tangent\", \"tangent\", \"tangent\", \"tangent\", \"tangent\", \"tangent_distance\", \"tangent_distance\", \"tangent_distance\", \"tangent_distance\", \"tangent_distance\", \"tangent_distance\", \"tangent_subspace\", \"tangent_subspace\", \"tangent_subspace\", \"tangent_subspace\", \"tangent_subspace\", \"tangent_subspace\", \"tangent_subspace\", \"tangent_subspace\", \"target_neuron\", \"target_neuron\", \"target_neuron\", \"target_neuron\", \"target_neuron\", \"target_neuron\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"temperature\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"tighten\", \"tighten\", \"tighten\", \"tighten\", \"tighten\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"touchdown\", \"tracklet\", \"tracklet\", \"tracklet\", \"tracklet\", \"tracklet\", \"tracklet\", \"tracklet\", \"tracklet\", \"tracklet\", \"tracklet\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"transform_code\", \"transform_coder\", \"transform_coder\", \"transform_coder\", \"transform_coder\", \"transform_coder\", \"transform_coder\", \"transform_coder\", \"transform_coder\", \"transient\", \"transient\", \"transient\", \"transient\", \"transient\", \"transient\", \"transient\", \"transient\", \"transient\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"tsybakovs\", \"turbo\", \"turbo\", \"turbo\", \"turbo\", \"turbulence\", \"turbulence\", \"turbulence\", \"turbulence\", \"turbulence\", \"turbulence\", \"ukt\", \"ullman\", \"unencode\", \"unencoded\", \"unencoded\", \"unencoded\", \"unencoded\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"unlabeled\", \"uphill\", \"uphill\", \"uphill\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"urban\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"valid_configuration\", \"valid_configuration\", \"valid_configuration\", \"valid_configuration\", \"valid_configuration\", \"valid_configuration\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vc_dimension\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vendor\", \"vendor\", \"ventral\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view_tuned\", \"view_tuned\", \"view_tuned\", \"view_tuned\", \"view_tuned\", \"view_tuned\", \"view_tuned\", \"view_tuned\", \"view_tuned\", \"vin\", \"vin\", \"vin\", \"vin\", \"vin\", \"vin\", \"vin\", \"vin\", \"vin\", \"vin\", \"vjk\", \"vjk\", \"vjk\", \"vjk\", \"vjk\", \"vkt\", \"vkt\", \"vkt\", \"vkt\", \"vkt\", \"vkt\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"vocabulary\", \"voting_classifi\", \"voting_classifi\", \"voting_classifi\", \"voting_classifi\", \"watanabe\", \"watanabe\", \"watrous\", \"watrous\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"wein\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"wind\", \"written_character\", \"written_character\", \"written_character\", \"written_character\", \"written_character\", \"written_character\", \"ws\", \"ws\", \"ws\", \"ws\", \"ws\", \"ws\", \"ws\", \"ws\", \"ws\", \"ws\", \"wt\", \"wt\", \"wt\", \"wt\", \"wt\", \"wt\", \"wt\", \"wt\", \"wt\", \"xim\", \"xim\", \"xim\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 6, 10, 5, 3, 8, 1, 4, 9, 7]};\n","\n","function LDAvis_load_lib(url, callback){\n","  var s = document.createElement('script');\n","  s.src = url;\n","  s.async = true;\n","  s.onreadystatechange = s.onload = callback;\n","  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n","  document.getElementsByTagName(\"head\")[0].appendChild(s);\n","}\n","\n","if(typeof(LDAvis) !== \"undefined\"){\n","   // already loaded: just create the visualization\n","   !function(LDAvis){\n","       new LDAvis(\"#\" + \"ldavis_el385511387618547071689949802437\", ldavis_el385511387618547071689949802437_data);\n","   }(LDAvis);\n","}else if(typeof define === \"function\" && define.amd){\n","   // require.js is available: use it to load d3/LDAvis\n","   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n","   require([\"d3\"], function(d3){\n","      window.d3 = d3;\n","      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","        new LDAvis(\"#\" + \"ldavis_el385511387618547071689949802437\", ldavis_el385511387618547071689949802437_data);\n","      });\n","    });\n","}else{\n","    // require.js not available: dynamically load d3 & LDAvis\n","    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n","         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n","                 new LDAvis(\"#\" + \"ldavis_el385511387618547071689949802437\", ldavis_el385511387618547071689949802437_data);\n","            })\n","         });\n","}\n","</script>"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["from gensim.models import CoherenceModel"],"metadata":{"id":"pGrpxcAXGJE0","executionInfo":{"status":"ok","timestamp":1751191504914,"user_tz":-330,"elapsed":40,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["# Compute Coherence Score\n","coherence_model_lda = CoherenceModel(model=lda_model, texts=clean_words_lemmatized, dictionary=id2word, coherence='c_v')"],"metadata":{"id":"YDTY0b-KJcYO","executionInfo":{"status":"ok","timestamp":1751191524235,"user_tz":-330,"elapsed":62,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["coherence_lda = coherence_model_lda.get_coherence()\n","\n","\n","print('LDA Model Coherence Score: ', coherence_lda)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJEedIlqJhGV","executionInfo":{"status":"ok","timestamp":1751191546925,"user_tz":-330,"elapsed":5534,"user":{"displayName":"Bishal Duarah","userId":"13455479126051814902"}},"outputId":"64b0d619-0031-4502-dfa2-ab30fe0ccff3"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["LDA Model Coherence Score:  0.23273659098781785\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bZ9g6vuZJlTD"},"execution_count":null,"outputs":[]}]}